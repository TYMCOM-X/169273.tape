


                              Revision 2



                              8/18/1979
                                                                Page 2


     This version of NEW114 contains new  material,  added  since  the
     release of 114 Beta-7.  Changes have been made to sections:



     2.10 System Variables -- new variables added.

     2.33 Extended Line Length -- new section

     2.34 Trailing Blank Supression on Teletypes -- new section

     17 The CHANGE Command During Simultaneous Update -- new chapter












                              CHAPTER 1

                 SUMMARY OF NEW SYSTEM 1022 FEATURES



     The 114 release of System 1022 has a number of new  commands  and
     features,  as well as enhanced performance in a variety of areas.
     The most important features of the current release are summarized
     below.   A  detailed description of each of these features can be
     found in the succeeding chapters.


     1.  Beware note

         Software House does not  support  System  1022  with  TOPS-20
         prior to version 2.

     2.  Multiple datasets per file

         The user now has the option of including multiple datasets in
         one file.


     3.  TOPS-20 file-descriptors

         File-descriptors under TOPS-20 have been modified to  include
         user names.


     4.  Dataset-descriptors

         A dataset-descriptor is now used to identify a dataset.


     5.  DESC clause

         Several commands now optionally include a DESC clause.   This
         clause provides more control over record formats on input.


     6.  APPEND Command

         The APPEND command has  several  new  capabilities.   Records
         with  a  different format than the currently open dataset can
         now be appended either from a DMI or a DMS file.
SUMMARY OF NEW SYSTEM 1022 FEATURES                           Page 1-2


     7.  CREATE Command

         The CREATE command performs the same  function  as  the  1022
         LOAD  command.   The  difference  between the two commands is
         that with the CREATE command the  data  is  maintained  in  a
         separate  file  from  the  DMS.   This is called an unbundled
         dataset.


     8.  DUMP Command

         Several new features have been added  to  the  DUMP  command.
         The DUMP command can now write unbundled datasets (see CREATE
         command), data (DMI) files, and files  whose  structures  are
         different from the original dataset.


     9.  TRANSACT Command

         The TRANSACT command enables the  user  to  perform  multiple
         updates  to  a  dataset  easily.   The command is geared to a
         system where changes are batched for later entry.


    10.  LOAD Command

         The LOAD command has been greatly enhanced.  Input and output
         files can now be specified in the command itself.


    11.  Data description files

         The  data  description  file  has  several  new  options  and
         enhancements.


    12.  Date formats

         There are several new date formats acceptable for input.


    13.  Error handling

         There is a new format for error log files.


    14.  System variables

         Several new system variables have been added.


    15.  FIND Command

         The FIND command now allows CONTAINS as a relational.
SUMMARY OF NEW SYSTEM 1022 FEATURES                           Page 1-3


    16.  Deleted records

         Two functions have  been  added  which  gain  access  to  and
         activate deleted records.


    17.  Passwords and the OPEN command

         The  OPEN  command  has  been  modified  to  include   System
         prompting for passwords.


    18.  FILE Command

         The FILE command manipulates disk files from the  stand-alone
         System.


    19.  PRINT Command

         The PRINT command has a new option which will print the value
         for each attribute of a record.


    20.  IGNORE DAMAGE Command

         The IGNORE DAMAGE command tells the System to ignore  dataset
         file damage.


    21.  INFORM Command

         The INFORM command has been enhanced  to  include  three  new
         options:  DAMAGE, STATUS and AUDIT.


    22.  INIT Command and System Output Channels

         The INIT  command  has  been  enhanced  to  optionally  allow
         existing  files  to  be  appended to.  There are now 8 System
         output channels.


    23.  Literals

         Quotes are now treated as input text.


    24.  Comments

         An  exclamation  point  now  indicates  the  beginning  of  a
         comment.

SUMMARY OF NEW SYSTEM 1022 FEATURES                           Page 1-4


    25.  Command files and CONST function

         There are two new types of indirect  text  references.   Also
         variables  can  now  be  referenced  whenever  a constant was
         previously required.


    26.  DEFINE Command

         The DEFINE command has been enhanced to permit definitions of
         double  precision integers and arrays.  In addition, multiple
         definition rules have been modified to simplify  the  use  of
         DEFINE within DPL programs.


    27.  SOS or EDIT Command

         It is now possible to  use  the  SOS  text  editor  from  the
         stand-alone System.


    28.  MAP Command

         The MAP command  has  been  enhanced  to  include  a  LOGICAL
         option.


    29.  Audit trail

         System 1022 now has the ability to maintain files  which  can
         be  used  to  back  up  a dataset in the event of a system or
         software crash.  These files  are  maintained  by  the  AUDIT
         commands.


    30.  Expression handling facilities

         System 1022 has an enhanced expression handler which  permits
         general  expressions  to  be specified in the place of simple
         values in many commands and which will automatically make any
         reasonable type conversions.


    31.  TMPFILE Command

         The TMPFILE command has been added for TOPS-10 users who  use
         TMPCORE for interprogram communications.


    32.  ADMIT command

         The ADMIT command has been enhanced to provide an  additional
         dataset security structure.

SUMMARY OF NEW SYSTEM 1022 FEATURES                           Page 1-5


    33.  BACKTO Command

         The BACKTO command will make the currently  selected  dataset
         compatible with version 113.


    34.  TYPE Command

         The TYPE command has  been  changed  so  that  it  no  longer
         requires channel 1.


    35.  Nested DPL Segments

         DPL segments may now contain many levels of nested DPL  START
         -- DPL END pairs.


    36.  VALUES Command

         The format of the output generated by the VALUES command  has
         been changed.


    37.  SPSS Command

         There is now an interface with the  Statistical  Package  for
         the Social Sciences (SPSS).


    38.  CHANGEs during interactive update

         The System has been enhanced to  allow  trapping  of  records
         that are being CHANGEd that have been altered since they were
         found.


    39.  Incompatibilities

         A few incompatibilities  between  V113  and  V114  have  been
         found.  They are:


         1.  Floating point conversion

             Slight inaccuracies in floating  point  conversions  were
             discovered in V113.  This problem has been fixed in V114.


         2.  The Formatter

             Special line printer conventions have been changed.

SUMMARY OF NEW SYSTEM 1022 FEATURES                           Page 1-6


         3.  Run-on Command Files

             V114 now checks that  command  files  end  properly  when
             control passes back to the user's teletype.



    40.  Internal changes and enhancements

         There have been changes and enhancements in the following


         1.  Block allocation

         2.  SORT routines

         3.  Incremental optimizer

         4.  Channel pooling

         5.  Default paths and SFDs



    41.  New printing line length

         The length of System 1022 print  lines  is  extended  to  400
         characters.


    42.  Supression of trailing blanks to a terminal

         Output that is  directed  to  the  user's  terminal  now  has
         trailing blanks supressed.


    43.  Host Language interface

         The Host Language interface  has  several  new  commands  and
         features:


         1.  MACRO interface

             It is now possible to access 1022 from MACRO.


         2.  Audit trail

             There are several subroutines available in  both  FORTRAN
             and COBOL which provide the same audit trail capabilities
             as the stand-alone System.  In  addition,  the  user  can
             define  his  own  audit  trail  entries  through the Host
             Language interface.
SUMMARY OF NEW SYSTEM 1022 FEATURES                           Page 1-7


         3.  DBINFO subroutine

             The information returned by  the  DBINFO  subroutine  has
             been enhanced to reflect the new allowable data types.


         4.  DBOPEN subroutine

             DBOPEN has been enhanced to permit  referencing  multiple
             datasets in one file.


         5.  DBMAP subroutine

             DBMAP has been enhanced to include a LOGICAL option.


         6.  DBSYSV subroutine

             Several new System variables can  now  be  referenced  by
             using DBSYSV.


         7.  New data types

             The FORTRAN and COBOL interfaces have  been  enhanced  to
             allow processing of the new data types.














                              CHAPTER 2

                            ODDS AND ENDS



     2.1  MULTIPLE DATASETS PER FILE

     The user now has the option of including multiple datasets in one
     file.   In  general, the user should put only one dataset in each
     file for the following reasons:

          The  files  can  be  distributed  among  several   file
          structures  (i.e.   separate  disk  units)  for  better
          access times in a complex data base  involving  related
          datasets.

          Should the file  become  damaged  due  to  hardware  or
          software  problems, only the one (smaller) dataset file
          has to be regenerated.  It  may  also  be  possible  to
          continue running with the other datasets.

          Should a dataset become invalid or  no  longer  needed,
          the space can be reclaimed by simply deleting the file.
          In a multi-dataset file, all active datasets would have
          to be DUMPed to a new file.

          During an AUDIT BACKUP blocks added  since  the  backup
          point  will  be  de-allocated.  In a multi-dataset file
          these blocks will not be de-allocated.  (See the  audit
          trail chapter for more details.)

     However, under the following cases it may be wise to put  several
     datasets in one file:

          The user will need to have more than 13  datasets  open
          at  once.   Since only 13 files can be open at one time
          (and fewer than 13 if sorting is to be done), more than
          one  dataset  would  have  to  be placed on some of the
          files.   There  is  no  limitation  on  the  number  of
          datasets  that  can  be  open  at  once;  the number of
          dataset files, however, is restricted to 13 or fewer.

          The user has several  small  datasets  (e.g.   datasets
          being used for table lookups of encoded values in other
          datasets)  which  are  always   open   together.    For
ODDS AND ENDS                                                 Page 2-2


          bookkeeping  reasons,  it may be easier to maintain the
          several small datasets in one file, rather than  having
          several small files in the user's directory.



     2.2  TOPS-20 FILE-DESCRIPTORS

     A file-descriptor specifies a DECsystem-10 or DECsystem-20  file.
     File-descriptors under TOPS-10 remain unchanged.  The form of the
     TOPS-20 file-descriptor is:

          DEV:<DIRECTORY>NAME.EXT

     DIRECTORY is the standard TOPS-20  directory  specification.   It
     may be up to 39 letters and digits including hyphens.

     DEV may have a maximum of 6  characters,  NAME  a  maximum  of  6
     characters, and EXT a maximum of 3 characters.



     2.3  DATASET-DESCRIPTORS

     A dataset-descriptor is used to identify  a  dataset.   The  full
     form of a dataset-descriptor is:

          <dataset-name> IN <file-descriptor>

     <dataset-name>  -  is the name given  to  the  dataset.   Dataset
     names  may contain letters, numbers and the under-score character
     (back-arrow on many terminals).  The  names  must  begin  with  a
     letter and contain a maximum of 25 characters.

     <file-descriptor>  -  is a file-descriptor as  described  in  the
     user's manual and above.

     On many commands, either the dataset-name or  file-descriptor  is
     optional.  For example, when creating a dataset (with the CREATE,
     LOAD, or DUMP commands) the file-descriptor must be specified  so
     the  System  will  know  on  what  file  to put the dataset.  The
     dataset-name, however, can be omitted, in which case  the  System
     assigns  the  dataset-name  to  be  the same as the filename.  If
     multiple  datasets  are  to  be  put  in  one  file,   both   the
     dataset-name  and file-descriptor must be specified.  On the OPEN
     command, if only the file-descriptor is specified the System will
     open all datasets in that file.

     Commands which reference existing datasets  (such  as  DBSET  and
     MAP)  need  only  specify  the  dataset-name if it is unique.  If
     there are other open datasets with the  same  dataset-name,  then
     the  file-descriptor must also be specified to uniquely determine
     which dataset is to be used.  (If one  dataset  is  OPENed  twice
     concurrently then the dataset number must be specified instead of
     the dataset-descriptor.)
ODDS AND ENDS                                                 Page 2-3


     2.4  DESC CLAUSE

     Several 1022 commands may include a DESC clause.  The DESC clause
     provides  control  over  the  format  of  datasets and data files
     created by the System, and specifies formats  for  records  which
     are input to the System.

     The DESC clause names a System 1022 data description file for use
     in  commands such as APPEND, TRANSACT, LOAD, or CREATE.  The full
     explanation for the form of a data description  file  appears  in
     the User's Manual under the LOAD command.  In the LOAD and CREATE
     commands, this  file  describes  the  input  data  file  and  the
     resulting  dataset  description.   In  the  APPEND  and  TRANSACT
     commands, it describes an input data file for processing  against
     a master dataset.

     When applied to data files, the description file gives a name and
     data type to the fields in the record.  In most cases, the System
     compares the user-specified DESC with an already existing dataset
     description  (i.e.  the structure of the currently open dataset.)
     The fields and attributes are matched  according  to  their  full
     names  (abbreviations  are ignored) to determine how to apply the
     input  data  against  the  attributes  of  the  master   dataset.
     Attribute  values  for  attributes  which  did  not  map from one
     description to the other are ignored on input and are treated  as
     null fields on record creation.

     When  applying  data  from  one  field  to  another,  the  System
     automatically  converts the data type (if possible) to match that
     of the master field, before applying the data to that field.   If
     field  sizes are not the same, truncation may occur.  When a text
     field is written to a  smaller  text  field,  characters  may  be
     truncated from the right.  When a target display numeric field is
     smaller than the input data, right truncation  may  occur.   When
     the  master  dataset  is bundled and the RANGE on an attribute is
     smaller than an input integer value  an  error  message  will  be
     printed  and zero will be the new value.  When the master dataset
     is unbundled there is no range checking and if the  target  field
     is smaller than the input data, right truncation may occur.  When
     the target field is REAL (not display) no truncation will occur.

                                 NOTE

          No warnings are printed to announce that truncation has
          occurred.
ODDS AND ENDS                                                 Page 2-4


     For example, consider the following master dataset structure, and
     a data file FOO.DAT with its description file FOO.DMD.

     The master dataset, PEOPLE.DMS, has the following structure:

          ATTRIBUTE FIRST_NAME TEXT    LENGTH 10
          ATTRIBUTE LAST_NAME  TEXT    LENGTH 10
          ATTRIBUTE AGE        INTEGER LENGTH  2 RANGE 0 80
          ATTRIBUTE NO_CARS    INTEGER LENGTH  1

     The data file FOO.DAT has the description FOO.DMD:

          ATTRIBUTE FIRST_NAME TEXT    LENGTH 12
          ATTRIBUTE LAST_NAME  TEXT    LENGTH 12
          ATTRIBUTE AGE        INTEGER LENGTH  2
          ATTRIBUTE SEQ_NUMBER INTEGER LENGTH  4

     If the following commands are given:

          OPEN PEOPLE
          APPEND DATA FOO.DAT DESC FOO.DMD

     then for each line of data in the data  file  FOO.DAT,  a  record
     will  be  added to the dataset PEOPLE.  The attributes FIRST_NAME
     and LAST_NAME in PEOPLE will be filled from the same named fields
     in FOO.DAT.  Since the fields in FOO.DAT are longer, they will be
     truncated to 10 character  of  text  to  fit  the  attributes  in
     PEOP
     The ages in FOO.DAT will be used in each record to fill  the  AGE
     attribute in PEOPLE.  If the values were too big to fit the range
     of 0 to 80 in PEOPLE, an  error  message  will  result  for  that
     record, and a value of zero will be inserted.

     The attribute NO_CARS in PEOPLE has no associated  field,  so  it
     will  be  filled  with  the  null value of 0 in each record.  The
     field SEQ_NUMBER in FOO.DAT does not correspond to any  attribute
     field, so it is ignored on input.



     2.5  BUNDLED AND UNBUNDLED DATASETS

     System 1022 can now create and  access  two  types  of  datasets:
     bundled and unbundled.

     1.  BUNDLED DATASETS

     The LOAD  command  produces  a  bundled  dataset.   This  command
     combines,  or  bundles, data records, their keys and description,
     and other 1022 information into one dataset.
ODDS AND ENDS                                                 Page 2-5


     2.  UNBUNDLED DATASETS

     The CREATE command (see chapter 5) produces an unbundled dataset.
     Unlike a bundled dataset, an unbundled one keeps the data records
     in another file, separate or unbundled from the  keys  and  other
     1022 information.


                            1022 DATASETS

     I----------------------I----------------------------------------I
     I                      I                                        I
     I    Bundled           I              Unbundled                 I          _______                          _________
     I                      I                                        I
     I                      I                                        I
     I    Dataset           I       Dataset          Datafile        I
     I   _________          I      _________        __________       I
     I   I       I          I      I       I        I        I       I
     I   I 1022  I          I      I 1022  I   I--->I data   I       I
     I   I info  I          I      I info  I   I    I recordsI       I
     I   I-------I          I      I-------I   I    I        I       I
     I   I       I          I      I ID of I   I    I        I       I
     I   I data  I          I      I data  I   I    I        I       I
     I   IrecordsI          I      I file  I---I    I (User'sI       I
     I   I       I          I      I-------I        I  data- I       I
     I   I-------I          I      I       I        I  file) I       I
     I   I       I          I      I       I        I        I       I
     I   I keys  I          I      I keys  I        I        I       I
     I   I       I          I      I       I        I        I       I
     I   I       I          I      I       I        I        I       I
     I   I_______I          I      I_______I        I________I       I
     I                      I                                        I
     I----------------------I----------------------------------------I



     2.6  LOAD COMMAND

     The format of the LOAD command has been changed to

          LOAD <file-descriptor>
               [DATA <file-descriptor>] [SET <dataset-descriptor>]
               [NOKEYS] [MAX <n>] [NOMSG]
               [LRECL <n>]
               [       V ]

     The first file-descriptor is the name  of  the  data  description
     file  (DMD).   It will also be the name of the dataset unless the
     SET option is used on the command line or in the DMD.

     The DATA clause specifies  the  input  data  file.   This  clause
     overrides the DATA (formerly the INPUT) loading option in the DMD
     file.
ODDS AND ENDS                                                 Page 2-6


     The SET clause specifies the output file.  This clause  overrides
     the SET (formerly the OUTPUT) loading option in the DMD file.

     The LRECL clause has the same effect as the LRECL clause that may
     be  included  in  the  DMD.  The V is for variable length records
     (the default) and n is the number of characters  per  record  for
     fixed  length  records.   When  LRECL  n  is used all characters,                                                       ___
     including <cr><lf>, are read as data.

     The rest of the command specifications remain unchanged.



     2.7  DATA DESCRIPTION FILE

     The LOADING SECTION of the DMD file has a  new  option,  RECMODE,
     which  specifies  the mode of the input data file.  The format of
     the RECMODE statement is:

          RECMODE [ISAM] ASCII  [ALIGN]
                         SIXBIT

     where ASCII and SIXBIT are the two possible modes.

     ISAM means that an ISAM file is the data file.  An ISAM file  can
     only  be  CREATEd  (see  chapter  5.)  It  can not be LOADed.  If                                                    ___
     neither ASCII nor SIXBIT is specified with the  ISAM  option  the
     System will assume the file is SIXBIT.

     The ALIGN clause of the RECMODE statement is  used  only  by  the
     DUMP  command.   (See chapter 10.) It is ignored by both the LOAD
     and CREATE commands.

     A new option BLOCKED (no abbreviation)  may  be  used  with  ISAM
     datasets  to  describe  the number of records to a logical block.
     For example:

          BLOCKED 40

     specifies that 1 logical block of the data file will  contain  40
     records.   The BLOCKED option may be included on the same line as
     the DATA (formerly INPUT) option.  For example:

          DATA FILE.DMI BLOCKED 128

     specifies that 1 logical block equals 128 records in FILE.DMI.

     The ALLOCATE and ADDCLUSTER statements in  the  data  description
     file  have  no  meaning  for  the TOPS-20 users.  The System will
     print a warning if the ALLOCATE statement is encountered and will
     continue its processing.

     The user can specify a dataset name for his dataset  in  the  SET
     statement.   If  the  SET  statement is not specified and the SET
     clause is not included in the LOAD command the System will assign
ODDS AND ENDS                                                 Page 2-7


     the  dataset  name  to  be the same as the filename.  If the user
     desires many datasets in one file, then both the dataset name and
     file-descriptor must be specified.  For example:

          SET TEST.DMS

     creates the  dataset  named  TEST  in  the  file  TEST.DMS.   Any
     previous copy of the file TEST.DMS is deleted.  Whereas,

          SET PARTS IN TEST.DMS

     creates the dataset named PARTS in the  file  TEST.DMS.   If  the
     file  TEST.DMS  already exists, the dataset PARTS is added to any
     existing datasets in the file.  Should the file TEST.DMS  already
     contain  a  dataset  named  PARTS, it will be replaced by the new
     dataset PARTS;  but the old blocks will not be reused.  Any other
     datasets in the file will not be affected.

     Any  numeric  data  type,  except  dates,  may  be  specified  as
     ADDITIVE.    ADDITIVE  attributes  are  used  with  the  TRANSACT
     command.  When performing transactions the System  will  add  the
     value  of  an  ADDITIVE  attribute in the transaction file to the
     corresponding value in the master file instead  of  changing  the
     value in the master to the value specified.  For example:

          ATTRIBUTE DEPOSIT REAL ADDITIVE LENGTH 6

     defines DEPOSIT as an ADDITIVE attribute.

     Any numeric attribute in a SIXBIT mode file may be  specified  as
     COMP or COMP1.

     The COMP data type is  equivalent  to  INTEGER  except  that  the
     System will expect the binary representation of the value instead
     of the SIXBIT representation.

     The COMP1 data type is equivalent to REAL except that the  System
     will   expect   the   binary   value   instead   of   the  SIXBIT
     representation.
ODDS AND ENDS                                                 Page 2-8


     Note that all COMP and COMP1 attributes must be aligned  on  word
     boundaries and have LENGTH 6.  For example:

          LOADING SECTION

               RECMODE SIXBIT

          STRUCTURE SECTION

               ATTRIBUTE JOB KEYED TEXT LEN 13
               ATTRIBUTE SSN KEYED TEXT LEN 9
               FILLER 2
               ATTRIBUTE SALARY COMP1 LEN 6
               ATTRIBUTE AGE INTEGER RANGE 1 100 LEN 3
               FILLER 3
               ATTRIBUTE BONUS COMP LEN 6



     2.8  DATE FORMATS

     System 1022 accepts a variety of new date formats.  The following
     are all, now, legal dates:

          MAY 26, 1955
          26-MAY-1955
          5/26/55
          550526
          19550526
          052655
          05261955

     Note that centuries need not be included,  and  if  absent,  they
     default to the twentieth century.  Also note that multiple spaces
     are not significant within dates, and that  the  delimiters  ",",
     ".",  "-",  and  "/"  are  equivalent  so  that  "26-MAY-55"  and
     "26.MAY 55" evaluate to the same date.

     A feature has also been added  to  resolve  ambiguities  in  full
     numeric  dates.   If  the  evaluation  of  a  date  in  the form:
     "YY(YY)MMDD" fails, then  it  will  be  evaluated  in  the  form:
     "MMDDYY(YY)".  If that evaluation fails, then the date is bad.



     2.9  ERROR HANDLING

     Error handling for the LOAD, APPEND, and TRANSACT commands is now
     standardized.   The  System  outputs error messages when input is
     detected which is not of the expected type.  Such errors  include
     invalid  data format, integers out of their specified range, etc.
     The error messages  are  of  two  types:   those  output  to  the
     terminal  (see the User's Manual);  and those written to an error
     log file on the disk.
ODDS AND ENDS                                                 Page 2-9


     The error log file is called name.DME, where  name  is  the  file                                                   ____
     name of the input data file.  The format of the error file is:

          SYSID     COMMENT

     where

     SYSID - is the internal number of the record

     COMMENT - is a 1022 comment of the form:

          !ATTRIBUTE NAME      ERROR TYPE:LOCATOR VALUE

     The possible error types for the LOAD and APPEND commands are:

          LAINVI - invalid input
          LARANG - out of range

     The possible error types for the TRANSACT command are:

          TRINVI - invalid input
          TRRANG - out of range
          TRAPIG - APPLIED IGNORE
          TRUNAP - UNAPPLIED
          TRMDUP - DUPLICATES for the value of the locator in the
                   MASTER file.
          TRTDUP - DUPLICATES for this value of the locator on
                   the TRANSACTION file.

     The format of the error log file allows a FIND command to  easily
     select  all error records as a group for inspection after LOADing
     or APPENDing is done.  The user may  then  CHANGE  the  incorrect
     values to the right ones easily.

     To select all error records, use the command

          FIND SYSID @name.DME

     The user may  also  LOAD  or  CREATE  the  error  file  with  the
     following DMD file:

          ATT IDNUMBER COLUMN 1 11
          ATT ATTRIBUTE_NAME COLUMN 14 38
          ATT ERROR_TYPE COLUMN 40 45
          ATT LOCATOR_VALUE COLUMN 47 70

     When a dataset is LOADed with an LRECL clause, normal line  break
     characters  are  read as data.  Occasionally these characters are
     included with invalid input and must  be  written  on  the  error
     file.   In order to keep this error file in a readable format the
     following substitutions will be made:

          Original character          Its form in the error file

     carriage return/linefeed                <CR><LF>
ODDS AND ENDS                                                Page 2-10


     formfeed                                <FF>
     escape or altmode                       <ES>



     2.10  SYSTEM VARIABLES

     Several new system variables have been added.

     SYSJOBNO contains the integer representation of  the  user's  job
     number.

     SYSADDMSG controls prompting  on  the  stand-alone  ADD  command.
     Normally,  the  System prompts for a stand-alone ADD command with
     attribute abbreviations (if they exist).  If the user issues  the
     command:

          "LET SYSADDMSG 1"

     the System will prompt with the full attribute name.

     SYSTIME contains the time of day at which the last command prompt
     was given.

     SYSDAYTIME is similar to SYSTIME except that it is  updated  when
     referenced.  This is most useful in DPL programs or REPORTs since
     long periods may elapse between command prompts.

     SYSMSTIME, an integer, contains the number of milliseconds  since
     midnight.  It is updated when referenced as with SYSDAYTIME.

     SYSRESET, an integer, may be set by the user to  control  logical
     opens  and  closes.   System  1022  keeps buffered information in
     core.  The logical opens and closes ensusre that the buffers  get
     refreshed   and  flushed.   SYSRESET  may  be  used  to  minimize
     conflicts between retrieval and updating.  A  value  of  1  means
     that 1022 will do a logical open each time a dataset is accessed,
     thereby ensuring that the most current information is  read  from
     disk  each  time rather than being buffered in core.  If the user
     has set UPDATE ON then SYSRESET may have a value of 2 which  will
     do  a logical open on access and, at the end of the command, will
     also do a  logical  close,  thereby  ensuring  that  other  users
     accessing   the  dataset  are  able  to  read  the  most  current
     information from the dataset.  The default value of  SYSRESET  is
     0.

     SYSLINE and SYSPAGE have been enhanced to reference  any  one  of
     the 8 System output channels.  The format of these variables is:

          SYSLINE(n)      and     SYSPAGE(n)

     where n is a channel number 1 through 8.  The old form  of  these
     variables  is  still  valid  and refers to channel 1.  SYSPAGE is
     user assignable, but SYSLINE is not.
ODDS AND ENDS                                                Page 2-11


     SYSPROT20 is a new System variable which may be  set  by  TOPS-20
     users  to control file protection.  It is a 6 character long text
     string which represents a protection code.   This  code  will  be
     used  by  the  LOAD,  CREATE,  DUMP  and  FILE COPY commands.  If
     unspecified, the default protection of  the  connected  directory
     will  be  used.   In  order  to  set SYSPROT20 in a host language
     program the user should call DBSYSV with the number 29.

     SYSEXPTYPE is a new System variable which may be set by the  user
     to  control  expression  type  evaluation.   Its default value is
     zero.

     Zero means that expressions will be  evaluated  the  same  as  in
     V113.   In the expresion 0.0+1/3 the 0.0 forces the expression to
     be evaluated as real and thus it equals .33.

     If the user sets SYSEXPTYPE to 1, expressions  are  evaluated  by
     operator.   In  the  above example division takes precedence over
     addition.   Thus  first  the  1/3  is  evaluated  as  an  integer
     expression  which  equals  0.   Next 0.0+0 is evaluated as a real
     expression which equals 0.0.  Thus when SYSEXPTYPE is  set  to  1
     the expression 0.0+1/3 equals 0.0.  (See also chapter 9.)

     The default value of SYSNRETRY has been changed to  10  from  its
     old value of 0.

     SYSNOSEG is a System variable which may be set  by  the  user  to
     control System segmentation.  (See below.)

     Three variables have been added to allow checking for division by
     zero.   SYSDIV,  which is normally 0, is set to 1 if the previous
     command involved a division by zero.  SYSDIVP is also set to 1 if
     a  command  uses  division  by  zero, but it will remain 1 unless
     reset with a LET command, or until one  leaves  1022.   SYSDIVMSG
     controls  the  printing  of the warning message;  0 (the default)
     has the message print,  while  a  value  of  1  has  the  message
     supressed.

     Similarly, three new variables are available to check  whether  a
     command  caused  an  overflow  condition.  SYSOVF is 0 unless the
     last command caused an overflow, when  it  will  be  1.   SYSOVFP
     reamains  set  at  1 after an overflow condition until reset by a
     LET command, or until one leaves 1022.   SYSOVFMSG  controls  the
     printing  of  the  overflow warning message;  0 (the default) has
     the message print, while a value of 1 has the message supressed.



     2.11  SEGMENTATION

ODDS AND ENDS                                                Page 2-12


     2.11.1  Tops-10 Considerations (standard Dec Monitor)

     The user may regard System 1022 as  consisting  of  a  number  of
     "sections",  which are sometimes called "segments" or "overlays."
     As the System performs tasks for the user, the segments  required
     for  each  particular  task  are  read  into  core.  At any given
     instant, the System has only one segment in core.   This  segment
     contains  the  portion of System 1022 that is required to execute
     the task immediately at hand.

     The advantage of this "segmentation" is that it allows the System
     to  occupy  far  less  core  than would be possible if the entire
     System was required to be  in  core  at  once.   There  are  many
     advantages to a small core size on TOPS-10 systems.  For example,
     smaller jobs usually  get  better  treatment  from  the  monitor,
     making  them  more "responsive" to interactive users.  Some users
     may be unable to even run programs larger than a certain size.

     Segmentation also has its disadvantages.  Frequently, when a  new
     segment  is required, it must be read from the disk, a relatively
     time-consuming process.  In a DPL process, where different  tasks
     may  be  performed in a loop, the cost of segmentation may result
     in considerable performance degradation.  In many of these cases,
     it  would  be  advisable to sacrifice some core space in order to
     reduce segmentation overhead.

     The amount of segmentation occurring in  any  given  process  may
     easily  be seen by typing the monitor command "SET WATCH VERSION"
     before running 1022.  Every segment change will  be  reported  by
     the monitor.

     The impact of segmentation may be estimated  by  typing  CTRL/T's
     during  the  process execution.  A process frequently in I/O wait
     for  an  .EXE  (or  .SHR)  file  is  probably  being  slowed   by
     segmentation.

     Large memory configurations may substantially reduce segmentation
     I/O.  In these cases, idle segments may be permitted to remain in
     core, requiring no I/O for a segment change.                     __



     2.11.2  Tops-20 And Other VM Monitors

     There is probably less reason to segment on VM  systems  than  on
     non-VM systems.  Theoretically, the VM page-fault-handlers should
     handle  large  programs  more  efficiently   than   segmentation.
     Segmentation in general, should be avoided on VM systems.
ODDS AND ENDS                                                Page 2-13


     2.11.3  Sysnoseg

     When the System variable SYSNOSEG equals 0, the System  increases
     segmentation  and  keeps  all segments below 12K of core in size.
     This is the default under TOPS-10.  When SYSNOSEG=1,  the  System
     attempts  to  minimize segmentation by reading in a large segment
     with enough capabilities  to  perform  several  tasks  without  a
     segment change.  This is the default under TOPS-20.



     2.12  FIND COMMAND

     The FIND command  now  allows  CONTAINS  (abbreviated  CT)  as  a
     relational.  This specifies finding text attributes which contain
     as a substring the mentioned  value  rather  than  requiring  the
     whole  attribute  to  match.   Since  CONTAINS  requires that the
     entire key table be  searched,  "SEARCH  CONTAINS"  may  be  more
     efficient in the case of a small subset of ALL records.



     2.13  DELETED RECORDS

     Two functions have been added  to  access  and  activate  deleted
     records.   Although  a  new  form  of  the  FIND  command  allows
     retrieval of  deleted  records,  it  is  recommended  that  users
     UNDELETE records before working with them.



     2.13.1  DFIND Command

     The DFIND command (like FIND)  selects  records,  but  only  from
     among  the deleted records that may exist in a dataset.  The form
     of a DFIND command is identical to that of the FIND command.  For
     example:

          DFIND FIRST_NAME JOHN

     would find all deleted records with the first  name  JOHN.   Once
     deleted records have been located with DFIND, then PRINT, SEARCH,
     GETREC, and SELECT commands operate on this selected  group  just
     as if these were active records in the dataset.

     When working with deleted records, DFIND commands may be  chained
     (e.g.  DFIND LAST OR ...) and may use FILE clauses to reference a
     previous group of deleted records saved with  the  SAVE  command.
     Whenever  the  user switches between FIND and DFIND commands, the
     current selection group is  cleared;   so  a  selected  group  of
     records  is  made  up  entirely of active, or entirely of deleted
     records, and is never intermixed.
ODDS AND ENDS                                                Page 2-14


     2.13.2  UNDELETE Command

     The UNDELETE command re-activates deleted records  selected  with
     DFIND.  It acts only on deleted records, so that it has no effect
     on records retrieved with FIND.  When used on an entire group  of
     records (global mode), all records in the group are UNDELETEd and
     become active again, with  the  result  that  no  records  remain
     currently selected.  When used on a record by record basis (local
     mode using GETREC) each individual record of  the  group  may  be
     independently  UNDELETEd  or  skipped.   Each UNDELETEd record is
     activated and removed from the currently selected group.

     After records have been activated, they must  be  selected  again
     using FIND in order to process them further.  If UNDELETE is used
     by mistake on active records, the active status will  remain  the
     same,  but  they will disappear from the currently selected group
     of records.



     2.13.3  DELETE Of Deleted Records

     If a DELETE command is given by mistake on  a  group  of  already
     deleted  records  (located  with  a  DFIND command) then the only
     effect is to clear the current selection group  of  all  records.
     The records in the group are undamaged and remain deleted.



     2.14  PASSWORDS AND THE OPEN COMMAND

     The OPEN command has been changed for the stand-alone  user  such
     that  when  OPENing a dataset which requires a password, the user
     may omit the password and the System will  prompt  for  it.   The
     password  will  be  accepted  in  noecho  mode  for  full  duplex
     terminals and will be overprinted for half duplex terminals.



     2.15  FILE COMMAND

     The FILE command manipulates  disk  files  from  the  stand-alone
     System.   The  four  options:   COPY, DELETE, RENAME and TYPE are
     described below.  The abbreviation of this command is  FIL.   The
     options may be abbreviated to the first three characters only.

     OPTION:  TYPE

     This command lists a disk  file  on  the  user's  terminal.   The
     format of the command is:

          FILE TYPE <file-descriptor>
ODDS AND ENDS                                                Page 2-15


     OPTION:  DELETE

     This command deletes a specified disk file.  The  format  of  the
     command is:

          FILE DELETE <file-descriptor>

     OPTION:  COPY

     This command copies a disk file.  The command has  the  following
     format:

          FILE COPY <file-descriptor-1> [TO] <file-descriptor-2>
               [BUFFERS <n>]
               [BUFS    <n>]

     where:

     <file-descriptor-1>  -  is the source file

     <file-descriptor-2>  -  is the destination file

     BUFFERS <n>  -  is the number of blocks  (or  quarter  pages)  of
     buffer space to be allocated for the file transfer.  It is needed
     to efficiently copy very large files.  If  buffer  space  greater
     than available core is specified, an error message is generated.

     OPTION:  RENAME

     This command renames a disk file.  The command has the  following
     format:

          FILE RENAME <file-descriptor-1> [TO] <file-descriptor-2>

     where:

     <file-descriptor-1>  -  is the source file

     <file-descriptor-2>  -  is the destination file

     Note:  No wildcards ("%","?", or "*") are  allowed  in  the  FILE
     commands.
ODDS AND ENDS                                                Page 2-16


     2.16  PRINT COMMAND

     The PRINT command has a new option, ALL,  which  will  print  the
     value for each attribute of a record.  For example:

          PRINT ALL SYSID

     will print the value of each attribute and sysid for each  record
     in the current selection group.

     The keyword ALL gets replaced with a list of all attribute names.
     A FORMAT statement, therefore, should take this into account.



     2.17  IGNORE DAMAGE COMMAND

     The command, IGNORE DAMAGE, tells the System to ignore  any  file
     damage  in  the currently selected dataset.  File damage messages
     will no longer occur and access and  update  privileges  will  be
     returned  to their normal state.  (See the AUDIT RECOVERY command
     for details about access and  update  privileges  following  file
     damage.)

                         * * * WARNING * * *

          Updating a damaged dataset may cause extensive damage.



     2.18  INFORM COMMAND

     The INFORM command has three new options.



     2.18.1  INFORM DAMAGE

     The command:

          INFORM [ON clause] DAMAGE

     has been added to inform  the  user  if  the  currently  selected
     dataset  is possibly damaged.  File name, time of damage, date of
     damage, and ppn (TOPS-10) or user directory name  (TOPS-20)  from
     which damage was created are reported for each damaged dataset.

     The optional ON clause is the same as for the other forms of  the
     INFORM command.  See the user's manual for more details.

     If you have issued the IGNORE DAMAGE command  the  INFORM  DAMAGE
     will  print  the  information concerning the original damage.  If
     there was subsequent damage the information concerning  the  last
     damage will also be printed.
ODDS AND ENDS                                                Page 2-17


     2.18.2  INFORM AUDIT

     The command:

          INFORM [ON clause] AUDIT

     has been added to tell the user the status of the audit trail for
     the currently selected dataset.



     2.18.3  INFORM STATUS

     The command:

          INFORM [ON clause] STATUS

     produces a report on the status of the  currently  open  dataset.
     The  report  includes  the  name  and  mode  of the data file for
     unbundled datasets, the fact that update is on (if  it  is),  the
     total  number  of  records,  the  number  active  and  the number
     deleted, who was the last  updater,  and  when  the  last  update
     occurred.



     2.19  INIT COMMAND AND SYSTEM OUTPUT CHANNELS

     There are now 8 System output channels.   The  INIT  command  has
     been  enhanced  to  reference  all  8  channels  and to allow the
     keyword APPEND.  When specified in the format:

          INIT APPEND <n> <file-descriptor>

     the file will be opened on software channel  n  in  APPEND  mode,
     i.e.   an existing file will be appended to, not rewritten.  N is
     an integer from 1 to 8.



     2.20  LITERALS

     Quotes (" or ') are now ignored if they don't start a word,  i.e.
     they  must  be  preceeded  by a space, tab, or cr-lf.  This means
     that they are treated as part of the input text.   When  a  quote
     begins  a  word,  then the next appearance of the quote character
     used will terminate that  word,  even  if  directly  followed  by
     another character.  For example:

          "HOW"AGE is now read as word=HOW   word=AGE
ODDS AND ENDS                                                Page 2-18


     2.21  COMMENTS

     An exclamation point (!) preceeded by a space, tab, or cr-lf  now
     marks  the  beginning of a comment.  The exclamation point itself
     and all text to the end of the current  line  are  treated  as  a
     comment  and  are  ignored  in  command processing.  Comments are
     allowed in the stand-alone system, in a DPL segment and in a  DMD
     file.



     2.22  COMMAND FILES AND CONST FUNCTION

     Two new techniques are  available  to  construct  command  files.
     They  are  similar to the @<filename> convention described in the
     user's manual.  The two new conventions are:

          @=<variable-name>   and   @TTY:

     At compile time the  command  scanner  will  convert  the  clause        _______ ____
     @=<variable-name>  into  the  text  contents of the variable name
     given.  The variable must be a text  variable  at  the  time  the
     statement  is  scanned  by the command reader.  The text value of
     the variable will become part of the command as read, as  if  the
     variable  were  a text file in a normal @<filename> construction.
     No spaces are allowed in this construction (i.e.  it  is  written
     as one word).

     The @TTY:  clause will stop for the user to input text that  will
     be  scanned  as  part of the command.  This clause normally reads
     one line of text from the user's terminal ended by a cr-lf.   The
     user may input multiple commands by using the normal line to line
     continuation sequence of "-<cr><lf>" at the  end  of  each  line,
     remembering  that  a space must be used to separate the last word
     of one line from the first word of the next line.

     These two types of indirect text references may be combined  with
     @<filename>  references  and  may  be stacked, in any order, to a
     limit of 10 levels.  Thus, a user could  provide  an  @<filename>
     reference  in  response  to  the  request for input from an @TTY:
     reference.  Also, the contents  of  a  variable  might  have  the
     clause  @TTY:   in  it,  and  this  would correctly reference the
     terminal when the contents of that variable were scanned  by  the
     reference @=<variable>.

     Text insertion is done only at the time  that  the  reference  is
     first  scanned.   In  a  DPL  program or report, the commands are
     determined at compile time and do not change during execution.

     The user is now  able  to  reference  the  value  of  a  variable
     whenever  a constant value was previously required.  This is done
     by specifying:

          CONST(<variable-name>)
ODDS AND ENDS                                                Page 2-19


     Any reasonable conversions will be made to produce a value of the
     required type.  For example

          DEFINE TEXT CONST(TLENGTH) TA(CONST(SYSNREC)).

     will define a text array indexed from 1 to the number of  records
     in  the present selection group where each entry contains TLENGTH
     characters.

     The CONST reference is resolved  at  compile-time  and  therefore                            ________  __  ____________
     will reflect the variable's value at that time.  For example:

          LET I=5.
          DPL START.
          LET I=10.
          PRINT CONST(I).

     will print 5.

     Array references are supported by CONST.  When  an  array  is  so
     referenced,  all  subscripts  are  treated  as  if  they too were
     constant references.  For example:

          LET A(1)=1  A(2)=2  I=1.
          DPL START.
          LET I=2.
          PRINT CONST(A(I)).

     will print 1.



     2.23  SOS OR EDIT COMMAND

     The SOS command calls in the SOS text editor from the System  for
     use  on  exterior  disk files.  TOPS-20 users may alternately use
     the equivalent EDIT command.  These commands are similar  to  the
     EDIT  command  on  the  DECSystem-20.   These  commands take on 2
     forms:


     1.  SOS  or  EDIT

         This just calls in the text editor.  A file  name  (either  a
         new one or an existing one) needs to be supplied next.


     2.  SOS (or EDIT) [FILE] <file-descriptor>

         This call combines into one command the 2 steps needed in the
         above  form (SOS command followed by file name.) The reserved
         word FILE is optional.


     In both cases  after  exiting  from  SOS  you  are  automatically
ODDS AND ENDS                                                Page 2-20


     returned to System 1022 command mode.

     Examples:  SOS
                EDIT TEST.DMC (TOPS-20 only)
                SOS FILE TEST.DMC



     2.24  MAP COMMAND

     The MAP command now has a LOGICAL option which specifies how  the
     records  selected  as a result of the MAP are to be combined with
     the previously selected records in the data set to which the  MAP
     is being done.  The format of the command is:

          MAP [LOGICAL <log>] [TO] <dataset-descriptor> [VIA] <attr-1>
               [[TO] <attr-2>]

     where:

     <log>  -  is either AND or OR.  If this  clause  is  omitted  the
     previous selection group has no effect on the result of the MAP.

     The rest of the command remains unchanged.

     For example, consider three data sets, one containing information
     on  parents,  a  second on their children and a third on schools.
     The first two data sets are linked by the Social Security numbers
     of  the  parents, which are stored in attribute SSN in the PARENT
     data set and in attribute PSSN in the CHILD data set.  The SCHOOL
     data  set  is  linked by the Student I.D.  to the CHILD data set.
     In both data sets the Student I.D.   is  contained  in  attribute
     STUNO.   To  find  all of the students in school 523 with parents
     older than 60, we could type:

          *OPEN SCHOOL PARENT CHILD          _
          *FIND SCHOOLID 523          _
          750 RECORDS FOUND          ___ _______ _____
          *MAP TO CHILD VIA STUNO          _
          750 RECORDS FOUND          ___ _______ _____
          *DBSET PARENT          _
          *FIND AGE GT 60          _
          15 RECORDS FOUND          __ _______ _____
          *MAP LOGICAL AND TO CHILD VIA SSN TO PSSN          _
          9 RECORDS FOUND          _ _______ _____



     2.25  TMPFILE COMMAND

     The TMPFILE command has been added  for  TOPS-10  users  who  use
     TMPCORE  for  interprogram  communications.   The  format  of the
     command is:

          TMPFILE <name> <d> <string> <d>
ODDS AND ENDS                                                Page 2-21


     where

     <name>    -  is a 3-character TMPCORE name.

     <d>       -  is any character except space, <cr>, <lf>, or  <tab>
                  to be used as a delimeter.

     <string>  -  is any ASCII string to be placed in TMPCORE.

     The abbreviation of this command is TMP.

     If the string will not fit into TMPCORE, a  file  whose  name  is
     ###nam.TMP  will  be  created  on  disk.   ### is the current job
     number.



     2.26  ADMIT COMMAND

     The ADMIT command has been enhanced to provide a dataset security
     structure  independent of ppn's or user names.  Access rights can
     now be specified according to password.  This  new  specification
     occurs as follows:

          ADMIT CLASS PASSWORD password [access-code] [FOR clause]

     Examples:

          ADMIT CLASS PASSWORD XYZ READONLY

          If  the  user  supplies  the  password  XYZ  he   has   read
          privileges.

          ADMIT CLASS PASSWORD ABC

          If  the  user  supplies  the  password  ABC  he  has  UPDATE
          privileges.

     The rest of the ADMIT command options remain unchanged.  Also  it
     is still possible to use the old format of the command.



     2.27  BACKTO COMMAND

     The command, BACKTO <version-number>,  will  make  the  currently
     selected   dataset   compatible   with   the  requested  version.
     Presently, BACKTO 113 is the only allowable form.  If the dataset
     cannot  be  made compatible, an error message will print.  A DUMP
     and reLOAD is then  the  only  means  to  produce  an  equivalent
     dataset under an earlier version.
ODDS AND ENDS                                                Page 2-22


     2.28  TYPE COMMAND

     The TYPE command has been changed so that is no  longer  requires
     channel 1.  It will still use channel 1 when channel 1 is unused,
     or in use for terminal output.  If channel 1 is  INITed  to  some
     other  device,  TYPE  will  do output independent of any channel.
     When TYPE uses channel 1 by default any page formatting  commands
     set up on channel 1 will be in effect.  If an independent channel
     has to be used, no page formatting will  apply.   TYPE  will  not
     affect  any  page  format  settings,  nor  any  previous  channel
     assignments.



     2.29  NESTED DPL SEGMENTS

     DPL segments may now contain many levels of nested DPL  START  --
     DPL  END pairs.  The range of the DPL segment starts on the first
     DPL START and ends  on  its  matching  DPL  END  statement.   The
     internal  DPL  START and DPL END statements have no effect on the
     operation of the program.  DPL pairs may  also  exist  completely
     inside  or  around a REPORT segment.  These nesting featurs allow
     the user to include any DPL segment inside  another  segment  (by
     USE or @) without removing any DPL START and DPL END statements.



     2.30  VALUES COMMAND

     The VALUES command has a new option and the format of the  output
     the  command generates has been changed.  The new option, COLUMN,
     causes each line of output to have the following format:

          [VALUE <space>] [SYSID <space>] [COUNT <space>] <cr><lf>

     where  SYSID  and  COUNT  are  each  6  characters  long,   right
     justified.   VALUE is the length of the attribute, if it is TEXT,
     or 15 characters long, right  justified,  otherwise.   When  both
     SYSID  and COUNT are specified with COLUMN there will be one line
     for each SYSID.  This line will  contain  the  value  0  for  the
     COUNT.  Following the 0 COUNT lines with the SYSIDs there will be
     a line containing a 0 SYSID and the proper COUNT.

     When SYSID, VALUE, and COUNT are  specified  without  COLUMN  the
     System will print each item on a separate line, but there will no
     longer be a blank line after the count.

     Note:  The output format is always the same whether output is  to
     a terminal or to a disk file.
ODDS AND ENDS                                                Page 2-23


     2.31  INCOMPATIBILITIES

     A few incompatibilities between V113 and V114 have been found.



     2.31.1  Floating Point Conversions

     The input and output conversions of numbers treated  as  REAL  in
     V113  were  found  to  be slightly inaccurate.  Inaccuracies were
     observed in the 5th significant digit.  In V114 this problem  has
     been  rectified.   Significance  now  extends  to the 8th decimal
     place,  the  maximum  permitted   by   the   single   word   REAL
     representation on the DECsystem-10 and -20.

     This may cause certain incompatibilities between versions 113 and
     114  due to external use of an old inaccurate value.  Examination
     of the stored quantity under V114 will disclose its  true  value.
     The external reference to the value should then be corrected.



     2.31.2  Run-on Command Files

     V114 now checks that command  files  end  properly  when  control
     passes back to the user's teletype.  The following two conditions
     will cause an error message:

     1.  The command file ends while in the middle of a literal.  This
         usually happens when a quote character is unpaired.

     2.  The file includes a REPORT START or DPL  START  command,  but
         not the corresponding REPORT END or DPL END command.


     When an error is detected, command processing is  initialized  to
     the * level.  REPORT or DPL mode is cancelled automatically.

     The System will allow the user to enter DPL or REPORT mode at the
     terminal  and invoke files which do not completely end this mode.
     When the command file ends, the user is left  in  DPL  or  REPORT
     mode and must supply a DPL END or REPORT END command to return to
     the * level.
ODDS AND ENDS                                                Page 2-24


     2.31.3  The Formatter

     The formatter has been changed so  that  it  now  uses  only  the
     following special line printer control character:

          Character     Octal ASCII Equivalent

            <lf>               12
            <cr>               15
            <ff>               14

     All actions done by the C1 through C20 format specifications  are
     done  logically  according  to  the body size of the output page.
     When many lines are skipped logically, the character sequence  is
     now  <cr><lf><lf>...<lf>,  i.e.,  n  linefeeds are used to skip n
     lines.  Previously, <cr><lf><cr><lf>...<cr><lf> was generated.

     The T (tab) format now generates an 11 and the C8 (always  go  to
     the next line, regardless) generates a 23.

     Note:  Standard reports not depending  on  special  line  printer
     conventions are unaffected.



     2.32  INTERNAL CHANGES AND ENHANCEMENTS

     The following sections describe a number of internal changes  and
     enhancements.



     2.32.1  Block Allocation

     A change to the block allocation algorithm somewhat  reduces  the
     damage experienced when a dataset is not closed properly.



     2.32.2  The SORT Routines

     Optimizations to the SORT routines increase the speed of  smaller
     sorts by keeping data in core.



     2.32.3  Incremental Optimizer

     The incremental optimizer now  performs  key  table  reformatting
     silently,   without  an  explicit  user  command,  during  update
     operations.  Since this reformatting  is  automatic,  it  should,
     generally  be  unnecessary to use the OPTIMIZE command.  However,
     there is one instance when the OPTIMIZE command may help.  Once a
     value  of  an  attribute is placed into the key table it does not
     get deleted even if no records currently have  that  value.   The
ODDS AND ENDS                                                Page 2-25


     OPTIMIZE  command will remove this value.  Thus, if a dataset has
     several such values, the use  of  the  OPTIMIZE  command  may  be
     indicated.



     2.32.4  Channel Pooling

     "Channel pooling" has been implemented.  All  references  to  the
     same dataset file will be made using the same I/O channel.



     2.32.5  SFDs

     Some of the problems that resulted from  running  1022  with  the
     default  path  set  to  an SFD have been fixed.  It should now be
     possible to use datasets in an SFD by setting  the  default  path
     properly.  Caution is advised here, however, since there are some
     cases that will cause problems:


     1.  Section 8.9 of this document should be  read  thoroughly  for
         restrictions on writing audit trail files into SFD's.


     2.  Two datasets are assumed to be identical if

         a.  They were created by  the  same  LOAD,  CREATE,  or  DUMP
         command.

         b.  They have the same file name and extension, or file type.

         c.  They are in the same UFD.

         The System will be unable to distinguish these datasets  from
         each other.  The logical combination of these datasets in any                                                                   ___
         1022 operations will cause errors.


     3.  The DMS and DMI portions of an UNBUNDLED dataset must  reside
         in the same default path if they are kept in an SFD.


     4.  The command scanner will not parse SFD specifications.




     2.33  EXTENDED LINE LENGTH


     The length  of  System  1022  print  lines  is  extended  to  400
     characters.   You  may  use  the  scroll  format  (S) and the tab
     function (T) within 400 characters;  the only difference is  that
ODDS AND ENDS                                                Page 2-26


     you can scroll and tab further out on a line than before.



     2.34  TRAILING BLANK SUPRESSION ON TELETYPES


     Output that is directed to the user's terminal now  has  trailing
     blanks  supressed.   This  does  not change the appearance of the
     output, nor does it have any effect on PRINTing to  a  file;   it
     only  makes  the  typeout  of  information  faster to a screen or
     terminal.  Blanks are not supressed at the end of  a  line  which
     prints without a <CR><LF>.  For example:

                    TYPE FMT "ENTER AMOUNT:  " $ END
     prints
                    ENTER AMOUNT:bb



     2.35  HOST LANGUAGE INTERFACE


     The  Host  Language  interface  has  several  new  commands   and
     features.


     1.  DBINFO subroutine

         The information returned by the DBINFO  subroutine  has  been
         enhanced   to   reflect   the  new  data  types  allowed  for
         attributes.  The following is returned by FORTRAN  in  INF(8)
         and by COBOL in ATT-TYPE:

              Type of attribute:
         0 INTEGER   5 DISPLAY-7 INTEGER   10 DISPLAY-6 REAL
         1 REAL      6 DISPLAY-7 REAL      11 DISPLAY-6 DATE
         2 TEXT      7 DISPLAY-7 DATE
         3 unused    8 SIXBIT TEXT
         4 DATE      9 DISPLAY-6 INTEGER


     2.  DBOPEN subroutine

         The syntax of the DBOPEN  subroutine  has  been  enhanced  to
         allow  references  to multiple datasets in one file.  The new
         format is:

              in FORTRAN

         CALL DBOPEN(['NOCLOSE',][DS1,'IN',]IDS1[,DS2,'IN'],IDS2...)

              in COBOL

         ENTER MACRO DBOPEN USING ["NOCLOSE",][DS1,"IN",]IDS1
ODDS AND ENDS                                                Page 2-27


              [,DS2,"IN"],IDS2....

         where:

         DSn  -  is a dataset name.  It is a text string  as  used  in
         the stand-alone System.  (See section 2.3 of this document.)

         IDSn  -  is a file-descriptor  as  used  in  the  stand-alone
         System.

         The other options remain unchanged.

         If a file is specified with no dataset name then all datasets
         in the file will be OPENed.  For example:

              CALL DBOPEN('TEST1','IN','TEST','TEST2')
         or
              ENTER MACRO DBOPEN USING "TEST1","IN","TEST","TEST2".

         will OPEN the dataset TEST1 in the file TEST.DMS and it  will
         OPEN all the datasets in the file TEST2.DMS.


     3.  DBMAP subroutine

         The DBMAP subroutine now has a LOGICAL option which simulates
         the LOGICAL option of the MAP command (see section 2.24.) The
         new format is:

              in FORTRAN

         CALL DBMAP(['LOGICAL',LOG,] DSETNO,SATTID [,DATTID])

              in COBOL

         ENTER MACRO DBMAP USING ["LOGICAL",LOG,]
              DSETNO,SATTID [,DATTID].

         where:

         LOG  is either 'AND' or 'OR'.  It specifies how  the  records
              selected  as  a  result  of  this  MAP command are to be
              combined with the previously  selected  records  in  the
              destination  dataset.   If  this  clause  is omitted the
              previous selection group has no effect on the result  of
              the MAP.

         The rest of the command remains unchanged.
ODDS AND ENDS                                                Page 2-28


     4.  DBSYSV subroutine

         Several new system variables can now be referenced by a  call
         to  DBSYSV.   The  following  is  a list of the variables and
         their corresponding numbers:

              Variable            Number              ________            ______

              SYSRESET              23
              SYSDELIM              24
              SYSJOBNO              25
              SYSDAYTIME            26
              SYSHLDISP             27
              SYSHLMODE             28
              SYSPROT20             29














                              CHAPTER 3

                          MULTIPLE DATASETS



     THIS CHAPTER IS A GUIDE TO USING THE MULTIPLE DATASET  CAPACITIES
     OF  SYSTEM 1022.  DETAILED INFORMATION NECESSARY TO CORRECTLY USE
     THESE FEATURES IS CONTAINED IN THE USER'S MANUAL.

     THE USER OPENS MANY DATASETS AT ONCE WHEN THEY WILL BE REFERENCED
     REPEATEDLY.    INFORMATION  IS  MAINTAINED  SEPARATELY  FOR  EACH
     DATASET.  THE MOST COMMON WAY TO OPEN MANY DATASTS IS:

          OPEN PARENT CHILD REMARK

     or a similar command.  This command would connect the  System  to
     all  three  datasets  at  the same time.  Also, many datasets may
     exist in one physical file.  Opening that file will automatically
     open the datasets contained in it.

     At any time, one of the open datasets is the  "current"  dataset.
     The  System  looks at the current dataset first when deciding how
     to interpret a command.  Most commands act only on or within  the
     current dataset.

     The user can discover information about  the  datasets  that  are
     open or current with the following commands:

          INFORM SET   gives the name and set number  of  the  current
                       dataset.

          INFORM BASE  gives  the  names  and  numbers  of  all   open
                       datasets.

     The user  controls  which  dataset  is  current  with  the  DBSET
     command.

          DBSET <n>     causes the nth dataset to be the current one.

          DBSET <name>  causes the named dataset  to  be  the  current
                        one.

     Switching between datasets with DBSET takes virtually no time  or
     system resources;  the datasets are functionally available at the
     same time.
MULTIPLE DATASETS                                             Page 3-2


     Most commands operate on one dataset at  a  time.   Working  with
     many datasets means deriving data from one dataset and then using
     this data to query or modify another one.  Or, it means  deriving
     information  from  many  datasets  for use in a report.  The user
     satisfies the data retrieval requirements of a  job  by  querying
     each dataset and saving intermediate results.

     The mechanics of processing many interrelated datasets  are  made
     easy  by  the independence of the datasets.  The condition of one
     dataset is not changed by any actions or queries in another  one.
     The  user  may  have selected a group of records in dataset A and
     pointed to the third record of that  group.   After  a  DBSET  to
     another  dataset,  and the eventual return to dataset A, the same
     group of records remains selected, with the same pointer  to  the
     third  record  of  the  group.   By  using  the GETREC command to
     sequence through the records, a selected goup of records  in  one
     dataset  may  be  used  to  drive  a loop that investigates other
     datasets for each selected record.  (See the example at  the  end
     of this section.)

     Often, a user wishes to print or  extract  information  from  the
     currently selected records in more than one dataset.  Version 114
     of the System allows PRINT, TYPE, LET, and EVALUATE  commands  to
     directly  reference attributes in datasets other than the current
     one.  This is called an alternate  dataset  reference.   When  an
     attribute  name  is  used  in one of these commands, and does not
     match any attribute in the current dataset, then the  other  open
     datasets  are  searched  in  turn  to find a match.  The matching
     attribute in the other dataset will provide the value.

     This feature does  not  automatically  select  records  in  other
     datasets.  It uses the values of the currently selected record in
     the other dataset.  It  is  of  particular  use  in  cases  where
     auxiliary  datasets  hold  information  keyed to the records of a
     main dataset.  The related record  in  an  auxiliary  dataset  is
     selected  by the user, allowing a PRINT command to reference both
     the original data in the current dataset and the auxiliary data.

     The MAP command automates the process  of  selecting  records  in
     other  datasets  that are related to a current record or group of
     records.  A MAP takes the list of values for a  given  attribute,
     one  value for each record currently selected, and uses this list
     to select matching records in another dataset.  The process  ends
     by  automatically DBSET'ing into that other dataset.  In a common
     case, a MAP is done from just one  record  into  a  dataset  that
     holds  the  text  translations for a numeric field.  Even after a
     DBSET back to the  original  dataset,  the  text  description  is
     available to a PRINT command by alternate dataset reference.

     Programs in DPL work with  multiple  datasets  by  including  the
     needed  DBSET  commands.  All datasets needed in the execution of
     the program  must  be  open  before  the  DPL  START  command  is
     encountered.   Then,  a DBSET command defines the current dataset
     until it is changed by another DBSET or by a  MAP  command.   All
     statements  in the program will be interpreted in accord with the
MULTIPLE DATASETS                                             Page 3-3


     current dataset, and other datasets are treated  as  external  to
     the current one.

     As  an  example  of  multiple  dataset  operation,  consider  the
     following datasets:

     CUST    A dataset of  customer  header  records.   These  records
             contain  the  IDNUM  (customer  id) and other information
             about credit rating and salesman (which will not be  used
             in this example).

     CUSNAM  This dataset holds CNAME (the full customer  name)  which
             is  not  stored in the CUST dataset.  The link to CUST is
             by the IDNUM.

     AMOUNT  Holds one record  for  each  invoice  processed  for  the
             customer   this  year.   The  attribute  of  interest  is
             BILLAMT, which is the total  dollars  for  that  invoice.
             The link to CUST is IDNUM.

     The following sample program shows how the features  of  multiple
     datasets  may  be  used  to access information from all the above
     datasets.  The program uses  the  CUST  dataset  as  a  base  for
     retrieving  each  customer name and calculating the total dollars
     for invoices processed so far this year.
MULTIPLE DATASETS                                             Page 3-4


            OPEN CUST AMOUNT CUSNAM.
            DPL START.

            DBSET CUST.  FIND ALL.   !locate all CUST records
                                     !for processing

     LOOP:  GETREC ENDLP.            !next customer record
            MAP TO AMOUNT VIA IDNUM. !find the associated AMOUNT
                                     !records based on ID NUMBER

            EVALUATE TAMT EQ TOT BILLAMT.
                                     !get the total from the amount
                                     !billed fields we have located
            DBSET CUST.              !back to our customer record
            MAP TO CUSNAM VIA IDNUM.
                                     !use the same record to locate
                                     !the name information record for
                                     !customer from the id number. The
                                     !customer name is in the
                                     !attribute CNAME
            DBSET CUST.              !back to our main dataset

            PRINT IDNUM CNAME TAMT.  !print the customer id number,
                                     !the actual customer name (using
                                     !the alternamte dataset reference
                                     !to the CNAME field in the CUSNAM
                                     !dataset), and the TAMT total
                                     !derived from the AMOUNT records
                                     !associated with that customer.

            GOTO LOOP.               !go for the next record

     ENDLP: PRINT "** LIST DONE **". !end of list banner

            DPL END.


     The GETREC at the label LOOP selects the first  of  the  customer
     records.   Then,  the MAP to AMOUNT finds (in the AMOUNT dataset)
     all the records associated to the one currently selected customer
     record.  The EVALUATE command totals the field BILLAMT and places
     the value into the variable TAMT which  will  be  PRINTed  later.
     The  program  then DBSET's back to CUST so that it can locate the
     customer's actual name, stored in the CUSNAM dataset.  Note  that
     the original customer record has not changed because of the first
     MAP command, so it can be used again.  The MAP to CUSNAM  locates
     the record containing the customer name in attribute CNAME.  This
     value will be used soon by refering to the field directly, taking
     advantage  of  the  alternate  dataset  reference feature.  Next,
     DBSET back to  the  main  dataset,  mostly  for  clarity  in  the
     procedure.  The PRINT of IDNUM, CNAME, and TAMT prints the values
     calculated or located in other datasets, as well  as  IDNUM  from
     the  main  CUST  dataset.   The GOTO LOOP starts the process over
     again for the next customer record selected by the GETREC.   Only
     here  does  the  selected record in CUST change.  When the GETREC
MULTIPLE DATASETS                                             Page 3-5


     runs out of CUST records, the program ends by  printing  a  final
     message.












                              CHAPTER 4

                            APPEND COMMAND



     The APPEND command reads information from a user's data file,  or
     a   System   1022  dataset,  and  adds  records  containing  this
     information  to  the  currently  selected  dataset  (the   master
     dataset.)

     The data may be described to the System in one of  the  following
     ways:

     1.  When a dataset is the source of data, the format  is  already
         described  by the source dataset structure.  When appending a
         dataset, the must already be OPENed and the  desired  records
         selected.

     2.  When a data file is the source  of  data  and  no  additional
         information  is  given,  the  System assumes the data has the
         same description as the master dataset.  The data  should  be
         in  the  same  format  as  used  to LOAD or CREATE the master
         dataset.

     3.  A data file in a format different from  that  of  the  master
         dataset  is  described  by  specifying  a  System  1022  data
         description file (DMD) in the APPEND command.


     In cases 1 and 3 above, the information to be appended  need  not
     have  the  same  description  or  field  ordering  as  the master
     dataset.  The attribute fields in the master dataset  are  filled
     with  data  from  the  fields  of the same full name in the input
     data.  For a complete description of this see  section  2.4,  the
     DESC clause.

     The form of the command is:

          APPEND  DATA <file-descriptor-1>  [DESC <file-descriptor-2>]
                  SET <dataset-descriptor>

               [NOMSG] [LRECL] [FORMFEED] [CORE <n>] [BUFFER <n>]

     where:
APPEND COMMAND                                                Page 4-2


          <file-descriptor-1>   is the name of the DMI file containing
                                the records to be APPENDed.

          <dataset-descriptor>  is the name or number of a  previously
                                OPENed  dataset  file  containing  the
                                records to be APPENDed.

          <file-descriptor-2>   is the name  of  the  DMD  file  which
                                specifies  the  structure  of the DATA
                                file.

          BUFFER <n>            indicates the number of buffers to  be
                                used in I/O.

          CORE <n>              indicates the amount  of  core  to  be
                                used  for  sorting,  if  any keying is
                                necessary.

          NOMSG                 turns off the system APPEND messages.

          FORMFEED              same as LOAD command.

          LRECL                 same as LOAD command.

     In order to APPEND from an ISAM data file, that file  must  first
     be CREATEd and the APPEND command must use the SET option.

     Examples:


     1.  OPEN TEST
         APPEND DATA FOO DESC BAR

         The above command  will  read  FOO.DMI  according  to  format
         specified  in  BAR.DMD  and  APPEND  the  records  in  FOO to
         TEST.DMS.  Attributes in BAR which are not in  TEST  will  be
         ignored.  The APPENDed records will have a null value in each
         field of TEST with no corresponding field in BAR.


     2.  OPEN TEST
         APPEND DATA FOO

         Same as example 1 above except FOO is read according  to  the
         same format as TEST.DMS was loaded.


     3.  OPEN TEST NEW
         FIND SYSID LE 10
         DBSET 2
         APPEND SET 1

         This command appends the first 10 records in TEST to NEW

APPEND COMMAND                                                Page 4-3


     4.  OPEN TEST NEW
         FIND SYSID LE 10
         DBSET 2
         APPEND SET TEST

         This does the same as example 3 above.


     5.  OPEN TEST
         APPEND DATA FOO BUFFER 3 CORE 7

         Uses 3 buffers per channel for I/O and allocates 7k core  for
         the  sorter.   Buffers  and  core may increase efficiency for
         very large production uses.


     6.  OPEN TEST
         APPEND DATA FOO NOMSG FORMFEED IGNORE

         Prints no  systems  message  and  ignores  all  formfeeds  in
         FOO.DMI.


     7.  OPEN TEST
         APPEND DATA FOO LRECL 10 DESC BAR

         The LRECL specified overrides any LRECL specified or computed
         from BAR.DMD.  LRECL is ignored if SET is chosen.



     Defaults are:

          DATA     extension defaults to DMI
          SET      extension defaults to DMS
          BUFFERS  2
          CORE     5
          DESC     same as currently open dataset if not specified.
                   extension defaults to DMD












                              CHAPTER 5

                            CREATE COMMAND



     5.1  CREATE COMMAND

     The CREATE command functions similarly to the LOAD command.   The
     CREATE  command  keeps the data "unbundled" in its original file.
     All other information  is  maintained  in  the  DMS  file.   (See
     section  2.5.)  The LOAD comand "bundles" data records, keys, and
     other information into one dataset.

     Although an unbundled dataset has a different physical  structure
     from  a  bundled one, all System 1022 procedures are the same for
     both.  For example, an OPEN command looks the same whether a user
     is opening a bundled or unbundled dataset.  OPENing the unbundled
     dataset actually opens both the dataset and data file,  but  this
     is transparent to the user.

     The CREATE command does not automatically build keys as the  LOAD
     command  does.   Attributes specified as ACCESS KEYED in the data
     description file become KEYED  INACTIVE  after  creation  of  the
     unbundled  dataset.   An  explicit KEY ALL command can be used to
     generate the keys if desired.

     The format of the command is:

          CREATE DESC <file-descriptor-1>
             [DATA <file-descriptor-2>] [SET <dataset-descriptor>]
             [NOMSG] [LRECL <n>]

     where:

     <file-descriptor-1>   is the name of the DMD file.

     <file-descriptor-2>   is the name of the DMI file.

     <dataset-descriptor>  is the name of the DMS file or the name  of
                           a dataset in a DMS file.

     NOMSG                 suppresses the  printout  of  informational
                           messages normally printed during processing
                           of the CREATE command.
CREATE COMMAND                                                Page 5-2


     <n>                   is the length of a record.  All records  in
                           the  unbundled  data file (DMI) are assumed
                           to be  fixed  length.   If  <cr><lf>'s  are
                           desired  they  should  be  included  in the
                           LRECL count.  If no LRECL count is given in
                           the  command  or  in the DMD, the user must
                           insure  that  all  records   are   properly
                           "filled out" to be the same length.

     The user may update information in the data file of an  unbundled
     dataset  by using commands in System 1022.  When changes are done
     with System  1022,  any  keys  which  have  been  built  will  be
     automatically maintained as well.

     When numeric display fields are updated in the data file, the new
     data  will be written according to the default numeric to display
     conversions.  When records are ADDed or APPENDed, the new records
     will  go  at the end of the data file and will extend its length.
     The form of the new records will  be  compatible  with  the  data
     file, as described in the LOADING SECTION of the data description
     file used in the CREATE command.

     When records are deleted using System 1022,  the  record  in  the
     data  file remains unchanged.  The record is deleted logically to
     the System alone.  If the user wishes to mark records as  deleted
     to  other  program  systems,  the  user should change a tag field
     value to indicate the deletion, before doing the DELETE command.

     Following are some reasons  for  and  against  using  the  CREATE
     command  to  format  data into a dataset, as compared to the LOAD
     command.

     Advantages of the unbundled dataset.

     1.  Fast setup

         The CREATE command does not read through the data file or set
         up  KEY  information, so the setup is immediate regardless of
         the length of  the  data  file.   In  the  ideal  case  of  a
         sequential  report,  the  user can CREATE a dataset using the
         sequential file, and process it with  a  System  1022  report
         procedure.

     2.  Outside data access

         The  data  file  remains  directly   readable   by   standard
         programming languages like FORTRAN and COBOL since no special
         information is stored in the data file by System  1022.   The
         data  file  may  be updated independently of System 1022, but
         problems will arise for 1022 procedures if KEYED  fields  are
         changed without later rebuilding those keys.

CREATE COMMAND                                                Page 5-3


     Disadvantages of the unbundled datasets.

     1.  Data error

         The data file is not processed  by  the  CREATE  command,  so
         errors of misalignment, data type, and range will only appear
         when particular records are accessed.

     2.  More channels

         Each unbundled dataset needs a system I/O channel  to  access
         the  data file.  When there are many datasets in a data base,
         the number of  needed  channels  may  become  more  than  the
         maximum of 13 available.

     3.  Data compaction

         The unbundled dataset can  not  undergo  data  compaction  of
         numeric  items.   The saving in space may be significant, and
         worth the time to LOAD the dataset.

     4.  Data conversion

         Numeric items in an unbundled dataset may be in display form.
         The  System must convert these to binary form for processing,
         which takes some time.  This  is  not  required  for  numeric
         items  in a bundled dataset, where they are already stored in
         binary form.


     Examples:


     1.  CREATE DESC FOO

         This creates FOO in FOO.DMS and assumes all data records  are
         in FOO.DMI


     2.  CREATE DESC FOO DATA INPUT.DMJ

         Makes FOO in FOO.DMS and assumes data is in INPUT.DMJ


     3.  CREATE DESC FOO SET OUTPUT.DMQ

         Creates OUTPUT in OUTPUT.DMQ and assumes input is OUTPUT.DMI.


     4.  CREATE DESC FOO SET OUTPUT IN PARTS.DMS NOMSG

         Creates OUTPUT in PARTS.DMS with the same  structure  as  FOO
         and assumes input is OUTPUT.DMI.  No standard System messages
         will be printed during the processing of this command.
CREATE COMMAND                                                Page 5-4


     Note that if FOO.DMD had a DATA or SET clause, the  specification
     on the command line overrides it.

     If no data file is found when doing a create, a null data file is
     created, and the DMS is set to contain 0 records.

     Users should not CREATE a dataset  with  a  data  file  that  has
     already been CREATEd and updated by 1022.

     The special attributes, INTEGER OF IDENTIFICATION, DATE OF ENTRY,
     and DATE OF CHANGE, will not be reset on a CREATE command.



                                   NOTE

         When an UNBUNDLED dataset is CREATEd the  input  data  is
         not  read.  Therefore the System does not do any range or         ___
         input checking.  Also no  update  command  for  unbundled                               __
         datasets  does  any range checking.  On an ADD and CHANGE
         the System will not allow the final value  of  a  numeric
         attribute   to   contain  a  non-numeric  character.   At
         runtime, if the user tries to ADD  or  CHANGE  a  display
         numeric  (not  COMP  nor COMP1) value to one that has too
         many characters the System will print a warning and use a
         null value instead.





     5.2  RELOCATE DATA COMMAND

     The command, RELOCATE DATA <file-descriptor>, updates the pointer
     in  an  unbundled dataset so that it will reference the specified
     data file after the next OPEN.  This command is useful for moving
     unbundled  datasets.   If  the  specified  file is not found, the
     System will look for it under the default ppn path  or  connected
     directory.












                              CHAPTER 6

                           TRANSACT COMMAND



     The TRANSACT command performs multiple changes and additions to a
     dataset,  using  data supplied by the user.  The transactions are
     processed against the  currently  selected  dataset  (the  master
     dataset).   The  transaction  records  are  supplied  in  another
     dataset, or are read from a data file.

     The transaction records need not have  the  same  format  as  the
     master dataset.  When the transactions are supplied in a dataset,
     the internal dataset description gives the record  format.   When
     the transaction records are supplied in a data file, the user may
     provide a data description file to  specify  the  record  format.
     When  a data file is provided, but no additional description file
     is used, the data file is assumed to have the same  structure  as
     the master dataset.

     Fields in the transacton records are associated to fields in  the
     master  records according to their full names (not abbreviatons).
     Each transaction field will only  modify  its  associated  master
     field.   See  section  2.4  for more information on this matching
     process.

     The  transaction  records  (transactions)  are  applied  to   the
     intended  master  records  (masters)  by  matching  on  the  user
     specified LOCATOR fields.  The locator fields may be used in  the
     following ways:

     1.  In direct access mode (default) each transaction  is  matched
         to   its   intended  master(s)  by  a  FIND  command  in  the
         background.  The locator  attribute  must  be  KEYED  in  the
         master  dataset,  and  only  one  locator  may  be used.  The
         transactions are processed in  transaction  file  order,  but
         neither  the  transaction  nor  the  master  file needs to be
         sorted into any particular order.

     2.  In SORTED mode, the System assumes that both the  master  and
         transaction  files  have  been  sorted on the locator fields.
         More than one locator may be ued, and the locators  need  not
         be  keyed.  When many locator fields are specified, the first
         one is highest in priority, and the  last  one  is  of  least
         priority in the matching.  The user must sort both the master
TRANSACT COMMAND                                              Page 6-2


         and transaction files using all the locators as sort  fields,
         and  by  specifying them in the same hierarchical order.  The
         SORTED mode TRANSACT command  collates  the  transaction  and
         master records against each other using all the locators.

         Contiguous  groups  of  transactions   are   associated   for
         application against matching groups of master records.  There
         may be one or  many  transactions  matched  to  one  or  many
         masters for each distinct set of locator values.

     In direct mode, master records will be located from among all the
     records  in the master dataset.  The selection can not be limited
     to a subset.  In sorted mode, only the set of master records that
     has  been selected and sorted will participate in the transaction
     process.

     When transaction records are supplied in a  data  file,  all  the
     records   will  participate  in  the  TRANSACT  operation.   When
     transactions are supplied in another dataset, the user may select
     (and possibly sort) any subset.

     For the following discussion, assume that each transaction record
     matches exactly one master record.  The details of the discussion
     are not substantially  changed  if  many  masters  are  matached.
     Consider two cases which occur during transaction processing.

     In the first case, a transaction record matches  a  master.   The
     transaction  processor  will  then  carry  out  the  changes  and
     additions to the master record  implied  by  the  values  of  the
     transaction  fields.   This  case  is  call  APPLIED,  since  the
     transaction is applied to an already existing master.  Sometimes,
     the  user  considers this case as an error, i.e.  the transaction
     file is not supposed to contain  any  already  existing  records.
     The  APPLIED clause and its modifiers allow the printing of error
     messages and ignoring any actions.

     In the second  case,  the  transaction  has  no  matching  master
     record.   This  is  the  UNAPPLIED case, and is controlled by the
     UNAPPLIED  clause  and  its   modifiers.    Normally,   unapplied
     transactions  will  be  ignored.   But, the user can direct error
     messages to be printed and that the information in the  unapplied
     transaction  be  used  to  form  a  new  master record (UNAPPLIED
     APPEND).

     There are options for handling cases when many transactions as  a
     group  match  many  masters  as a group.  The SYNC clause directs
     that matching groups are to be  matched  in  parallel.   Matching
     transactions  and  masters  are  paired  off one by one, and each
     transaction affects only its master partner.   Left  over  master
     records  are  ignored;   left  over  transaction  records will be
     handled as UNAPPLIED.

     THE SYNC clause can only be used in sorted mode.  It is  only  in
     sorted  mode  that  transactions  can  be  considered as a group.
     Also, when SYNC is used, the DUPLICATES clauses  (see  below)  do
TRANSACT COMMAND                                              Page 6-3


     not apply.

     The DUPLICATES clauses permit  handling  multiple  matches  in  a
     different way.  DUPLICATES TRANSACT specifies which of a group of
     transactions (with the same locaors) will  be  processed  against
     the matching masters.  Note that transactions are only considered
     in groups when sorted mode is used.

     DUPLICATES MASTER tells which  of  a  group  of  matching  master
     records  will  be  affected by each processed transaction record.
     This can be useful in direct access  mode,  as  well  as  sorted,
     since multiple master records might be selected.

     In each case of  multiple  transactions  with  the  same  locator
     (sorted mode) the options for DUPLICATES TRANSACT are:

          FIRST   Use only the first transaction, skip the others.

          LAST    Use only the last transaction, skip the first ones.

          ALL     Apply all of the transaction records in sequence.

          IGNORE  There should not be  multiple  transactions,  ignore
                  all of them.

     In the  case  that  there  are  multiple  master  records  for  a
     transaction record(s) the options for DUPLICATES MASTER are:

          FIRST   Apply all transactions that match to just the  first
                  master record selected.

          LAST    Apply all transactions that match to just  the  last
                  master record selected.

          ALL     Apply each transaction record in sequence to all  of
                  the  master  records as a group.  Each master record
                  is affected by every matching transaction record.

          IGNORE  A match to many master  records  is  a  mistake,  so
                  ignore all of the matching transaction records.

     The NOCHANGE BLANKS option  allows  complex  transaction  streams
     with one transaction record format.  Transaction fields which are
     all spaces are ignored;  only the fields having content  will  be
     processed  against the master record.  This permists changing any
     subset of a group of fields  by  filling  in  the  fields  to  be
     changed, and leaving the others blank.

     The following differences exist between data files  and  datasets
     when  using  NOCHANGE  BLANKS.  In an ASCII data file, all fields
     are display and may have a blank value.  This blank value will be
     treated  differently  from  a  "0"  value;   the  zero value will
     produce an action, while the blank value will be ignored.

     In a SIXBIT data file, numeric display fields are treated in  the
TRANSACT COMMAND                                              Page 6-4


     same way.  COMP or COMP1 fields will never be treated as having a
     blank value, they can only have a zero value.

     If the transactons come from a System 1022 dataset, the following
     interpretation of a blank value will apply.  Since numeric fields
     can not have a blank value, but only a zero value, the zero value
     will  be treated as it it is a blank value under NOCHANGE BLANKS.
     So, when transacting records from  a  dataset,  both  all  blanks
     values and zero numeric values will be ignored.

     The format of the TRANSACT command is:

          TRANSACT  DATA <file-descriptor>   [DESC <file-descriptor>]
                    SET <dataset-descriptor>

             [SORTED  [SYNC  [MESSAGE] [TTY] ] ]

             LOCATOR <attname>  [,...,<attname>]

             [NOCHANGE BLANKS]

             [UNAPPLIED [MESSAGE] [TTY] APPEND]
             [                          IGNORE]

             [APPLIED [MESSAGE] [TTY] IGNORE]

             [DUPLICATES TRANSACT  [MESSAGE] [TTY]     FIRST ]
             [                                         LAST  ]
             [                                         ALL   ]
             [                                         IGNORE]

             [DUPLICATES MASTER    [MESSAGE] [TTY]     FIRST ]
             [                                         LAST  ]
             [                                         ALL   ]
             [                                         IGNORE]

             [LRECL]  [NOMSG]  [FORMFEED]  [BUFFERS <n>]  [CORE <n>]


     TRANSACTION file-descriptor:  If SET, may be a dataset number  or
     a dataset file name.  If DATA must be a file name.

     DESC clause:  Optional and used only with the DATA  clause.   The
     file-descriptor  is  the  name of the DMD file that describes the
     structure of the input data file.  (See also section 2.4)

     SORTED:  For large numbers of  transactions,  efficiency  can  be
     obtained  by  sorting  the  TRANSACTION file and then sorting the
     selected records in the MASTER on the same fields.   SORTED  mode
     is  the  only way to use the transaction processor on a subset of
     the MASTER file.  Note:  In order for the sorted options to  work
     predictably the sort order must be unique.

     LOCATOR:   The  transaction  processor  locates  the  appropriate
     MASTER   records  by  comparing  the  LOCATOR  fields(s)  on  the
TRANSACT COMMAND                                              Page 6-5


     transaction record with the locator field on the MASTER records.

     For unsorted transactions only one locator field is  allowed  and
     the locator attribute name must be keyed in the MASTER.                                          _____

     For SORTED transactions multiple locators are  allowed  and  they
     need not be keyed.

     NOCHANGE BLANKS:  Indicates that for each blank TRANSACTION field
     the corresponding MASTER field will not be changed.  (See above.)

     UNAPPLIED:  If a TRANSACTION record has a locator  for  which  no
     MASTER   record  exists,  that  transaction  is  unapplied.   The
     UNAPPLIED APPEND and UNAPPLIED IGNORE  options  indicate  to  the
     System whether to append the UNAPPLIED record or to ignore it.

     DUPLICATES:  The locator fields may select more than one matching
     MASTER  record  for  a  transaction record.  In sorted mode there
     might also be duplicates in the TRANSACTION file.


     FIRST       these clauses indicate which of the duplicates 
     LAST        to use (DUPLICATES TRANSACT) or be changed
     ALL         (DUPLICATES MASTER).
     IGNORE      

     SYNC:  Indicates that duplicates in the  transaction  and  master
     files  are  to  be mapped one to one.  The first duplicate on the
     transaction is performed on the first duplicate  on  the  master.
     The  2nd  duplicate  on  the  transaction is performed on the 2nd
     duplicate on the master, etc.  If one  runs  out,  the  rest  are
     ignored.  This can be used only on sorted files.  When using SYNC
     mode  the  SORTED  option  must  be  used,  but   the   DUPLICATE
     TRANSACT/MASTER mode is not needed.

     APPLIED  IGNORE:   Indicates  that  APPLIED  transactions   (i.e.
     records  whose  locator  appears  in  the  MASTER file) are to be
     ignored and all other transactions (i.e.  the UNAPPLIED ones) are
     to be appended.

     MESSAGE clause:   An  optional  part  of  several  clauses  which
     indicates where to write error messages.

          MESSAGE - write    only    on    the    error    log    file
          (transaction-file.DME).  See also section 2.9.

          TTY - write on the user's terminal only.

          MESSAGE TTY - write on both  the  error  log  file  and  the
          user's terminal.

     LRECL and FORMFEED:  Control aspects of the  input  file  format.
     See the LOADing procedure options section.

     NOMSG:  Suppresses all non-errror messages to the user's terminal
TRANSACT COMMAND                                              Page 6-6


     during the TRANSACT operation.

     BUFFERS <n>:  Indicates the number of buffers to be used in I/O.

     CORE <n>:  Indicates the amount of core to be used for sorting.

     Buffers  and  core  may  increase  efficiency  for   very   large
     production uses.


     The defaults are:

     TRANSACTION file-descriptor - DMI or DMS extension
          is assumed depending on the keyword DATA/SET.
     DESC - DMD extension is assumed
     UNSORTED is assumed
     UNAPPLIED IGNORE
     DUPLICATES MASTER ALL (in unsorted mode)
     DUPLICATES MASTER ALL (in sorted mode)
     DUPLICATES TRANSACTION LAST (in sorted mode)
     Buffers - 2
     Core - 5

     Messages will  not  be  written  unless  the  MESSAGE  clause  is
     included.

     Notes on usage of the TRANSACT command:

     The user must allow  a  large  enough  field  width  for  numeric
     display  attributes.   If  a  transaction on an unbundled dataset
     causes a value to be generated whose length in  ASCII  or  SIXBIT
     characters  is  greater  than  the  field  width  allowed for the
     attribute, the System will truncate the value.

     For display integer attributes,  the  range  of  the  transaction
     value  is  not  checked.  However, for display integer attributes
     which are additive, the range is checked.

     In order to TRANSACT from an ISAM data file, that file must first
     be CREATEd and the TRANSACT command must use the SET option.

     The transaction processor does not preserve the current selection
     group.   After  a  TRANSACT  command, the current selection group
     contains no records.

     ADDITIVE TRANSACTIONS     ________ ____________

     Any attribute of numeric type may be specified as ADDITIVE in the
     DMD  of  the transaction file.  This attribute is then transacted
     by adding its value to the one found in the MASTER  file  record.
     (See  the  description  of  ADDITIVE  in  the  DDL  section.) For
     example:

          If TRA.DMD is
          ATT CUSTIDNO INTEGER LENGTH 6
TRANSACT COMMAND                                              Page 6-7


          ATT DEPOSIT INTEGER LENGTH 6 ADDITIVE

     then for each  CUSTIDNO  in  TRA.DMI,  the  corresponding  master
     CUSTIDNO record will have the DEPOSIT field changed to the sum of
     the current value and the  value  specified  in  the  transaction
     file.


     EXAMPLES:     ________

     1.
     OPEN TEST
     TRANSACT DATA XTRAN DESC XTRAN LOCATOR LN

     This transaction will read from XTRAN.DMI according to  XTRAN.DMD
     and  use  LN as a locator for records in TEST.  If DUPS are found
     in TEST then the default DUP MASTER ALL will be applied.

     2.
     OPEN TEST
     F AGE GT 30
     SORT LN FN
     TRANSACT DATA XTRAN DESC XTRAN LOCATOR LN FN SORTED

     This transaction assumes that XTRAN.DMI has been sorted by LN FN.
     If  it  is  unsorted,  some  records  will  be  skipped  as being
     unapplied.  The transaction will be  performed  on  the  selected
     group with the following defaults:
     DUPLICATES MASTER ALL
     DUPLICATES TRANSACT LAST
     UNAPPLIED IGNORE

     3.
     OPEN TEST XTRAN
     DBSET 2
     FIND ALL
     DBSET 1 
     TRANSACT SET XTRAN LOCATOR LN DUPLICATES MASTER FIRST -
        UNAPPLIED MESSAGE APPEND

     This transaction will perform transaction on the first record  if                                                      _____
     duplicates are found in the master for a value of LN.  If a value
     of LN is not found in the master, the record will be added and an
     entry made to the error file.
TRANSACT COMMAND                                              Page 6-8


     4.
     OPEN TEST XTRAN
     DBSET 2
     FIND AGE GT 30
     SORT LN
     DBSET 1
     FIND AGE GT 30
     SORT LN
     TRANSACT SET 2 LOCATOR LN SORT SYNC

     This transaction will perform the first duplicate transaction  on
     the  first  master,  the second transaction on the second master,
     etc.  Note that when using the SET mode the  transaction  records
     may  be  a  subset of the transaction dataset.  Only the selected
     transaction records will be used by the transaction processor.












                              CHAPTER 7

                            DEFINE COMMAND



     The DEFINE command creates variables and  arrays  for  subsequent
     use in commands.  The format of the command is:

          DEFINE <variable-type> <variable> [<variable>...]

     where

     <variable-type>   is the System 1022 data type for  the  variable
                       names to be defined.

     <variable>        is a variable or array name to  be  defined  as
                       this   data  type.   An  array  is  defined  by
                       including the subscript dimensions as  part  of
                       the  variable  name.   Every entry in the array
                       will  have  the  described  data   type.    The
                       variable  name consists of 1 to 10 alphanumeric
                       characters starting with a  letter.   An  array
                       may  have  up to 7 subscripts (dimensions).  An
                       array  subscript  can   have   bounds   between
                       +/- 131,071.

       The variable-types may be chosen from the following:

       INTEGER         A  single  precision  integer.   It  may  store
                       values in the range +/- 34,359,738,368.

       DOUBLE INTEGER  A  double  precision  integer.   It  may  store
                       integer  values  in  the  approximate  range of
                       +/-1.18 * 10**21.

       REAL            A single precision floating  point  value.   It
                       may  store values in the range of +/- 10**(-38)
                       to 10**38, and will store 8 decimal  digits  of
                       precision.   Round  off  errors in calculations
                       and conversions may show up in the 8th digit of
                       precision.

       DATE            A half word integer which  will  store  a  date
                       value between 1-1-1800 and 9-22-2517.
DEFINE COMMAND                                                Page 7-2


       TEXT <length>   Text values of the specified length, which  may
                       store  strings  of  characters  from  the ASCII
                       character set.  The length may be in the  range
                       of 1 to 2**16-1 (65535) characters.

     Examples of DEFINE:

          DEFINE INTEGER I J K IAR(5) JAR(2,5) AAR(3,3,20).

          DEFINE DOUBLE INTEGER DTOT GRPTOT(3,3).

          DEFINE TEXT 10 NAME ADDRESS(3).

          DEFINE TEXT 100 ABSTRACT TEMP1(8).


     Lower Subscript Bounds     _____ _________ ______

     When a single number is given for a subscript  bound,  the  lower
     bound  defaults  to  1.   So IAR(5) will accept subscripts in the
     range of 1 to 5.  To define subscripts with other  lower  bounds,
     replace  any  or  all  subscript  numbers with a pair of the form
     lowbound:highbound.  The array will  then  accept  subscripts  in
     that position which fall in that range.  For example:

          DEFINE INTEGER IAR(-3:5) JAR(-10:-1) AAR(3,0:3,20)


     Multiple Definitions of Type     ________ ___________ __ ____

     More than one type of variable may be defined in a single  DEFINE
     statement.   Each  group  of variables is preceeded by the proper
     variable type keyword(s).  For clarity this may be done  on  many
     lines.  For example:

          DEFINE INTEGER IAR REAL XSUM.

          DEFINE INTEGER JFI JAR
                 REAL    YSUM ZSUM.

     (Note that the commands are ended here by periods.  If the second
     example were typed from the terminal, the user would continue the
     command from line to line with "-".)


     Initial Values and Redefinition      _______ ______ ___ ____________

     DEFINE'd variables and arrays are initialized  at  the  time  the
     DEFINE  is processed.  Integer and real quantities are cleared to
     zero, text is cleared to blanks, and dates are cleared to JAN  1,
     1800 (a zero integer value).

     Once a variable  is  defined,  it  may  not  be  redefined  to  a
     different  data  type,  length, or array structure unless a CLEAR
     command  has  been  issued  (see   the   User's   Manual).    For
DEFINE COMMAND                                                Page 7-3


     convenience, a variable may be named again in a DEFINE command if
     its  definition  does  not  change.   Whenever  a   variable   is
     redefined, it is initialized as described above.












                              CHAPTER 8

                           THE AUDIT TRAIL



     8.1  AUDIT TRAILS

     The AUDIT commands maintain journal files for  a  data  base  and
     permit  the  user  to backup datasets in the event of a system or
     software crash.  These journal files are called Audit Trails.

     An audit trail contains  the  information  needed  to  restore  a
     dataset  to  its  condition  before  an error caused it to become
     damaged.   This  information  is  made  of  "pre-images."   These
     pre-images  can  be  used to selectively restore those areas most
     recently changed.

     To recover from damage the audit system will restore the  dataset
     to  a  safe  condition.   This  is  a condition that is free from
     internal errors and incomplete  updates.   In  automatic  program
     systems,  the  user's  application  must  be coordinated with the
     audit trail.  The user's system must know just what data has  and
     has  not  been  added  to  a  dataset,  so it may proceed after a
     recovery.  The audit system provides and  names  checkpoints  for
     communication between a user program and the audit trail.

     The AUDIT commands provide functions other than the  primary  one
     of  backing  up  a dataset.  When dataset damage is detected, the
     dataset may be interlocked from further use until  the  error  is
     corrected or ignored.  The audit trail provides information about
     when an update was done and which user controlled it.

     The AUDIT commands are  summarized  below.   Then  the  modes  of
     operation  are  discussed and related to the commands.  Following
     this is  the  detailed  description  and  syntax  of  each  AUDIT
     command.   The user will find it helpful to refer to the detailed
     command descriptions when reading about the different  modes  and
     procedures of operation.
THE AUDIT TRAIL                                               Page 8-2


                            AUDIT COMMANDS                            _____ ________


     AUDIT START       Start an  audit  file  for  this  dataset,  and
                       establish the mode of the audit trail.

     AUDIT CLEAR       Turn off the AUTO  mode  of  the  audit  trail,
                       auditing  will  now  be  manual on a job by job
                       basis.

     AUDIT LIST        Print the audit information.

     AUDIT BACKUP      Use the audit trail files to backup  a  dataset
                       to a specified time in the past.

     AUDIT FIX         A simplified AUDIT BACKUP command,  to  do  the
                       most common backup for damaged datasets.

     AUDIT RECOVERY    Set the mode  of  recovery.   Recovery  may  be
                       automatic or manual.  Access to the dataset may
                       be restricted until recovery is completed.

     AUDIT CHECKPOINT  Establish a user controlled checkpoint  in  the
                       dataset  history for possible use in backing up
                       the dataset.

     AUDIT COMMENT     Place a comment into the audit trail.

     AUDIT MERGE       Combine many separate audit files.



     8.2  KINDS OF AUDIT TRAILS

     When constructing an audit system, the  user  must  first  decide
     where  each audit trail will be stored.  At least one audit trail
     will be maintained for each dataset.  These may all  exist  in  a
     single  file,  or  a  unique  file  may be created for each audit
     trail.  In addition, a single audit trail may  be  spread  across
     several  files.   The greater the number of audit files used, the
     less contention there will be for access to each file.   However,
     with  an  increased  number of audit files, the administration of
     the audit system will  be  complicated.   Each  of  the  possible
     storage schemes are explained below.
THE AUDIT TRAIL                                               Page 8-3


     8.2.1  One Dataset To One Audit File

     In the simplest case, the user will direct the  system  to  write
     one  audit  file  for  each  dataset.   When many jobs update the
     dataset, all audit information  goes  to  this  one  file.   When
     backup  is  necessary,  that  file  can  be  used  alone for this
     dataset.  The System closes the audit  file  repeatedly  so  that
     other jobs may have access to it.



     8.2.2  One Dataset To Many Audit Files

     When the user invokes the JOB option of the AUDIT START  command,
     each  job  updating  the dataset will be given its own audit file
     with a name derived from the job number.  This means  that  there
     is  no  contention between jobs for access to the audit file, and
     fewer operations are expended  on  closing  out  the  audit  file
     between updates.  A disadvantage is that many audit files will be
     created, even if only one process at a time updates the  dataset,
     since  that  process will usually have different job numbers each
     time it is run.  When backup is  required,  it  is  necessary  to
     gather together all the audit files created for this dataset.



     8.2.3  Many Datasets For One Audit File

     One file may be specified to record audit trail information  from
     many datasets.  This is usually done where many datasets from one
     data base and are updated together.  In this mode  there  is  the
     maximum  contention  between  users  of the separate datasets for
     access to the audit file.  However, where the many  datasets  are
     opened  together for processing, there is no contention, and only
     one I/O channel is needed to maintain the audit  information  for
     all  the datasets.  If backup is needed, the single audit file is
     run against each dataset in turn.



     8.2.4  Mixtures

     The above modes may be mixed in any application.  It may be  that
     one  dataset,  in  a  multiple  dataset  data  base, deserves JOB
     treatment while all the other datasets use just  one  audit  file
     for  simplicity.   As  long  as  all the audit information can be
     gathered together, a backup can be done.
THE AUDIT TRAIL                                               Page 8-4


     8.3  OPERATION

     The user may select among several types of audit file access  for
     recording  audit trail information.  These will affect the degree
     to which a dataset is tied to an audit file, and  the  efficiency
     of maintaining the file.



     8.3.1  Audit On Demand

     The System opens the audit file only when necessary and closes it
     when  an update is complete.  It anticipates that other jobs need
     access to the file to carry out update actions.

     Audit trail creation and maintenance may be either  automatic  or
     manual.   The  automatic mode is activated by the AUTO keyword in
     the  AUDIT  START  command,  and  is  the  recommended  mode  for
     maintaining  audit  files  with many users.  It remains in effect
     until ended by the AUDIT CLEAR command.

     While in AUTO mode, any job which  opens  the  dataset  makes  an
     entry  into  the  audit file, and all updates are recorded in the
     file, without any special actins by that job.  AUTO assures  that
     all jobs make entries in the audit file, and that the dataset can
     be recovered when necessary.

     When AUTO is not specified, the use of the audit file is  manual.
     In  manual  mode,  each  job must issue an AUDIT START to turn on
     auditing.  Auditing will remain in  effect  for  just  that  run.
     When  the  dataset  is  closed,  the  auditing  ceases.   Because
     auditing is turned on for only this job, other jobs updating  the
     dataset  will  not make entries into the audit file.  Should this
     happen, the audit file is useless and cannot correctly backup the
     dataset.   Audit  trails  in  manual  mode are recommended when a
     single user wishes to protect against error in  a  single  update
     run.



     8.3.2  Audit With Locked Audit File

     When the user gives the LOCKED option in the AUDIT START command,
     the  job  will open the audit file and keep it open for updating.
     This results in less overhead than with audit on demand.

     When a single audit file is used for a dataset, locking the audit
     file  will  lock out other users from all dataset operations.  If
     auditing is in effect for other users (AUTO mode) then they  must
     access  the  audit  file  when  they OPEN the dataset.  When this
     access is denied because one job has LOCKED the audit file,  they
     will  not  be  able  to do the OPEN.  If the mode is manual, then
     other jobs may query  and  even  update  the  dataset,  as  these
     updates  will  happen outside the protection of the audit system,
     and will prevent backing up with the current audit file.
THE AUDIT TRAIL                                               Page 8-5


     When an audit trail is being written into  an  audit  file  along
     with  the audit trails of other datasets, LOCKing one audit trail
     will lock out, in a similar way, all the datasets  writing  their
     audit  trails into that file.  Normally a job will expect to have
     sole access to all the associated datasets, and will LOCK all the
     audit  trails,  when  locking  any one of many audit trails being
     written to one audit file.

     The JOB option is most useful to give the efficiencies of LOCKing
     open  the  audit  trail,  while  allowing  multiple access to the
     dataset.  The JOB option will cause each  job  to  have  its  own
     audit  file for that dataset.  When combined with LOCK, this file
     will be kept open and ready to record update transactions without
     interference  from other users of the dataset.  The LOCK, JOB and
     AUTO options are commonly used together.



     8.3.3  Checkpoints

     A checkpoint is an entry in the audit trail indicating  that  the
     dataset is stable.  It is generated automatically just before the
     system begins an update and it may be generated by request of the
     user  at  any  time.   Between  checkpoints,  the system may have
     updated information in temporary memory that  has  not  yet  been
     written to the dataset.  If the update operation stops abnormally
     (due  to   hardware   or   software   failure)   there   may   be
     inconsistencies in the dataset.

     A continuous update sequence begins when the user  issues  UPDATE
     ON,  and  it  ends at UPDATE OFF (or when the dataset is CLOSED).
     If UPDATE ON - OFF is not used, then each  command  that  updates
     the  dataset  is  a  complete update sequence in itself.  In both
     cases, a checkpoint will be generated just before beiginning  the
     update.

     The AUDIT CHECKPOINT command will write a checkpoint.  It is used
     to  generate  checkpoints inside an UPDATE ON - OFF sequence, and
     to generate checkpoints with user assigned names.   An  automated
     procedure  can generate named checkpoints that are related to the
     data stream used for the updates.  Use  of  AUDIT  CHECKPOINT  is
     more efficient than creating a checkpoint by issuing extra UPDATE
     ON - OFF commands.

     A checkpoint is a state where everything is consistent as far  as
     the  disk  management software is concerned It is not a guarantee
     that the dataset is undamaged  at  that  point.   Errors  in  the
     dataset  that existed at the time the checkpoint was written will
     still be in the dataset.  It may be necessary to backup more than
     one   checkpoint  to  correct  long  standing  errors  that  were
     previously unnoticed.
THE AUDIT TRAIL                                               Page 8-6


     8.4  BACKING UP DATASETS FOR RECOVERY

     The AUDIT RECOVERY command sets up the rules for  the  manual  or
     automatic  recovery  of a dataset.  The AUDIT BACKUP command does
     the actual recovery.  AUDIT FIX is a convenient form of the AUDIT
     BACKUP  command  for  the  most common case of backup to the last
     checkpoint.



     8.4.1  The BACKUP Operation

     The BACKUP procedure uses the audit trail informaton to bring the
     dataset  back  to  its  condition  at  the  time  of  a  previous
     checkpoint.  The  checkpoint  to  attain  is  identified  by  its
     checkpoint  number,  or  the  name  given to the checkpoint in an
     AUDIT CHECKPOINT command, or by its relative  position  from  the
     end  of  the  current  audit trail.  In practice, most backups go
     backward just one  checkpoint  to  erase  damage  from  the  last
     computer or software crash.

     The user is protected from a bad backup operation.  It  might  be
     worse  to start a backup that cannot succeed, than to correct the
     damage by re-keying, or DUMPing and LOADing  a  new  dataset.   A
     backup  would  fail  if the audit file did not contain a complete
     record of  the  transactions  that  occurred  since  the  desired
     checkpoint.   This  might  happen  if  not  all  the  audit files
     pertinent to the dataset  are  not  merged  together  (see  AUDIT
     MERGE), or if the dataset were updated outside the audit system.

     The System protects the user by examining the audit  file  before
     starting  the  physical  backup.   The  System  verifies that all
     entries necessary to do the backup exist in  the  file.   If  any
     entries are missing, an error message is produced and the dataset
     is left unchanged.  After the verification, the  backup  proceeds
     immediately.

     There is a chance that the computer will crash while a backup  is
     in  progress.   This  does not harm anything.  The backup command
     can be repeated any number of times  if  interrupted.   When  the
     backup finally succeeds, the dataset is restored.  However, until
     the backup is finished, the dataset will be in a  highly  damaged
     state.

     Because a backup removes all new  information  from  the  dataset
     since  the  desired  checkpoint,  the user may wish to examine or
     write out any new information from the dataset before  doing  the
     backup.   Damage to a System 1022 dataset is usually concentrated
     in the KEY structures, and does not affect the ability  to  write
     out  the  data  records last changed, it it is possible to locate
     them.
THE AUDIT TRAIL                                               Page 8-7


     8.4.2  Protected Backup -- RETRY

     A simple backup is not reversible, so the user should be  careful
     not  to  back up farther than desired.  The dataset may be backed
     up in many jumps, but going forward in time is impossible.

     A backup done with the RETRY option is reversible, at the cost of
     some  overhead and complication.  With RETRY in force, the backup
     operation itself leaves an audit trail,  which  may  be  used  to
     erase  the backup and return again to the start.  The RETRY audit
     trail uses the current audit machinery, so the user must issue an
     AUDIT  START command with a new file name to hold the RETRY audit
     trail.  Should the user wish to return to the  start  again,  the
     RETRY  audit  trail  is  specified in an AUDIT BACKUP command and
     restores the dataset.

     If the system crashes while doing a  backup  that  is  writing  a
     RETRY  audit  trail,  the  user  should issue another AUDIT START
     specifying the now partially written RETRY  audit  trail.   Then,
     the  same  AUDIT  BACKUP  command may be issued again.  The RETRY
     audit trail will be longer than if the system did not crash,  but
     will retain its ability to restore the dataset to the start.



     8.4.3  AUDIT FIX

     A special case of backing up a dataset  is  done  easily  by  the
     AUDIT  FIX  command.   AUDIT FIX causes the dataset to back up to
     the most recent checkpoint.  It is used just  after  a  crash  to
     establish  the  latest  possible  version of the dataset that was
     consistent.  It is a simple means for any user to invoke a backup
     operation  without  needing  to  remember  much  about  the  more
     complicated AUDIT BACKUP command.

     If the dataset  is  already  at  a  checkpoint,  AUDIT  FIX  does
     nothing.   If  the  user has ignored a damaged situation and does
     additional updates, AUDIT FIX will  not  backup  over  the  later
     checkpoints entered by the additional updates.  An explicit AUDIT
     BACKUP command must be issued in this case.

     When many update users are writing audit  trails  under  the  JOB
     option,  AUDIT  FIX may be issued by any qualified user to backup
     the dataset to the most recent  checkpoint.   This  may  be  done
     without  merging  together  the many audit trails that will exist
     under the JOB  option.   The  proper  individual  audit  file  is
     selected by the System to do the backup.

     Like other backups,  AUDIT  FIX  will  remove  updates  from  the
     dataset  done  since  the  last checkpoint.  Usually this will be
     just the update in progress when the interruption occurred.  With
     multiple  users under the JOB option, the updates removed will be
     the last ones done by the user in control of the dataset  at  the
     moment of the system crash.
THE AUDIT TRAIL                                               Page 8-8


     8.4.4  Administering Backup

     The AUDIT RECOVERY command sets rules to control who can backup a
     damaged  dataset, whether this backup is automatic or manual, and
     what can be done with a damaged dataset before a backup is done.



     8.4.4.1  Who Can Backup A Dataset - Any  user  who   has   global
     update privileges, may issue the AUDIT BACKUP command.  This will
     perform a backup unless the user is  further  restricted  by  the
     current rules of an AUDIT RECOVERY ALLOW clause.

     When a dataset is  undamaged,  any  update  privileged  user  can
     backup a dataset.  Since there is no damaged condition, there can
     be no AUDIT RECOVERY ALLOW interlock (see later).

     When the AUDIT RECOVERY MODE is AUTO,  any  user  may  cause  the
     aotomatic  backup of the dataset.  If the dataset is damaged, the
     next  user  to  open  the  dataset  will  trigger  the  automatic
     recovery,  provided  the  user's  job has write privileges to the
     physical dataset file.



     8.4.4.2  Automatic Or Manual Backup - When  the  AUDIT   RECOVERY
     MODE  is  MANUAL, no backup action is taken the the System when a
     dataset is damaged.  Restrictions given in the ALLOW clause  come
     into   effect.    The  backup  of  the  dataset  is  left  for  a
     knowledgeable user.  MANUAL mode gives the  option  of  examining
     the  state  of  the  dataset  and deciding what to do.  It may be
     desirable to write out information  last  added  to  the  dataset
     before doing a backup which will remove that information.

     The IGNORE DAMAGE command  will  release  the  dataset  from  its
     damaged  state  and  allow  it  to  be  processed  normally.  The
     internal damage (if any) will not be fixed, but the  restrictions
     of  the ALLOW clause will be removed.  This may be useful in rare
     cases where the administrator chooses to continue operating  with
     a  possible  damaged  datset  rather  than backup over the latest
     transactions.

     When the AUDIT RECOVERY MODE is AUTO, then quick recovery of  the
     dataset  is  desired.  A recovery backup will be started when the
     next user OPENs the dataset and has the physical right (under the
     user name or ppn) to modify the dataset file.

     The System will first perform an AUDIT FIX command to restore the
     dataset  to  the last checkpoint.  If the damage is cleared, then
     everything returns to  normal.   If  the  dataset  still  records
     damage  after  the  simple  backup,  the  conditions of the ALLOW
     clause remain in effect and manual intervention in the dataset is
     required.
THE AUDIT TRAIL                                               Page 8-9


     8.4.4.3  Restricting Damaged Dataset - Restrictions on the use of
     a  damaged  dataset  are  set  by  the  ALLOW clause of the AUDIT
     RECOVERY  command.   Access  can  be  unaffected,  restricted  to
     queries  only, or restricted completely.  The restrictions remain
     unchanged until a new  AUDIT  RECOVERY  command  is  given.   The
     restrictions  are  actually  enforced  whenever  the  dataset  is
     damaged.

     The owner of the dataset is always permitted to change the  ALLOW
     restrictions,  so  a  complete  lockout  is impossible.  An ALLOW
     NOTHING clause prevents any action on the data  until  the  owner
     changes  the restrictions or removes the damage condition.  Other
     actions, such as INFORM and OPEN are not locked.



     8.5  RESOURCES USED BY AUDIT

     Maintaining an audit file uses extra resources.   For  the  query
     user  these  are minimal.  When the dataset is OPENed an entry is
     made to the audit file which requires opening the audit file  and
     writing  once to the disk.  The audit file is then released, does
     not occupy an I/O channel and is not accessed again.

     When the audit file is  not  LOCKED  open,  each  update  request
     causes  the  audit  file to be opened and the appropriate entries
     are made.  Then the file is closed,  under  the  assumption  that
     other jobs may need access.

     When an audit file is LOCKED open, the file is opened  once,  and
     remains continuously available to the job.  Some time is saved by
     not re-opening the file many times.   Additional  time  is  saved
     because  the  System  can retain information about the audit file
     that would ordinarily require a disk read after each open.   When
     audit  is  in effect and UPDATE ON is issued for the dataset, the
     audit file is automatically  LOCKED  open  during  the  updating.
     Maintaining  the  audit  files  will  increase the number of disk
     accesses to do update operatons by about 100%.



     8.6  WHEN TO USE AUDIT TRAILS

     Not  all  datasets  require  audit  trails.    The   expense   of
     maintaining  audit  trails  may  be  avoided  by more traditional
     copy-before-update methods.  When massive updating is to be  done
     by  a  program  in  batch  mode, it is more efficient to copy the
     dataset first and run without audit, than to maintain  the  audit
     file.   In  the  event of system failure, the copy is restored as
     the original and the job re-run.

     If the updates will take such a long time that a machine  failure
     might  be  expcted  during the run, the audit trail may be useful
     anyway.  The update procudure must be designed  to  re-start  the
     updating  at known checkpoints in the event of crashes.  This can
THE AUDIT TRAIL                                              Page 8-10


     avoid long re-runs from the beginning.

     When a dataset is large,  audit  trails  eliminate  the  need  to
     re-key,  or  dump a dataset to restore consistency.  The overhead
     of the  audit  trail  is  paid  back  in  not  doing  these  long
     procedures.   When  datasets  are small enough so that DUMPing or
     re-KEYing does not take long (compared with the requirements  for
     dataset uptime), the audit overhead may not be worthwhile.

     For any size dataset, audit trails allow for  immediate  recovery
     after  a  crash.   They  are  always  useful  for  a dataset with
     multiple users having a need to  constantly  query  the  dataset,
     with little down time allowed.



     8.7  DELETING AUDIT FILES

     Audit files will eventually become large, since the  System  does
     not delete information from them.  The user should delete all the
     files that are no longer needed for possible backups.

     There is no danger to the  dataset  from  deleting  audit  files.
     When  an  audit  file is deleted while not being used, it will be
     created, starting at zero length, when  the  next  job  needs  an
     audit  file  again.  If an audit file is in use, the monitor will
     not delete it, and the job will not be affect.

     If the JOB option is in effect, there will be many  audit  files.
     The  user  may  try  to  delete  any of them, even while jobs are
     actively using them.  Again,  if  they  are  in  active  use  the
     monitor  will  not  delete  them,  and the using jobs will not be
     affected.

     The result of audit file deletions is that  the  remaining  audit
     files may lack the informaton to backup the dataset more than one
     checkpoint.  If all audit information is retained  from  a  given
     time, then any checkpoint since that time may be reestablished by
     an AUDIT BACKUP.



     8.8  WRITING THE AUDIT TRAILS

     The FAST mode option of AUDIT START can affect the efficiency  of
     writing  audit  trails  at the expense of some protection.  There
     are differences depending on whether the operating system is  DEC
     10 or DEC 20.

     The following applies to DEC 10 operating systems:

          In normal mode, each audit entry is finished by closing
          the  audit  file.  This insures that the information is
          physically  written  to  the  disk  before  the  System
          continues.  In FAST mode, a monitor function is used to
THE AUDIT TRAIL                                              Page 8-11


          end the entry.  This is more efficient than closing the
          file, but depends on the monitor eventually writing the
          data to the file.  Should the monitor crash  in  a  way
          that  prevents  writing,  the  audit  file  will not be
          correct.

          FAST mode provides protection from user interruption of
          updates  (control  C's),  user software and System 1022
          failures,  and  most  monitor  crashes.   Some  monitor
          crashes will damage the audit trail.  The efficiency of
          FAST  mode  may  be  worth  the  slight   decrease   in
          protection.

     Under the DEC 20 operating system, a similar monitor function  is
     not  availbable.   In  FAST  mode,  even a user's control C would
     cause an incorrect audit file.  FAST mode should not be  used  on
     the DEC 20.



     8.9  AUDIT START


     The AUDIT START command turns on the audit trail.  The format  of
     the command is:

          AUDIT START [FILE <file>] [AUTO] [LOCK] [JOB] [FAST]

     <file>  -  is the file name  for  the  audit  trail.   If  it  is
     omitted  the  file name will be the same as that of the currently
     open dataset with an extension of DML.

     AUTO  -  indicates that whenever the currently  open  dataset  is
     opened  in  the  future  the  audit  trail  will automatically be
     started.  This condition remains  in  effect  until  the  command
     AUDIT CLEAR is issued.  (see below)

     LOCK  -  indicates that the user desires exclusive access to  the
     audit file.  (See section 8.3.2.)

     JOB  -  changes the DML extension to the user's job number.  (See
     sections 8.2.2 and 8.3.2.)

     FAST  -  disables the somewhat time-consuming procedure  employed
     to  ensure  maximum  safety in the event of a system crash.  (See
     section 8.8.)

     The default directory for the AUDIT trail file is the same as the
     directory  for  the dataset file to which it refers.  The default
     directory for this file is not the connected  directory  (DEC-20)                             __ ___ ___ _________  _________  ________
     or  default  path  (DEC-10).  On the DEC-10, audit trails will be     __  _______  ____  ________
     written into the top level of the PPN only and never into an SFD.                                                    _____ ____ __ ___

                                 NOTE
THE AUDIT TRAIL                                              Page 8-12


          Files containing datasets should have the same name and
          directory  during  LIST and BACKUP operations that they
          had when the corresponding  audit  trail  entries  were
          created.

     The specification of an AUDIT AUTO file remains the same  when  a
     dataset  file  is moved to another directory.  The AUTO file will
     still refer to the old directory unless a new  AUDIT  START  AUTO
     command is given.

     The INFORM AUDIT command will display the  status  of  the  audit
     trail for the current dataset.

     Note that if the audit trail does not exist when an  AUDIT  START
     command is given the System will print a warning message and will
     create the appropriate file.

                         * * * WARNING * * *

          When a dataset has been damaged while an audit trail is
          being  generated,  the System may prevent access to the
          dataset.   Refer  to   the   AUDIT   RECOVERY   command
          description below.



     8.10  AUDIT LIST

     The AUDIT LIST command prints the audit file.  The  form  of  the
     command is:

     AUDIT LIST [ALL] [FILE <file1>] [ON <file2>] [SINCE <date time>]

               [                  [   <n>    ]  ]
               [          LAST    [          ]  ]
               [   FROM           [CHECKPOINT]  ]
               [          <check>               ]

     where:

     ALL  -  specifies that the whole trail is to be printed.  If  ALL
     is  not  specified  then only entries pertaining to the currently
     open data set will be printed.

     <file1>  -  is the file name of the audit  file  to  be  printed.
     Omitted  fields  within  the  file  name  will be filled with the
     corresponding fields in DSK:dsname.DML, with  the  following  two
     exceptions.   If the JOB option was specified in AUDIT START, the
     user's job number is inserted as the extension.  If an AUDIT file
     is open, fields are defaulted to those of the AUDIT file.

     <file2>  -  is the file name on which the audit trail  list  will
     be  written.  The default is TTY:.  If the ON clause is used, the
     defaults for any unspecified fields are DSK:dsname.LST.
THE AUDIT TRAIL                                              Page 8-13


     <date time>  -  is a 1022 date/time descriptor.  (See section 2.8
     above and Appendix A).  One or the other or both may be used.  If
     used the list will include only  those  entries  made  after  the
     desired date/time.

     CHECKPOINT  -  the list will begin at the last checkpoint.

     <n>  -  the list will include entries starting at the nth to  the
     end  checkpoint.   Note  that  LAST 1 and LAST CHECKPOINT are the
     same.

     <check>  -  is any checkpoint number or name.  If  specified  the
     list will begin at the named checkpoint.

     If the LAST clause is specified without CHECKPOINT or n, then the
     System will default to LAST 1.



     8.11  AUDIT BACKUP

     The AUDIT BACKUP command backs up a  dataset.   Since  there  are
     several options which determine how far the dataset can be backed
     up, doing an AUDIT LIST first is  advised.   The  format  of  the
     command is:

          AUDIT BACKUP [FILE <file>]

               [                  [   <n>    ]  ]
               [          LAST    [          ]  ]
               [   FROM           [CHECKPOINT]  ]
               [          <check>               ]

               [RETRY] [NOMSG]

     where:

     <file>  -  is the audit trail file name.

     FROM clause  -  is the same as in the AUDIT LIST command above.

     NOMSG  -  disables printing of all  system  messages  during  the
     back  up  except  warnings.   Normally, entries will be listed as
     they are backed over.

     RETRY  -  causes audit trail entries to be made during the backup
     operation, thereby making the backup operation itself reversible.
     (See section 8.4.2.)

     In the case of a single dataset in a  dataset  file,  the  backup
     operation  will  "chop off" or de-allocate any blocks added since
     the backup point.  If multiple  datasets  exist  in  the  dataset
     file,   recovered  blocks  will  not  be  de-allocated,  possibly
     resulting  in  "lost"  blocks  in  the  dataset  file.   If  this
     situation  is  unacceptable,  the  user  must  dump and rekey the
THE AUDIT TRAIL                                              Page 8-14


     entire dataset.

     When an AUDIT BACKUP is done without the FROM option the data set
     will be backed up to a point just prior to the first entry in the
     audit trail, typically, the  first  AUDIT  START  command.   That
     means  that  if  the  AUTO  option had been specified, it will be
     removed, but the audit trail will remain  on.   The  user  should
     reissue an AUDIT START command with the desired options.



     8.12  AUDIT MERGE

     If separate audit files are maintained for the same dataset  they
     must  be  merged  together  before any backing up may be done for
     that dataset.  This can be done with the following command:

          AUDIT MERGE <file1> [FROM] <file2> [<file3> ...]

     where:

     <file1>  -  is the name of the resulting merged audit file.

     <file2>, <file3>, etc.  -  are the names of the audit files being
     merged.

     Note that System generated checkpoint numbers may change after an
     AUDIT MERGE command.

     Although it is not required that all merged audit  files  pertain
     to the same dataset it is so recommended.

     Care should be taken when  BACKing  UP  a  dataset  with  several
     associated  audit  files.  The BACKUP must be done using a single
     audit file containing all audit entries  made  since  the  BACKUP
     checkpoint.   Error  messages  will  result for all missing audit
     trail entries.



     8.13  AUDIT CHECKPOINT

     The AUDIT CHECKPOINT  command  generates  a  checkpoint  for  the
     purpose of later restoring the dataset to its current state.  The
     format of the command is:

          AUDIT CHECKPOINT <check> [FAST]

     where:

     <check>  -  is  the  checkpoint  name,  a  maximum  of  10  ASCII
     characters  not beginning with a digit (0-9).  This name may then
     be used in an AUDIT LIST or AUDIT  BACKUP  command  as  described
     above.
THE AUDIT TRAIL                                              Page 8-15


     FAST  -  indicates a faster checkpointing process  with  possibly
     less reliablity.  (The dataset will not be closed and reopened.)

     Checkpoints are automatically generated whenever the  dataset  is
     opened  for  writing  (i.e.   in a CHANGE or ADD command).  These
     checkpoints are given numbers by the System, which are printed by
     an AUDIT LIST command.

     If the currently open dataset is in UPDATE mode  then  the  audit
     trail  will  not  contain  checkpoints  between the UPDATE ON and
     UPDATE OFF commands.  If  checkpoints  are  desired  during  this
     period the user must explicitly insert them with this command.



     8.14  AUDIT COMMENT

     The AUDIT COMMENT command permits the user to place comments into
     the audit trail.  This command's format is:

          AUDIT COMMENT <delim> <string> <delim>

     where:

     <delim>  -  is any non-blank delimeter character.

     <string>  -  is any sequence of characters (including cr/lf)  not
     containing a delim.



     8.15  AUDIT CLEAR

     The AUDIT CLEAR command turns off the AUTO  option  specified  in
     the AUDIT START.  The command's format is:

          AUDIT CLEAR

     with no options or arguments.  Note that this  command  does  not
     turn  off  the  audit trail.  The only way to do that is to close
     the dataset.



     8.16  AUTOMATIC RECOVERIES

     To promote data integrety, System  1022  provides  facilities  to
     automatically  repair  dataset  damage  and  to  limit  access to
     damaged datasets.  These facilities operate in  conjunction  with
     the   1022  audit  trails.   Treatment  of  damaged  datasets  is
     specified  (by  the  dataset  owner)  using  the  AUDIT  RECOVERY
     command.

     The format of the AUDIT RECOVERY command is:
THE AUDIT TRAIL                                              Page 8-16


                         [     AUTO [RETRY] ] [      QUERIES]
          AUDIT RECOVERY [MODE              ] [ALLOW UPDATES] [NOMSG]
                         [     MANUAL       ] [      NOTHING]

     where:

     AUTO    indicates that the System will automatically  attempt  to
             repair dataset damage via the audit trail that was in use
             when  the  damage   occurred,   when   the   dataset   is
             subsequently OPENed.

     RETRY   if present, instructs the System  to  generate  an  audit
             trail   during   the   automatic   recovery.    The  same
             disadvantages  that  apply  to  the  AUDIT  BACKUP  RETRY
             command  are present here.  The generated audit file will
             be created in the current user's directory as dsname.DAn.
             The  System  will attempt to create dsname.DA0;  however,
             if that file exists, dsname.DA1 will be checked,  and  so
             forth.   If  dsname.DA0  -  dsname.DA9  exist,  the audit
             information  will  be  appended  to   dsname.DA0.    This
             generated  audit  file may be used to undo the effects of
             the automatic recovery, if so desired.

     MANUAL  prevents the System from attempting to automatically  fix
             the dataset in the event of damage.  This is the default.

     NOMSG   is used to suppress informational messages  to  the  user
             when the damaged dataset is OPENed.

     The ALLOW clause specifies the type  of  access  permitted  to  a
     damaged dataset.

     ALLOW NOTHING  prevents  access  of  any  kind  to  the   damaged
                    dataset.

     ALLOW QUERIES  prevents updates of any kind to the dataset.   Any
                    attempt to write to the dataset will fail with the
                    UP1 error (refer  to  appendix  E  in  the  User's
                    Manual).  This is the default.

     ALLOW UPDATES  permits access as if no damage existed.


     If no AUDIT RECOVERY command is given, the default

          AUDIT RECOVERY MODE MANUAL ALLOW QUERIES

     is assumed.
THE AUDIT TRAIL                                              Page 8-17


     Regardless of the specified ALLOW clause, the  dataset  owner  is
     always permitted to 

          A.  OPEN and read the dataset
          B.  Execute the following commands which modify the dataset:

               AUDIT BACKUP...
               AUDIT FIX...
               AUDIT RECOVERY...
               IGNORE DAMAGE



     8.17  AUDIT QUICK FIXES

     If the dataset has been damaged while an  audit  file  was  being
     written, the user may manually return the dataset to its state at
     the last checkpoint in the audit file  by  using  the  AUDIT  FIX
     command  instead  of  an AUDIT BACKUP command.  The format of the
     AUDIT FIX command is:

          AUDIT FIX [RETRY] [NOMSG]

     If the audit file in use when the  dataset  damage  occurred  was
     FOO.DML, this command is identical to

     AUDIT BACKUP FILE FOO.DML FROM LAST CHECKPOINT [RETRY] [NOMSG]

     The name of the audit file in use when dataset damage occurs  may
     be obtained with the INFORM AUDIT command.


                         * * * WARNING * * *

          When using AUDIT FIX to repair a damaged  dataset,  the
          AUDIT  FIX  command  must  be the first write operation                               ____         _____
          performed on the dataset after the damage has occurred.
          Any  other  write  operation  (including  the UPDATE ON
          command) performed before the AUDIT  FIX  command  will
          prevent  AUDIT  FIX from properly restoring the damaged
          dataset.



     8.18  AUDIT LIST ENTRY FORMATS

                          * * *  NOTE  * * *


          The AUDIT LIST command is included to enable  the  user
          to  obtain  a  "dump"  of  the information in the audit
          trail for perusal, perhaps prior  to  an  AUDIT  BACKUP
          operation.   It  is  not  intended to produce formatted
          dataset usage reports.  The host language audit utility
          interface  may  be used for this purpose.  Although the
THE AUDIT TRAIL                                              Page 8-18


          format of the AUDIT LIST output may lend itself to  use
          as   input  to  a  down-stream  processor  (e.g.   TECO
          macros),  this  is  not  recommended  for  "production"
          systems.  Future versions of AUDIT LIST output will not                                                         ____ ___
          necessarily be upward compatible!  Upward compatibility          ___________ __ ______ __________
          is assured by the host language audit utility interface
          only!

     An AUDIT LIST command produces a list of the selected entries  in
     the  audit file.  Each listed entry consists of a one line header
     followed by information for that particular type of  entry.   The
     header line has the following format:

          <cr><lf>
          >hh:mm:ss dd.-mmm-yyyy. jjj. p pn dsh [HL] [WF]<cr><lf>

     where:

     <cr><lf>       is a carriage-return, followed by a linefeed.

     >              is the character ">" used as an indicator  that  a
                    listed entry starts on this line.

     hh:mm:ss       is the time at which the entry was made.

     dd.-mmm-yyyy.  is the date on which the entry was made.

     jjj.           is the job number of the user making the entry.

     p              is the project  number  of  the  user  on  TOPS-10
                    systems;   the  translated project number (usually
                    4) of the user on TOPS-20 systems.

     pn             is the programmer number of the  user  on  TOPS-10
                    systems;  the user's logged-in directory number on
                    TOPS-20 systems.

     dsh            is the dataset handle.  This is a  pair  of  octal
                    numbers that are different for each dataset.

     HL             flags an entry made while 1022 is  being  accessed
                    through the Host Language interface.

     WF             flags the current  dataset  as  opened  in  UPDATE
                    mode.

     This header line is followed by information that depends  on  the
     type  of  entry  being  listed.  With the exception of the header
     line and code 6 entries (which are comments) all lines begin with
     a  space.   This causes the ">" flag character of the header line
     to be the only non-blank character in column 1 on an  audit  file
     listing.   Numbers  appearing  in an audit file listing are octal
     unless they are followed by a decimal point ("."), in which  case
     they  are  decimal.  In some cases, the number may appear in both
     formats.  The second format will appear in parentheses.
THE AUDIT TRAIL                                              Page 8-19


     The first line following the header line begins  with  the  octal
     code  for  the entry being listed.  The entry code is followed by
     the name of the entry and any  additional  information  that  the
     entry contains.



     8.19  SYSTEM DEFINED ENTRIES

     Entry code 4:  Dataset opened     _____ ____ __  _______ ______

         4 Dataset opened with internal name <name>
         File ID: <fid> [RO] [FD] [Previously opened] [with UPDATE ON]
         <filespec>

     <name>              is the internal dataset name.  If STUDENTS IN
                         SCHOOL  were  being  opened,  name  would  be
                         STUDENTS.

     <fid>               is the File ID number.  This is  the  dataset
                         handle of the first dataset in the file.

     RO                  if present, indicates that  the  dataset  was
                         opened for READ ONLY access.

     FD                  if present, indicates that  the  dataset  had
                         possible file damage when opened.

     Previously opened   indicates  that  the  audit  file   was   not
                         automatically  started  when  the dataset was
                         OPENed.  The user  started  the  audit  trail
                         manually  with an AUDIT START command and may
                         have modified the dataset prior  to  starting
                         the audit trail.

     <filespec>          is the file where the dataset resided when it
                         was opened.


     Entry code 5:  Start Audit trails     _____ ____ __  _____ _____ ______

          5 Start Audit Trails FMT:  <fmt>

     <fmt>   is the format version number of  the  audit  trail  file.
             This  should  be  zero  for the current version of System
             1022.

     This entry indicates that a user has begun the  audit  trails  on
     the currently opened dataset.


     Entry code 6:  Comment     _____ ____ __  _______

          6 Comment:
          <text><cr><lf>
THE AUDIT TRAIL                                              Page 8-20


     <text>   is the text of the comment as typed by the  user.   This
              is not formatted in any way, and new lines will start in
              column 1.


     Entry code 11:  End Audit Trails     _____ ____ ___  ___ _____ ______

          11 End Audit Trails for this DS.  

     This entry indicates that the session begun by a  previous  Audit
     start entry (code 5) has been concluded.


     Entry code 13:  Dataset closed     _____ ____ ___  _______ ______

          13 Dataset closed <name>
          File ID:  <fid> [RO] [FD] previously opened [with UPDATE ON]
          <filespec>

     All terms are identical to those present in  the  Dataset  opened
     (code 4) entry.


     Entry code 14:  End write operation     _____ ____ ___  ___ _____ _________

          14 End write operation

     This entry indicates that a previously begun write  operation  on
     the current dataset has terminated.


     Entry code 15:  Begin write operation     _____ ____ ___  _____ _____ _________

     This entry indicates that a write operation  has  been  initiated
     for  the current dataset, i.e.  the System has opened the current
     dataset for write access.  A CHANGE command, for  example,  would
     generate a code 15 entry.

          15 ***CHECKPOINT <scno> ***
          Begin write operation at <b> blocks [, <w> wds in unb.
                                                  dataset]
          [DAMAGED date:  <dd>]
          [DAMAGED time:  <dt>]
          [DAMAGED by ppn:  <dusr>]
          <r> Records = <a> active + <d> deleted, with <l> allocated.
          Last update (<lupd>) was on <updd> at <updt> by <updu>
          [ADMIT criteria]

     <scno>             is the system-generated checkpoint number  for
                        this entry, which may be used as a location in
                        BACKUP or LIST operations.

     <b>                is the size in blocks, where 4 blocks equal  1
                        page,   of  the  file  in  which  the  dataset
                        resides.
THE AUDIT TRAIL                                              Page 8-21


     <w>                is the size in words of the unbundled  dataset
                        file, if one exists.

     <dd>,<dt>,<dusr>   are the damage parameters.  If  the  file  has
                        possible  file damage, the date, time and user
                        number will be displayed.

     <n>                is the number of records in the dataset.

     <a>                is the number of records in the  dataset  that
                        have not been deleted.

     <d>                is the number of deleted records.

     <l>                is  the  number  of  records  that  have  been
                        allocated, though not necessarily used.

     <lupd>             is the number  of  the  last  update.   Update
                        numbers  start  at  zero  and  are incremented
                        whenever the dataset is written into.

     <updd>             is the date of the last update.

     <updt>             is the time of the last update.

     <updu>             is the user number of the last user to  update
                        the dataset.

     ADMIT criteria     will be displayed if security  provisions  are
                        in  force  for the dataset as the result of an
                        ADMIT command.


     Entry code 16:  Checkpoint     _____ ____ ___  __________

          16 ***CHECKPOINT <scno>***
          ***CHECKPOINT <cname>*** DMS file was at <b> blocks
                                        [, <w> wds in unb.  dataset]
          [DAMAGED date:  <dd>]
          [DAMAGED time:  <dt>]
          [DAMAGED by ppn:  <dusr>]
          <n> Records = <a> active + <d> deleted, with <l> allocated.
          Last update (<lupd>) was on <updd> at <updt> by <updu>.
          [ADMIT criteria]

     <cname>   is the name the user gave to this checkpoint.

     All other terms are identical to those used in code 15 entries.


     USER DEFINED ENTRIES     ____ _______ _______

     Entry codes 700-777     _____ _____ _______

     These are entries inserted into the audit file by a  user-written
THE AUDIT TRAIL                                              Page 8-22


     Host  Language  program.   The  information  contained  in  these
     entries is unknown to the System.

          700 User-defined entry.  (<len> words long.)

     <len>   is the number of words in the user-defined entry.


     EXAMPLES OF AUDIT TRAIL ENTRIES     ________ __ _____ _____ _______

     The following are examples of audit file entries:

     1.
         >10:51:46 5.-Oct-1977.  26.  25 2 766277 220070
          5 Start Audit Trails FMT:0.  (0)

     The first line is a header line which occurs in each entry.

     10:51:46  -  is the time the entry was made.
     5.-Oct-1977.  -  is the date.
     26.  -  is the job number
     25 2  -  is the PPN on the DEC-10, the user's logged in directory
     number on the DEC-20.
     766266 2210070  -  is the dataset handle.

     5  -  is the type of audit trail entry, AUDIT START.

     2.
         >10:52:47 5.-Oct-1977.  26.  25 2 766277 220070
          15 ***CHECKPOINT  40.***

     The asterisks (***) indicate a  checkpoint.   40  is  the  System
     generated checkpoint number which can be used in an AUDIT LIST or
     AUDIT BACKUP command.

     3.
         >11:07:22 5.-Oct-1977.  26.  25 2 766277 220070
          6 Comment:
         NOW DO THE UPDATE

     This is an entry resulting from an AUDIT COMMENT command.












                              CHAPTER 9

                  NEW EXPRESSION HANDLING FACILITIES



     9.1  EXPRESSIONS

     System 1022 allows arithmetic expressions in the place of  single
     values  in  most commands.  For example, expressions may be given
     in PRINT lists and in the ADD, CHANGE, and  FIND  commands  among
     others.    An   arithmetic   expression  may  contain  constants,
     literals, attribute names, user and System defined variables (see
     chapter  7),  and  functions (see section 9.5).  These quantities
     are connected by the arithmetic operators to express a  resulting
     value.   Parentheses may be freely used for clarity, or to change
     the order of calculating the expression.  Spaces are  ignored  in
     expressions except for some date expressions (see below).  Spaces
     are not needed around arithmetic operators.  A comma will  always
     separate  one  expression from the next, but usually they are not
     needed;  the end of  an  expression  occurs  when  no  arithmetic
     operator follows.

     The arithmetic operators are:

          * Multiplication
          / Division
          + Addition
          - Subtraction

     Parentheses are used to make separate sub-expressions  which  are
     evaluated  completely  before their values are used in the larger
     expression.  Examples of typical arithmetic expressions are:

          AGE-18
          100.0 + SALARY
          (A+B)/C +(1+AVG)/D

     Expressions are evaluated according to the following rules:

     1.  The data items in an expression are read from left to  right.
     They  are  combined arithmetically as they are read, unless other
     higher  priority  operations  must  be  done  first.   Any   data
     conversions  or  type conversions are done just before an item is
     combined with other items.
NEW EXPRESSION HANDLING FACILITIES                            Page 9-2


     2.  The left-to-right evaluation will be interrupted to first  do
     operations with a high priority.  For example, * (multiplication)
     has  higher  priority  than  +  (addition).   A  group  of  items
     multiplied  together will be evaluated before the result is added
     to an earlier part of the expression.  A  sub-expression  denoted
     by  parentheses  has  the  highest  priority,  and  is completely
     evaluated before its result is combined with  the  values  around
     it.

     The priorities of the operations are:

          ( ...  ) Subexpressions     Highest Priority
            * /    Multiply, Divide   Next lower
            + -    Plus, Minus        Lowest Priority

     For example, the rules  tell  how  the  following  expression  is
     evaluated step by step:

          1)  1+3+5*2*(1+2)  becomes...
          2)  4  +5*2*(1+2)
          3)  4  +10 *(1+2)
          4)  4  +10 *3
          5)  4  +30
          6)  34             as the final answer.

     3.  The user may combine items of many types in  one  expression.
     (In  FORTRAN these are called mixed mode expressions.) The System
     will automatically convert data from one type to another while it
     is evaluating the expression.  These are called type conversions,
     and are necessary to do the  arithmetic.   The  types  themselves
     have  priorities;   INTEGER type has the lowest priority and REAL
     type has the highest.  The table of priorities for all  the  data
     types is:

          REAL                        Highest Priority Type
          DOUBLE PRECISION INTEGER
          INTEGER                     Lowest Priority Type

     When   two   quantities   of   different   types   are   combined
     arithmetically,  the lower priority type item is converted to the
     type of the higher priority type item.  Then, the  arithmetic  is
     performed, yielding a result with the higher priority type.  This
     result type will be used in further computations.

     When an item of high priority type is seen in the left  to  right
     scan,  its  type  sets  the expected data type.  Arithmetic terms
     farther to the right will be converted to this expected data type
     before  arithmetic  combinations  are  done.   For  example,  the
     presence of a REAL quantity early in an expression will cause the
     rest of the expression to be evaluated as REAL.

     3/2 + 1.0   Evaluates to 2.0.  The division is  done  in  integer
                 mode, yielding 1.

     1.0 + 3/2   Evaluates to 2.5.  The division is done in real  mode
NEW EXPRESSION HANDLING FACILITIES                            Page 9-3


                 because it follows a real quantity.

     A   subexpression   set   off   by   parentheses   is   evaluated
     independently;   the  expected  data type starts with the type of
     the first term in the subexpression.

     1.0 + (3/2)   Evaluates to 2.0  (compare  to  just  above).   The
                   subexpression is evaluated independently.

     For example, let I  be  any  integer  quantity  and  R  any  real
     quantity.   If  we keep track of only the resulting data types as
     the expression is evaluated, we get the following sequence:

          1)  R + I/I * (I + I)        This becomes ...
          2)  R + R/R * (I + I)
          3)  R + R   * (I + I)
          4)  R + R   * I
          5)  R + R   * R
          6)  R + R
          7)  R                             ...as the final type.

     See section 2.10 for information on SYSEXPTYPE, a system variable
     which offers FORTRAN compatible mode for expression evaluation.

     4.  An attribute or variable may be a numeric  value  represented
     in  display  form, composed of ASCII or SIXBIT characters.  These
     display numeric quantities may be used in expressions.  When they
     are  evaluated,  the  System  will  first  convert  them to their
     computational form of the same  data  type.   Display  real  will
     become real for computation.  Display integer becomes integer for
     computation.



     9.2  COMPARISON OF EXPRESSIONS

     When an expression is compared to another value,  the  expression
     will be converted to the same type as the value being compared.

     As an example of a comparison, the command

          IF NEWSUM LE 2.0*OLDSUM THEN ...

     would compare the two expressions, and would take the TRUE action
     if  the  integer  value  NEWSUM  is  less  than  or  equal to the
     truncated integer part of 2.0*OLDSUM (a  real  type  value).   In
     comparisons, the second expression is always changed to match the
     type of the first expression.

     The user should be careful about comparing real  expressions  for
     equality.   Real expressions are sensitive to the exact order and
     values of items that make them up.  Minor roundoff error in  real
     arithmetic   (unavoidable   in   the   computer)  may  cause  two
     expressions which are mathematically equal to actually differ  by
     very  small amounts.  This will cause an unequal comparison where
NEW EXPRESSION HANDLING FACILITIES                            Page 9-4


     the user might expect an equal one.  The  user  can  expect  real
     expressions to come close, but not be exact in all cases.



     9.3  STORING EXPRESSIONS

     When the value of an expression is stored  into  a  variable,  or
     used to change an attribute, the value will be converted to match
     the type of the variable or attribute being changed.  Of  special
     interest  is the case where a computational numeric value is used
     to set the value of a display numeric  attribute  (or  variable).
     After  any  type  conversion  is  done,  the  System will use the
     default rules (See_____) to produce a display form of the  value,
     and  will  set  the  attribute to this display result.  A warning
     will be issued and a null value used  if  the  receiving  display
     numeric field is too small.



     9.4  DATE ARITHMETIC

     Date items and constants may be used in  expressions.   (See  the
     User's  Manual.)  The  underlying  value  in  a date variable (or
     attribute) is the integer  number  of  days  past  1/1/1800  that
     represents  that  date.  For example, the date "1/5/1800" has the
     underlying value of 4.

     The user may add and subtract numeric  values  from  dates;   the
     result  is  a  date  which is that number of days sooner or later
     than the starting date.  If two dates are subtracted, the  result
     is  of  type  Integer,  and is the number of days between the two
     dates.  If the user tries to add two dates, the System  gives  an
     error  message,  since  this  gives  an  answer  which is usually
     meaningless.  But, even this can be accomplished by explicit  use
     of the Conversion Functions (See section 9.5.3).

     The following table gives the legal and illegal  combinations  of
     dates  with  other  data  types.   I stands for integer or double
     integer, R for real, and D for date.  When  values  are  combined
     with dates, they are converted to integer first.

     Type   (operations)  Type   Result Type    Comment     ____   ____________  ____   ______ ____    _______

     D      (-)           D      Integer        Interval in Days
     D      (+,-)         I,R    Date           Adjust the Date, 
                                                Real is converted
                                                to Integer first.
     I,R    (+)           D      Date           Adjust the Date.
     ANY    (-,*,/)       D      *Illegal*    
     D      (*,/)         ANY    *Illegal*

     There is a convenience and a restriction when using  DATE  values
     in  the  FIND,  SEARCH,  SELECT,  ADD, and CHANGE commands of the
     System.  The convenience is that any  single  date  need  not  be
NEW EXPRESSION HANDLING FACILITIES                            Page 9-5


     enclosed   in  quotes  in  order  to  be  correctly  read.   This
     simplifies the typing of these query commands.  For example:

          FIND BDATE 5/1/59 OR 5/2/59

     is a valid command without the use  of  quote  marks,  since  the
     System is expecting a DATE.

     The restriction applies to expressions in  these  same  commands.
     when  an  expression  is used instead of just one item, the first
     term of the expression must be followed  by  space  if  it  is  a
     variable  or  attribute name.  All date literals in an expression
     must be quoted.  For example:

          FIND BDATE EQ SYSDATE -1

     The space following SYSDATE is requiried to scan it correctly.

          CHANGE NDATE "1/1/1978"+INTERVAL

     The date constant is placed in quotes when in an expression.

     In all other places in  the  System,  a  date  constant  must  be
     enclosed   in   quotes  to  distinguish  it  from  an  arithmetic
     expression.  For example:

          PRINT "MAY 1,1978"   "5/1/78"

     The enclosing quotes make these valid date constants.



     9.5  SYSTEM FUNCTIONS

     System Functions are provided in System 1022 to perform  commonly
     needed  tasks  and  to  generalize  the handling of quantities in
     expressions.  These function names are reserved words  in  System
     1022.  They are of the following types:

          Totals Functions         Process values from many records to
                                   form  a  total  or quantity that is
                                   derived  from  the  entire   record
                                   group.

          Arithmetic Functions     Perform a complex arithmetic step.

          Conversion Functions     Control data  type  conversion  for
                                   flexibility in handling data.

     The System Function is used by giving the function name  followed
     by  its argument, which may be a general numeric expression.  For
     example:

     TOT SALARY        Totals the salary in a group of records.
NEW EXPRESSION HANDLING FACILITIES                            Page 9-6


     TOT SALARY+BONUS  Totals the sum of SALARY+BONUS in  a  group  of
                       records.

     There are two ways of providing  the  expression  argument  to  a
     System  Function,  a convenient way and a completely general way.
     The  convenient  way  is  illustrated  above;   just  follow  the
     function name with the expression.  The general way is to enclose
     the function argument in parentheses (like FORTRAN);  but this is
     only  needed  where  the  argument  is just part of the following
     expression.

     System Functions may be used  in  a  completely  general  way  in
     forming expressions in System 1022.  The entire function group is
     used in the same way that any variable may be used.

     Examples:

          TOT SALARY+BONUS              These are equivalent
          TOT(SALARY+BONUS)

          TOT (SALARY)/TOT(BONUS)       These are equivalent
          (TOT SALARY)/TOT BONUS

          TOT SALARY*TOT BONUS          These are illegal
          TOT SALARY * (TOT BONUS)

          TOT (SALARY)*TOT BONUS        These are correct
          (TOT SALARY)*(TOT BONUS)



     9.5.1  Totals And Statistics Functions

     The  Totals  Functions  (also  known  as  Record  Functions)  are
     convenient  for  generating a value which depends on many records
     in a  dataset.   Typically  this  will  be  all  records  in  the
     currently  selected  group of records, or all records selected by
     an ON CHANGE command  in  a  report.   These  functions  imply  a
     background   process  in  which  values  from  many  records  are
     collected and evaluated, and are the primary means of  generating
     totals in the System.  They are:  TOT, MEAN, MIN, MAX, and STDEV.

     The full descriptions of the functions are:

     TOT    The sum of the argument expression will be formed over all
            records   in   the  selected  group.   The  expression  is
            evaluated once for each record, and each result  is  added
            into the total which is formed.

            The resulting sum will be of the same type as the type  of
            the  expression.  For instance, if the expression is REAL,
            the total will be of Real  type.   If  the  expression  is
            Integer,  the  total  will  be  Integer.   We say that the
            expression type flows through the function to the result.
NEW EXPRESSION HANDLING FACILITIES                            Page 9-7


            The expression TOT 1 is a simple way  to  count  how  many
            records  are in the group.  The constant expression "1" is
            added into the result once for each record in the group.

     MEAN   The arithmetic mean of the expression is  calculated  over
            the  records  in  the group.  The result will always be of
            type Real, regardless of the argument.  This is  the  same
            as  TOT  (expression)/TOT 1.0.  If there are no records in
            the group, the result is 0.0.

     MIN    The minimum or maximum value of the expression for all the
     MAX    records in the group is generated as the result.  The type
            of  the  argument  flows through to become the type of the
            result.  Only numeric arguments are allowed.

     STDEV  The standard deviation of  the  expression  is  calculated
            from  the  values  that  the  expression  attains  for the
            records in the group.  The standard deviation for a set of
            values is defined by the following formula:

                                     ( V(I) - VMEAN )**2
                 SQRT ( SUM OVER I ( ------------------- ) )
                                           N-1

            where V(I) is the Ith record value in the group, and VMEAN
            is the arithmetic mean of all the values.

            The standard  deviation  is  actually  calculated  by  the
            formula:

                        SUM OVER I ( V(I)**2 ) - N * VMEAN ** 2
                 SQRT ( --------------------------------------- )
                                          N-1

            The result of STDEV is type REAL regardless of the type of
            the  argument.  If there are fewer than two record values,
            the result is set to zero.



     9.5.2  Arithmetic Functions

     The arithmetic function SQRT computes  the  square  root  of  the
     value  of  the expression which is its argument.  If the argument
     is negative, the absolute  value  of  the  argument  is  used  to
     compute the result.  The result is of Real type regardless of the
     type of the argument.
NEW EXPRESSION HANDLING FACILITIES                            Page 9-8


     9.5.3  Conversion Functions

     The conversion functions give the user control over the data type
     conversions which are ordinarily done automatically by the System
     in evaluating expressions.

     The conversion functions take an  expression  of  any  type,  and
     return the converted value of the desired type.  They may be used
     to do unnatural conversions in special situations.  If  the  user
     wants  the  integer  numeric  value of a Date item (the number of
     days since Jan.  1, 1800) this can be recovered as an integer for
     computation  by using INT date-item, in the expression.  The user
     may even do conversions of items which are of type TEXT.

     When such a text field  contains  characters  which  satisfy  the
     requirements  for  a  numeric display constant, then a conversion
     function will extract  the  numeric  value.   If  the  field  has
     illegal  characters or form, then a runtime conversion error will
     result.  The argument to a conversion  function  may  follow  the
     function  name  without being enclosed in parentheses, and may be
     an arithmetic expression, possibly including other conversions.

     The conversion functions are:

     INT   Converts its argument expression  to  type  INTEGER.   Real
           expressions will be truncated and their integer part taken.
           Truncation will be to the integer next closer to 0  if  the
           argument is not already an exact integer.

     REAL  Converts its argument expression to type REAL.

     DINT  Converts its argument expression to  type  DOUBLE  INTEGER.
           This  is  useful  for  generating  large  double  precision
           integer totals from a list of single precision values.   By
           doing  the  total  on    DINT  (expression)   the result is
           double precision.

     Examples:

          INT(1.9)  gives   1
          INT(1.0)          1
          INT-1.0          -1
          INT(-1.5)        -1

          DINT(1.35E+12)    1350000000000

          TOT( DINT(IVAL))  Produces the double precision total of the
                            integer quantity IVAL.












                              CHAPTER 10

                             DUMP COMMAND



     The DUMP command writes information from a dataset directly to  a
     new  dataset  or  datafile.  The information dumped is taken from
     all the records, or any selected subset of  the  records  in  the
     master  dataset.  The new dataset (or datafile) may have the same
     structure as the master, or may be given  a  different  structure
     with a new data description file.  The SORT option in the command
     string will write out the new records  in  any  desired  physical
     order.    The   new   dataset   is  always  created  without  KEY
     information, leaving the option of building  the  KEYS  (see  the
     User's Manual) if this is necessary.

     The format of the DUMP command is:

          DUMP [UNBUNDLED] [SET <dataset-descriptor>]

               [DATA <file-descriptor-1>]

               [DESC <file-descriptor-2>]

               [BUFFER <n>] [SORT[ED] [BY] sort clause]

     where

     UNBUNDLED             means an unbundled dataset will be  created
                           by  the  DUMP.   When UNBUNDLED is used, it
                           must immediately precede the SET option.

     <dataset-descriptor>  gives the name of the dataset which will be
                           written.   If  this  is  an UNBUNDLED DUMP,
                           then this dataset contains only the  System
                           information.

     <file-descriptor-1>   in UNBUNDLED DUMPs,  is  the  name  of  the
                           datafile   which   will  contain  the  data
                           records of the newly created dataset.
DUMP COMMAND                                                 Page 10-2


     <file-descriptor-2>   is the name of the  data  description  file
                           describing  the  structure  of  the dataset
                           and/or datafile being created by the  DUMP.
                           If this clause is omitted, the structure of
                           the dataset being dumped will be  used  for
                           the new dataset.  (See section 2.4.)

     <n>                   is the number of internal disk input/output
                           buffers to be used during the DUMP.  When n
                           is large, say 24, the efficiency  of  large
                           DUMPs  may  be improved.  It is only useful
                           for DUMPing large datasets.

     sort clause           A full SORT command given here will reorder
                           the  physical  records  into  the specified
                           sort order while they are DUMPed to the new
                           dataset.  (See the User's Manual.)


     DEFAULT NAME RULES

     If the entire dataset or  file  descriptor  is  not  given  in  a
     clause,  then the following default extensions or file types will
     be used by the System:

          SET    Extension file type is DMS
          DATA   Extension file type is DMI
          DESC   Extension file type is DMD

     The default value for the BUFFER clause is 2.

     If UNBUNDLED is specified, but no DATA clause is given, a default
     datafile  will  be  created.  The name of this datafile will come
     from the DESC file when one is specified, or  it  will  be  named
     after the SET filename.



     10.1  EXTRACTING RECORDS

     A simple DUMP command writes out all of  the  currently  selected
     records  directly  into a new dataset of only those records.  The
     records are selected by a FIND, SEARCH, or other  command  before
     they  are  DUMPed.  The output dataset has the same structure and
     attribute names as the master dataset being DUMPed.

     The commands that follow do a typical DUMP:

          * OPEN COMPNY
          * FIND DIVISION EQ 6
          322 Recs Found          ___ ____ _____
          * DUMP SET SMDIV

     The dataset SMDIV.DMS is created  out  of  just  the  DIVISION  6
     records.   The  dataset  SMDIV may be OPENed immediately (without
DUMP COMMAND                                                 Page 10-3


     LOADing) and has the same structure as COMPNY, except that no KEY
     tables  are  built during the DUMP.  If KEYS are needed, they are
     built with the KEY command.

     When the SORTED BY clause  is  used,  the  selected  records  are
     sorted  into  order  as they are dumped.  A SORT command could be
     used just before the DUMP, but the sort within the  DUMP  command
     is  faster  than the two separate commands.  The dataset produced
     will have this sorted order as the physical order of the  records
     in  the dataset.  This may allow reports and PRINT requests to be
     done in the future without additional sorting.

     The space occupied  by  deleted  records  in  a  dataset  may  be
     reclaimed  by  selecting  all  records  in the master dataset and
     DUMPing to a new one (possibly sorted).  Next, a KEY ALL  command
     will rebuild the keys for fast retrieval.  Deleted records in the
     master dataset will not be copied, giving a smaller dataset.  The
     new  sort  order  may  provide for more efficient reporting if it
     reduces the need for sorting small selected groups of records.



     10.2  CHANGING THE TYPE OF DATASET

     DUMP can produce an unbundled dataset from a standard one,  or  a
     standard  dataset  from  an unbundled one, or write out data to a
     simple datafile.  This  is  a  simple  case  of  restructuring  a
     dataset (see later).

     The UNBUNDLED  keyword  directs  that  an  unbundled  dataset  be
     written.   (See  the CREATE command for a complete description of
     bundled and unbundled datasets.) The name of the .DMS file  comes
     from  the  SET  clause.  The name of the .DMI file comes from the
     DATA clause, or the name in the DESC clause if no DATA clause  is
     specified.

     In the absence of  a  DESC  clause,  the  format  of  the  output
     datafile or dataset is taken from the master dataset description.
     The field widths for each item become the output field widths  in
     the  datafile.   The data file is written in ASCII or SIXBIT mode
     depending on the description of  the  master.   Conversions  from
     numeric  to  display  numeric  are done automatically to fill the
     output fields.  If numeric data is  too  large  to  be  correctly
     displayed  in  the associated field width, silent truncation or a
     conversion error will occur.

     If the DATA clause is used alone, then just the datafile  portion
     of  the  unbundled  dataset  will  be written under the file name
     given.  This is usually done when data is to be read  by  another
     program system without further action by System 1022.

     Note:  Records may not be DUMPed to an ISAM data file.                        ___
DUMP COMMAND                                                 Page 10-4


     10.3  RESTRUCTURING A DATASET

     A completely new description file may be specified, with the DESC
     clause,  to  control  the  structure  of  the  output  dataset or
     datafile.  Attributes in the master dataset are directed  to  the
     fields  of  the  new description by matching attribute names (not                                                                   ___
     abbreviations).   (See  section  2.4  for  information  on   this
     matching.)

     A common use for restructuring is to  make  room  for  additional
     attributes  in  a dataset.  The old dataset is dumped using a new
     description that contains extra attributes to be filled in later.
     During  the  DUMP,  these  new attributes are given blank or zero
     values.  After building the new  dataset,  the  user  builds  the
     necessary  keys,  and may fill in the new fields with the desired
     data.  The TRANSACT command or another process may be used to  do
     this.



     10.4  EXAMPLES

     1.  DUMP SET NEWSET

         This will produce a new dataset called NEWSET.DMS  consisting
         of the currently selected records in the master dataset.  The
         records are written out with  the  same  description  as  the
         master dataset, and in the order that they appear there.

     2.  DUMP NEWSET

         This is the old style of the DUMP command.  It will  work  in
         Version  114, but is not recommended.  It has the same effect
         as Example 1 above.

     3.  DUMP SET NEWSET DESC NEWDES

         The standard dataset NEWSET.DMS  will  be  written  from  all
         currently selected records, according to the default order of
         the master dataset.  The description file NEWDES.DMD will  be
         used  to  describe  the  structure of NEWSET.DMS.  The effect
         will be as if the extracted information in the master dataset
         had just been LOADed without keys into the dataset NEWSET.DMS
         using the description NEWDES.DMD.

     4.  DUMP SET INFOR1 IN NEWSET DESC NEWDES

         This illustrates that the set and  file  descriptors  may  be
         completely  general.  The dataset being created will be named
         INFOR1 and will reside in the physical file NEWSET.DMS, along
         with any other datasets in that physical file.  If NEWSET.DMS
         does not already exist, it will  be  created  fresh  to  hold
         INFOR1.   This  command is just like that in example 3 except
         for the destination of the new dataset.
DUMP COMMAND                                                 Page 10-5


     5.  DUMP SET NEWSET DESC NEWDES SORTED BY LNAME FNAME

         This is just like example 3, except that a new physical  sort
         order  will  be  imposed  on  the  records of NEWSET.DMS.  We
         assume that LNAME (last name)  and  FNAME  (first  name)  are
         attributes  of  the  master  dataset.  The dataset NEWSET.DMS
         will be ordered by major key LNAME in ascending order, and by
         next  minor key FNAME in ascending order.  (These need not be
         KEYED fields, they are just called sort keys, as is standard.
         See   the   SORT  command  in  the  User's  Manual  for  more
         information.) These fields need  not  appear  in  the  output
         description  of NEWSET;  they control the order for selecting
         the master records to be written out to NEWSET.

     6.  DUMP UNBUNDLED SET NEWSET DESC NEWDES

         The dataset to be created will be an unbundled dataset,  with
         the  System  information residing in a file separate from the
         data records of the dataset.  The System information will  be
         in  file  NEWSET.DMS.   A  datafile will be written in a form
         described by the data description file NEWDES.DMD.  Since the
         datafile  is  not  named,  the  name would come from the DATA
         clause (if any) in NEWDES.DMD.  If that fails,  the  datafile
         name  will  default  to NEWDES.DMI, following the name of the
         data description file.

     7.  DUMP UNBUNDLED SET NEWSET DATA NEWDAT.ABC

         An unbundled dataset will  be  written.   There  is  no  DESC
         clause,  so  the  structure  will  be  the same as the master
         dataset.  The user has specified that  the  dataset  will  be
         called   NEWSET.DMS,   and   the   datafile  will  be  called
         NEWDAT.ABC.

     8.  DUMP DATA DATFIL

         Since no SET or UNBUNDLED clause appears, a dataset will  not
         be  created;  no DMS file will result.  A pure data file will
         be  written  according  to  the  description  of  the  master
         dataset.   A  data  description  file  could  be specified to
         obtain a data file with a different format.  This form of the
         DUMP command is very useful to create data files for transfer
         to other programs or systems.




     10.5  ALIGNING DATA LINES

     The user may wish to create "word  aligned"  datafiles  with  the
     DUMP  command.   This  means  that each line of the datafile will
     occupy an exact number of basic  computer  words  in  the  output
     file.   This is necessary, for example, when a FORTRAN program is
     to read the file as data.  To do this  a  data  description  file
     must be prepared with the clause:
DUMP COMMAND                                                 Page 10-6


          RECMODE ASCII ALIGN

     This clause goes in the Loading Section of the description  file.
     When writing the datafile, the System will add a carriage-return,
     linefeed sequence at the end of each line, and will fill out  the
     line to the next word boundary with nulls.












                              CHAPTER 11

               AUDIT TRAIL - FORTRAN INTERFACE ROUTINES



     The DBAUD routine provides the  ability  to  control  1022  audit
     trails from FORTRAN programs.  In addition to allowing initiation
     of audit trails and checkpoint generation as in the  stand  alone
     system,  DBAUD  makes  it  possible for users to define their own
     audit file entries.


     Starting the AUDIT Trail     ________ ___ _____ _____

     To start the audit trail for the current  dataset,  the  call  to
     DBAUD takes the form:

     CALL DBAUD('START' [,'FILE',file] [,'LOCK'] [,'JOB'] [,'FAST'])

     where the optional keywords and possible defaults are the same as
     those used in the stand alone system's audit start command.


     Entering AUDIT File Checkpoints     ________ _____ ____ ___________

     Checkpoints may be entered into the currently opened  audit  file
     by using the following form of the DBAUD routine:

          CALL DBAUD('CHECK',checkname[,'FAST'])

     which performs the same function as the AUDIT CHECKPOINT command.


     Custom AUDIT Entries     ______ _____ _______

     Audit file entry type codes 700 through 777  octal  (448  through
     511  decimal) are reserved for users.  These entries are inserted
     into the audit trail by a call to DBAUD:

          CALL DBAUD('PLACE',icode,len,entry)

     where:

     icode   is the code (700-777 octal) that the user has assigned to
             this entry.
AUDIT TRAIL - FORTRAN INTERFACE ROUTINES                     Page 11-2


     len     is the length in words of the entry.

     entry   is an array that contains the entry data.

     These entries may later be retrieved from the audit trail through
     the use of the DBAGET subroutine.


     Retrieving AUDIT File Information     __________ _____ ____ ___________

     The DBAxxx family of routines may be used to  access  audit  file
     entries  from  FORTRAN, allowing customized audit file reports as
     well as the retrieval  of  user-defined  entries  (codes  700-777
     octal).


     Initialization for AUDIT Retrievals     ______________ ___ _____ __________

     To initialize the audit file reader, the following call is made:

          CALL DBAINI(filename[,'ALL'])

     filename   is the name of the audit trail file

     'ALL'      indicates that entries for datasets other than the one
                currently opened will be returned.

     Once DBAINI has been called, entries may be  retrieved  from  the
     audit trail with the command:

          CALL DBAGET(LENF,FLAGS,LENE,ENT,EOF)

     LENF    is the length of the FLAGS array.

     FLAGS   will receive information about the entry as follows:

          FLAGS(1)    =entry code

          FLAGS(2)    =entry length in words

          FLAGS(3)    =dataset handle

          FLAGS(4)    =the date and time that the entry  was  made  in
                      universal date-time standard format (TOPS-10) or
                      in internal date and time format (TOPS-20).

          FLAGS(5)    =the ppn (TOPS-10) or logged in directory number
                      (TOPS-20) of the user making the entry.

          FLAGS(6)    =the job number of the user making the entry.

          FLAGS(7)    =the location of the entry.  If the entry  is  a
                      checkpoint,    this   is   the   system-assigned
                      checkpoint number.
AUDIT TRAIL - FORTRAN INTERFACE ROUTINES                     Page 11-3


          FLAGS(8)    =1 if the entry was made through a Host Language
                      program, 0 otherwise.

          FLAGS(9)    =1 if the dataset had UPDATE ON when  the  entry
                      was made, 0 otherwise.

          FLAGS(10)   =1 if this entry is a CHECKPOINT, 0 otherwise.

     LENE    is the length of the ENT array.

     ENT     is the array that will receive the entry from  the  audit
             file.

     EOF     will be zero when the audit file being  read  is  not  at
             end-of-file.   If EOF is non-zero, the file is at the end
             and no FLAGS or entry data are returned.

     If a user defined entry is being returned, its  form  in  ENT  is
     identical  to  its  entry  form when it was PLACED into the audit
     file with DBAUD.

     Additionally, system-defined entries (whose  code  types  are  in
     octal) may be returned.

     Entry type 4:  Dataset opened     _____ ____ __  _______ ______

     ENT(1) - ENT(5)   =the internal dataset name.  If FOOTBALLPLAYERS
                       IN  SPORTS  were  being opened, ENT(1) - ENT(3)
                       would     contain      FOOTBALLPLAYERS      and
                       ENT(4) - ENT(5) would contain blanks.

     ENT(6)            =the file ID, i.e.  the dataset handle  of  the
                       first dataset in the file.

     ENT(7)            =1 if the file was opened for READ ONLY access,
                       0 otherwise.

     ENT(8)            =1 if the file was DAMAGED, 0 otherwise.

     ENT(9)            =1 if the dataset was opened before  the  audit
                       entry  was  written,  0  if  the audit file was
                       opened as the result of  an  AUDIT  START  AUTO
                       command.

     ENT(10)           =1 if UPDATE was ON when the entry was made,  0
                       otherwise.

     ENT(11)           =the directory of the file that was opened.

     ENT(12) - ENT(13) =the file name and file type  or  extension  in
                       ASCII.

     ENT(14) - ENT(15) =the device name in ASCII.
AUDIT TRAIL - FORTRAN INTERFACE ROUTINES                     Page 11-4


     Entry type 5:  Audit Trail Started     _____ ____ __  _____ _____ _______

     ENT(1)   =the format version number  of  the  audit  trail  file.
              This must be 0!                   ____


     Entry type 6:  Comment     _____ ____ __  _______

     ENT(1) - ENT(FLAGS(2))   contains the text of the comment.


     Entry type 11:  End Audit Trails     _____ ____ ___  ___ _____ ______

     No information is returned.


     Entry type 13:  Dataset Closed     _____ ____ ___  _______ ______

     This entry is identical to Entry type 4 (Dataset opened).


     Entry type 14:  End Write Operation     _____ ____ ___  ___ _____ _________

     This entry is generated  whenever  the  dataset  is  closed.   It
     contains no other information.


     Entry type 15:  Begin Write Operation     _____ ____ ___  _____ _____ _________

     This entry may be used as a checkpoint.

     ENT(3)    =size of file in blocks (4 blocks = 1 TOPS-20 page)

     ENT(4)    =size of unbundled dataset in words.

     ENT(5)    =0 or date the file was damaged  in  radix  date  form.
               (See Appendix B.)

     ENT(6)    =0 or time the file was damaged in  milliseconds  since
               midnight.

     ENT(7)    =0 or user number of dataset updater when the file  was
               damaged.

     ENT(8)    =the number of active records in the dataset.

     ENT(9)    =the number of inactive (i.e.  deleted) records in  the
               dataset.

     ENT(10)   =the number of records allocated in the dataset.

     ENT(11)   =the last update  number  for  the  dataset.   This  is
               incremented whenever the dataset is opened for writing.

     ENT(12)   =date of last update in radix date form.
AUDIT TRAIL - FORTRAN INTERFACE ROUTINES                     Page 11-5


     ENT(13)   =time of last update in milliseconds since midnight.

     ENT(14)   =user number of last dataset updater.

     ENT(15)   =1 if the dataset had ADMIT criteria, 0 if the  dataset
               had no ADMIT criteria.


     Entry type 16:  Checkpoint     _____ ____ ___  __________

     This is a checkpoint entry, identical to  Entry  type  15  (Begin
     Write Operation) except that:

     ENT(1) - ENT(2)   =checkpoint name in ASCII.


     Random access Audit trail input     ______ ______ _____ _____ _____

     The DBALOC subroutine may be used to start input at the beginning
     of  the  audit  trail file, or at any checkpoint within the file.
     This may be done with the following call:

          CALL DBALOC(LOCODE,N)

     where:

     LOCODE   is the locator code:

          0 = start of file
          1 = checkpoint number N
          2 = checkpoint name N
          3 = last Nth checkpoint

     N        is a name or integer as indicated by LOCODE

     To start input at checkpoint "HEREGOES", for  example,  the  call
     would be:

          CALL DBALOC (2, 'HEREGOES')

     To start input at the last checkpoint:

          CALL DBALOC(3,1)


     Loading Programs Using DBAxxx Routines     _______ ________ _____ ______ ________

     The DBAxxx family of routines is included in HL1022.REL only, but                                                             ____
     may  be combined with programs searching HR1022.REL by loading as
     follows:

          LOAD FOO.FOR,SYS:HR1022.REL/LIB,SYS:HL1022.REL/LIB

     Note that HR1022 must be searched before searching HL1022.                      ____             ______
AUDIT TRAIL - FORTRAN INTERFACE ROUTINES                     Page 11-6


     Examples     ________

     The following program starts a LOCKed audit trail on the  current
     dataset.  The audit file has an extension (or file type) equal to
     the user's job number.  A checkpoint (named  "STARTUP")  is  then
     placed into the audit trail, and the program continues.

                 CALL DBFOR
                 CALL DBOPEN('PAYROL')
                 CALL DBAUD('START','LOCK','JOB')
                 CALL DBAUD('CHECK','STARTUP')
                 .
                 .
                 .


     The following fragment writes a custom audit entry  whenever  the
     user  runs  the program.  The program accepts the user's name and
     authorization code  in  the  initialization.   These  values  are
     placed in the custom audit entry with code 700 octal.

                 .
                 .
                 .
                 (initialization - accept and verify
                  NAME and AUCODE)
                 .
                 .
                 .
                 CALL DBOPEN('MOOCOW')
                 CALL DBAUD('START','FILE','MOOAUD','LOCK')
                 ENTRY(1)=NAME(1)
                 ENTRY(2)=NAME(2)
                 ENTRY(3)=AUCODE
                 CALL DBAUD('PLACE',"700,3,ENTRY)
                 .
                 .
                 .
AUDIT TRAIL - FORTRAN INTERFACE ROUTINES                     Page 11-7


     Given an application using the previous custom AUDIT  ENTRY,  the
     following program reports all users who have accessed the dataset
     and their authorization codes.

                 DIMENSION ENTRY(3)
                 CALL DBFOR
                 CALL DBAINI('MOOAUD.DML','ALL')
         10      CALL DBAGET(1,FLAG,3,ENTRY,IEND)
                 IF (IEND .NE. 0) GO TO 100
                 IF (FLAG .NE. "700) GO TO 10
                 TYPE 1000,ENTRY
         1000    FORMAT(2A5,10X,I6)
                 GO TO 10
         100     STOP
                 END














                              CHAPTER 12

                AUDIT TRAIL - COBOL INTERFACE ROUTINES



     The DBAUD routine provides the  ability  to  control  1022  audit
     trails  from  COBOL programs.  In addition to allowing initiation
     of audit trails and checkpoint generation, as in the stand  alone
     system,  DBAUD  makes  it  possible for users to define their own
     audit file entries.


     Starting the AUDIT Trail     ________ ___ _____ _____

     To start the audit trail for the current  dataset,  the  call  to
     DBAUD takes the form:

          ENTER MACRO DBAUD USING "START" [,"FILE",file] [,"LOCK"]
               [,"JOB"] [,"FAST"].

     where the optional keywords and possible defaults are the same as
     those used in the stand alone system's audit start command.


     Entering AUDIT File Checkpoints     ________ _____ ____ ___________

     Checkpoints may be entered into the currently opened  audit  file
     by using the following form of the DBAUD routine:

          ENTER MACRO DBAUD USING "CHECK", checkname [,"FAST"].

     which performs the same function as the AUDIT CHECKPOINT command.


     Custom AUDIT Entries     ______ _____ _______

     Audit file entry type codes 700 through 777  octal  (448  through
     511  decimal) are reserved for users.  These entries are inserted
     in the audit trail by a call to DBAUD:

          ENTER MACRO DBAUD USING "PLACE", icode, len, entry.
AUDIT TRAIL - COBOL INTERFACE ROUTINES                       Page 12-2


     where:

     icode  is the code (700-777 octal) that the user has assigned  to
            this entry.

     len    is the length in words of the entry (=(# characters+4)/5).

     entry  is a DISPLAY-7 (X  picture)  variable  that  contains  the
            entry data.

     These entries may later be retrieved from the audit trail through
     the use of the DBAGET subroutine.


     Retrieving AUDIT File Information     __________ _____ ____ ___________

     The DBAxxx family of routines may be used to  access  audit  file
     entries  from  COBOL,  allowing  customized audit file reports as
     well as the retrieval  of  user-defined  entries  (codes  700-777
     octal).


     Initialization for AUDIT Retrievals     ______________ ___ _____ __________

     To initialize the audit file reader, the following call is made:

          ENTER MACRO DBAINI USING filename [,"ALL"].

     filename   is the name of the audit trail file

     "ALL"      indicates that entries for datasets other than the one
                currently opened will be returned.

     Once DBAINI has been called, entries may be  retrieved  from  the
     audit trail with the command:

          ENTER MACRO DBAGET USING LENF,FLAGS,LENE,ENT,EOF.

     LENF    is a COMP item indicating the length of the FLAGS array.

     FLAGS   will receive information about the entry as follows:
AUDIT TRAIL - COBOL INTERFACE ROUTINES                       Page 12-3


     01   FLAGS.
          05   ENTRY-TYPE                     PIC 999   COMP.
             88   DATASET-OPEN-ENTRY          VALUE 4.
             88   AUDIT-TRAIL-STARTED-ENTRY   VALUE 5.
             88   COMMENT-ENTRY               VALUE 6.
             88   END-AUDIT-TRAILS-ENTRY      VALUE 11.
             88   DATASET-CLOSED-ENTRY        VALUE 13.
             88   END-WRITE-OPERATION-ENTRY   VALUE 14.
             88   BEGIN-WRITE-OPERATION-ENTRY VALUE 15.
             88   CHECKPOINT-ENTRY            VALUE 16.
             88   CUSTOM-ENTRY                VALUES 448 THRU 511.
          05   ENTRY-LENGTH                   PIC 9999  COMP.
          05   DATASET-HANDLE                 PIC 9(10) COMP.
          05   ENTRY-DATE-TIME                PIC 9(10) COMP.
          05   PPN                            PIC 9(10) COMP.
          05   JOB-NUMBER                     PIC 999   COMP.
          05   CHECKPOINT-NUMBER              PIC 9(6)  COMP.
          05   HOST-LANGUAGE-FLAG             PIC 9     COMP.
             88   ENTRY-FROM-HL               VALUE 1.
             88   ENTRY-FROM-SA               VALUE 0.
          05   UPDATE-ON-FLAG                 PIC 9     COMP.
             88   ENTRY-HAD-UPDATE-ON         VALUE 1.
             88   ENTRY-HAD-UPDATE-OFF        VALUE 0.
          05   CHECKPOINT-FLAG                PIC 9     COMP.
             88   ENTRY-IS-CHECKPOINT         VALUE 1.
             88   ENTRY-IS-NOT-CHECKPOINT     VALUE 0.

     Notes:

     1.  ENTRY-DATE-TIME is in  universal  date-time  standard  format
         (TOPS-10) or in internal date and time format (TOPS-20).

     2.  PPN is the  ppn  (TOPS-10)  or  logged  in  directory  number
         (TOPS-20) of the user making the entry.


     LENE    is a COMP item indicating the length of the ENT array.

     ENT     is the record that will receive the entry from the  audit
             file.

     EOF     is a COMP item which will be zero  when  the  audit  file
             being  read  is  not at end-of-file.  If EOF is non-zero,
             the file is at the end and no FLAGS  or  entry  data  are
             returned.

     If a user defined entry is being returned, its  form  in  ENT  is
     identical  to  its  entry  form when it was PLACED into the audit
     file with DBAUD.

     Additionally, system-defined entries (whose  code  types  are  in
     octal) may be returned.

AUDIT TRAIL - COBOL INTERFACE ROUTINES                       Page 12-4


     Entry type 4:  Dataset opened     _____ ____ __  _______ ______

     01  THE-ENTRY.
         05   DATASET-OPEN.
              07   DATASET-NAME                   PIC X(25) DISPLAY-7.
              07   FILE-ID                        PIC 9(10) COMP.
              07   ACCESS-FLAG                    PIC 9     COMP.
                 88   READ-ONLY-ACCESS            VALUE 1.
                 88   NOT-READ-ONLY-ACCESS        VALUE 0.
              07   DAMAGED-FLAG                   PIC 9     COMP.
                 88   FILE-NOT-DAMAGED            VALUE 0.
                 88   FILE-DAMAGED                VALUE 1.
              07   AUTO-OPEN-FLAG                 PIC 9     COMP.
                 88   AUDIT-AUTOMATICALLY-STARTED VALUE 0.
                 88   EXPLICIT-AUDIT-START        VALUE 1.
              07   UPDATE-ON-FLAG                 PIC 9     COMP.
                 88   STARTED-WITH-UPDATE-ON      VALUE 1.
                 88   STARTED-WITH-UPDATE-OFF     VALUE 0.
              07   DATASET-FILE-DIRECTORY         PIC 9(10) COMP.
              07   FILENAME                       PIC X(10) DISPLAY-7.
              07   DEVICENAME                     PIC X(10) DISPLAY-7.

     NOTES:

     1.  AUDIT-AUTOMATICALLY-STARTED means that the  audit  trail  was
         opened as the result of an AUDIT START AUTO command.

     2.  EXPLICIT-AUDIT-START means that the dataset was opened before
         the audit entry was written.



     Entry type 5:  Audit Trail Started     _____ ____ __  _____ _____ _______

         05   AUDIT-TRAIL-START      REDEFINES DATASET-OPEN.
              07   THE-VERSION-NUMBER             PIC 999 COMP.
                 88   PRESENT-VERSION             VALUE 0.
                 88   BAD-VERSION-NUMBER          VALUES 1 THRU 999.
              07   FILLER                         PIC X(70) DISPLAY-7.


     ENTRY TYPE 6:  COMMENT     _____ ____ __  _______

         05   COMMENT     REDEFINES DATASET-OPEN.
              07   COMMENT-TEXT                   PIC X(75) DISPLAY-7.

     Note:

     A comment may  be  longer.   Its  actual  length  (in  words)  is
     specified  by  ENTRY-LENGTH  in FLAGS.  The user must remember to
     expand all redefinitions if the comment item is lengthened.
AUDIT TRAIL - COBOL INTERFACE ROUTINES                       Page 12-5


     Entry type 11:  End Audit Trails     _____ ____ ___  ___ _____ ______

         05   END-AUDIT-TRAIL     REDEFINES DATASET-OPEN.
              07   FILLER                         PIC X(75) DISPLAY-7.


     ENTRY TYPE 13:  DATASET CLOSED     _____ ____ ___  _______ ______

         05   DATASET-CLOSED     REDEFINES DATASET-OPEN.
                  <IDENTICAL TO DATASET-OPENED>


     Entry type 14:  End Write Operation     _____ ____ ___  ___ _____ _________

         05   END-WRITE-OPERATION     REDEFINES DATASET-OPEN.
              07   FILLER                         PIC X(75) DISPLAY-7.


     ENTRY TYPE 15:  BEGIN WRITE OPERATION     _____ ____ ___  _____ _____ _________

         05   BEGIN-WRITE-OPERATION     REDEFINES DATASET-OPEN.
              07   FILLER                         PIC X(10) DISPLAY-7.
              07   FILE-SIZE                      PIC 9(6)  COMP.
              07   SET-SIZE                       PIC 9(6)  COMP.
              07   DAMAGE-DATE                    PIC 9(10) COMP.
                 88   NO-DAMAGE-DATE              VALUE 0.
              07   DAMAGE-TIME                    PIC 9(10) COMP.
                 88   NO-DAMAGE-TIME              VALUE 0.
              07   DAMAGE-USER                    PIC 9(10) COMP.
                 88   NO-DAMAGE-USER              VALUE 0.
              07   NUMBER-ACTIVE-RECORDS          PIC 9(10) COMP.
              07   NUMBER-DELETED-RECORDS         PIC 9(10) COMP.
              07   NUMBER-ALLOCATED-RECORDS       PIC 9(10) COMP.
              07   LAST-UPDATE-NUMBER             PIC 9(10) COMP.
              07   LAST-UPDATE-DATE               PIC 9(10) COMP.
              07   LAST-UPDATE-TIME               PIC 9(10) COMP.
              07   LAST-UPDATE-PPN                PIC (10)  COMP.
              07   ADMIT-FLAG                     PIC 9     COMP.
                 88   ADMIT-CRITERIA-PRESENT      VALUE 1.
                 88   ADMIT-CRITERIA-ABSENT       VALUE 0.

     Notes:

     1.  This entry may be used as a checkpoint.

     2.  FILE-SIZE is in blocks (4 blocks = 1 TOPS-20 page).

     3.  SET-SIZE is the size of the unbundled dataset in words.

     4.  DAMAGE-DATE and LAST-UPDATE-DATE  are  in  radix  date  form.
         (See Appendix B.)

     5.  DAMAGE-TIME and LAST-UPDATE-TIME are  in  milliseconds  since
         midnight.
AUDIT TRAIL - COBOL INTERFACE ROUTINES                       Page 12-6


     6.  DAMAGE-USER is the user number of the data base updater  when
         the file was damaged.

     7.  LAST-UPDATE-NUMBER is incremented  whenever  the  dataset  is
         opened for writing.

     8.  LAST-UPDATE-PPN is the project-programmer number (TOPS-10) or
         logged-in  directory  number  (TOPS-20)  of  the last dataset
         updater.



     Entry type 16:  Checkpoint     _____ ____ ___  __________

         05   CHECKPOINT     REDEFINES DATASET-OPEN.
              07   CHECKPOINT-NAME PIC X(10) DISPLAY-7.
                     <identical to BEGIN-WRITE-OPERATION starting
                       from FILE-SIZE>


     Random access Audit trail input     ______ ______ _____ _____ _____

     The DBALOC routine may be used to start input at the beginning of
     the audit trail file, or at any checkpoint within the file.  This
     may be done with the following call:

          ENTER MACRO DBALOC USING LOCODE,N.

     where:

     LOCODE   is the locator code:

          0 = start of file
          1 = checkpoint number N
          2 = checkpoint name N
          3 = last Nth checkpoint

     N        is a name or integer as indicated by LOCODE

     To start input at checkpoint "HEREGOES", for  example,  the  call
     would be:

          ENTER MACRO DBALOC USING 2, "HEREGOES".

     To start input at the last checkpoint:

          ENTER MACRO DBALOC USING 3,1.
AUDIT TRAIL - COBOL INTERFACE ROUTINES                       Page 12-7


     Loading Programs Using DBAxxx Routines     _______ ________ _____ ______ ________

     The DBAxxx family of routines is included in HL1022.REL only, but                                                             ____
     may  be combined with programs searching HR1022.REL by loading as
     follows:

          LOAD FOO.CBL,SYS:HR1022.REL/LIB,SYS:HL1022.REL/LIB

     Note that HR1022 must be searched before searching HL1022.                      ____             ______


     Examples     ________

     The following program starts a LOCKed audit trail on the  current
     dataset.  The audit file has an extension (or file type) equal to
     the user's job number.  A checkpoint (named  "STARTUP")  is  then
     placed into the audit trail, and the program continues.

                 ENTER MACRO DBCBL.
                 ENTER MACRO DBOPEN USING "PAYROL".
                 ENTER MACRO DBAUD USING "START","LOCK","JOB".
                 ENTER MACRO DBAUD USING "CHECK","STARTUP".
                 .
                 .
                 .
AUDIT TRAIL - COBOL INTERFACE ROUTINES                       Page 12-8


     The following fragment writes a custom audit entry  whenever  the
     user  runs  the program.  The program accepts the user's name and
     authorization code  in  the  initialization.   These  values  are
     placed in the custom audit entry with code 700 octal.

     WORKING-STORAGE SECTION.
         01   FLAGS.
              05   ENTRY-TYPE           PIC 999    COMP.
         01   CUSTOM-ENTRY-SIZE         PIC 9      COMP VALUE 3.
         01   CUSTOM-ENTRY-NUMBER       PIC 999    COMP VALUE 448.
         01   CUSTOM-ENTRY.
              05   USER-NAME            PIC X(10)  DISPLAY-7.
              05   AUTHORIZATION        PIC X(5)   DISPLAY-7.
         01   EOF-FLAG                  PIC 9      COMP.
             88     END-OF-AUDIT-FILE   VALUE 1.
     PROCEDURE DIVISION.
              .
              .
              .
              (INITIALIZATION - ACCEPT AND VERIFY
               NAME and AUCODE)
              .
              .
              .
         ENTER MACRO DBOPEN USING "MOOCOW".
         ENTER MACRO DBAUD
              USING "START","FILE","MOOAUD","LOCK".
         MOVE NAME TO USER-NAME IN CUSTOM-ENTRY.
         MOVE AUCODE TO AUTHORIZATION IN CUSTOM-ENTRY.
         ENTER MACRO DBAUD
              USING "PLACE",CUSTOM-ENTRY-NUMBER,
              CUSTOM-ENTRY-SIZE,CUSTOM-ENTRY.
              .
              .
              .


     Given an application using the previous custom AUDIT  ENTRY,  the
     following partial program reports all users who have accessed the
     dataset and their authorization codes.

              .
              .
              .
     START.
         ENTER MACRO DBCBL.
         ENTER MACRO DBAINI USING "MOOAUD.DML","ALL".
      
     LOOP.
         ENTER MACRO DBAGET USING
              1,FLAGS,CUSTOM-ENTRY-SIZE,CUSTOM-ENTRY,EOF-FLAG.
         IF END-OF-AUDIT-FILE   GOTO ALL-DONE.
         IF ENTRY-TYPE = CUSTOM-ENTRY-NUMBER
              DISPLAY USER-NAME,"       ",AUTHORIZATION.
         GOTO LOOP.
AUDIT TRAIL - COBOL INTERFACE ROUTINES                       Page 12-9


     ALL-DONE.
         STOP RUN.














                              CHAPTER 13

                          FORTRAN INTERFACE



     13.1  DATA TYPES

     In the stand-alone  (interactive)  System,  four  data-types  are
     recognized:   these are INTEGER, REAL, DATE, and TEXT.  The first
     three are numeric (binary), and TEXT is  ASCII  or  SIXBIT.   The
     numeric data-types all have two correspoding DISPLAY equivalents:
     DISPLAY-6 and DISPLAY-7.  The terms INTEGER, REAL, and  DATE  are
     the internal data-types.

     The FORTRAN Interface accepts values  from  the  user  in  either
     numeric  or  DISPLAY-7  modes.   SIXBIT  display  values  are not
     accepted as input although they  may  be  returned  by  the  Host
     Language   routines.   Restrictions  for  the  FORTRAN  user  are
     summarized below:


     1. INTEGER numerics must be represented  either  by  integer
        constants  or by integer variables.  Display integers may
        be represented by text literals or  arrays.   The  arrays
        must  be  three  words long, right justified.  They are a
        maximum of 11 characters long including a sign.

     2. REAL  numerics  must  be  represented  either   by   real
        constants   or   by  real  variables.   Double  precision
        constants and variables may not be used.   Display  reals
        may  be  represented  by  text  literals  or arrays.  The
        arrays must be three words long, right  justified.   They
        are a maximum of 14 characters including a sign, exponent
        E, exponent sign, and decimal point.

     3. DATE numerics must be represented as  integers,  computed
        as  the  number of days since January 1, 1800.  Dates may
        not be passed as text.  User-supplied values in text form
        must be parsed by the user's program into separate values
        for month, day and year.  They may then be  converted  to
        the   proper  encoded  form  using  the  DBDATN  routine.
        Display dates may be  represented  by  text  literals  or
        either arrays of double precision constants or variables.
        The arrays must be two words long, right justified.   The
        display  date  format  is  month/day/year,  e.g.  5/26/55
FORTRAN INTERFACE                                            Page 13-2


        represents May 26, 1955.

     4. TEXT  values  are  of  four   kinds:    file-descriptors,
        keywords,  attribute identifiers and alphanumeric values.
        Each of these kinds may be passed to  the  Host  Language
        routines  as  quoted literals or through variables of any
        type, integer or real.



     13.2  RUNTIME TYPE CONVERSIONS

     The FORTRAN Interface allows the user to supply attribute  values
     in either numeric or DISPLAY-7 modes for any of the Host Language
     subroutines.  Additionally, Host Language subroutines may  return
     attribute values as numeric, DISPLAY-6 or DISPLAY-7.

     Type conversions are  enacted  globally  (throughout  the  user's
     program)  by  1022  System  Variables,  or  locally  (in  a given
     subroutine call) by using special keywords.

     For global  conversions  the  users  sets  the  System  Variables
     SYSHLMODE  and  SYSHLDISP  with  DBSYSV  (see  section  2.33)  as
     follows:

     1.  SYSHLDISP

         This System Variable governs the prevailing mode of input and
         output  of  display items from the Host Language.  A value of
         zero causes display items to be passed  as  and  returned  as
         DISPLAY-7.   A value of +1 causes display values to be passed
         as and returned as DISPLAY-6.  Zero is the default setting.

     2.  SYSHLMODE

         A value of zero means that no conversions are to be done.   A
         value  of  +1  means  that  the  Host Language Interface will
         accept and return all numerics in the prevailing display mode
         (see  SYSHLDISP).   A  -1  value  causes the Host Language to
         accept and return all values with internal  numeric  type  as
         numeric.  The default value is zero.


     For  local  conversion,  precede  the  attribute  name   in   the
     subroutine  call  with  the keyword "DISP." for display or "BIN."
     for binary (numeric.) DISP.  and BIN.  act to override the  value
     of SYSHLMODE on a local level as follows:

     1.  DISP.

         If this special keyword precedes an attribute identifier, the
         Host  Languages  Interface  assumes that the value associated
         with that identifier will be passed as (e.g.  in  DBFIND)  or
         returned  (e.g.   in DBVAL) in the prevailing display mode as
         set by SYSHLDISP.
FORTRAN INTERFACE                                            Page 13-3


     2.  BIN.

         If this special keyword precedes an attribute identifier, the
         value associated with the attribute identifier will be passed
         as or returned as numeric (binary) if the  internal  type  is
         numeric.   Preceeding a TEXT attribute identifier with "BIN."
         has no effect.


     Users  should  note  that  SYSHLMODE  and  SYSHLDISP  affect  the
     operation  of  the user program in a global manner for both input
     (e.g.  DBADD) and output  (e.g.   DBVAL).   As  with  all  System
     Variables,  their  action  remains in effect until they are reset
     (by another call to DBSYSV) or until they are  overriden  locally
     by using DISP.  or BIN.  before an attribute identifier.



     13.2.1  Example

     Assume the following describes a dataset:

          ATTRIBUTE NAME TEXT LENGTH 15
          ATTRIBUTE SSN TEXT LENGTH 11
          ATTRIBUTE AGE INTEGER LEN 3 RANGE 1 150

     This dataset is either bundled or unbundled.  If it  is  bundled,
     the attribute AGE will be binary.  In the unbundled case AGE will
     be display.

     The  following  subroutine  FINDs  the  appropriate  records  and
     CHANGEs the value of attribute AGE for the bundled dataset only:

          SUBROUTINE FIXAGE(NAME,OLDAGE,NEWAGE)
          DIMENSION NAME(1)

          CALL DBFIND('NAME','EQ',NAME,'AND','AGE','EQ',OLDAGE)
          CALL DBCHNG('AGE',NEWAGE)
          RETURN
          END

     A possible call to this subroutine is:

          CALL FIXAGE('FRED',25,27)

     In order for FIXAGE to work on unbundled  datasets  the  numerics
     have  to  be  passed  as displays or the System has to be told to
     expect a binary instead of the display.

     The following version of FIXAGE will work for  both  bundled  and
     unbundled datasets:

          SUBROUTINE FIXAGE(NAME,OLDAGE,NEWAGE)
          DIMENSION NAME(1)
FORTRAN INTERFACE                                            Page 13-4


          CALL DBFIND('NAME','EQ',NAME,'AND','BIN.','AGE','EQ',OLDAGE)
          CALL DBCHNG('BIN.','AGE',NEWAGE)
          RETURN
          END

     A possible call to this subroutine would be:

          CALL FIXAGE('FRED',25,27)



     13.3  STANDARD RECORD FORMAT

     A 1022 record is returned by DBGET into an array (IAR) in what we
     refer  to  as  'Standard  Record  Format.'  In  this format, each
     attribute value begins on a new word boundary.

     The System variables SYSHLMODE and SYSHLDISP affect  this  record
     format  since  display  numerics  are  longer  than binaries (see
     section  12.1)  and  DISPLAY-7  values  are  packed  into   words
     differently   than   DISPLAY-6   values.   In  DISPLAY-7  mode  5
     characters constitute a word.  In  DISPLAY-6  mode  6  characters
     constitute a word.

     EXAMPLE:

     Assuming the dataset consists of three attributes:

          (#1)  ATTRIBUTE R REAL
          (#2)  ATTRIBUTE T TEXT LENGTH 6
          (#3)  ATTRIBUTE D DATE

     and assuming SYSHLMODE and SYSHLDISP have their default  settings
     of 0 then:


          1.  If the record is retrieved from a BUNDLED dataset  using
              DBGET

                   IAR(1) would contain R (in binary floating point)
                   IAR(2) and IAR(3) would contain T
                   (last four characters filled with blanks)
                   IAR(4) would contain D (1022 encoded date format)

              The 20th position of the INF array  returned  by  DBINFO
              contains the index into the Standard Record Format array
              of the attribute.  In the above example:

                   CALL DBINFO('R',INF1)
                   CALL DBINFO('T',INF2)
                   CALL DBINFO('D',INF3)

              would set:

                   INF1(20)=1
FORTRAN INTERFACE                                            Page 13-5


                   INF2(20)=2
                   INF3(20)=4


          2.  If the record is retrieved  from  an  UNBUNDLED  dataset
              using DBGET

                   IAR(1) - IAR(3) would contain R,
                   right justified and blank padded, in ASCII
                   IAR(4) and IAR(5) would contain T,
                   left justified and blank padded, in ASCII
                   IAR(6) and IAR(7) would contain D,
                   right justified and blank padded, in ASCII.

              The 20th position of the INF array  returned  by  DBINFO
              contains the index into the Standard Record Format array
              of the attribute.  In the above example:

                   CALL DBINFO('R',INF1)
                   CALL DBINFO('T',INF2)
                   CALL DBINFO('D',INF3)

              would set

                   INF1(20)=1
                   INF2(20)=4
                   INF3(20)=6


     NOTE:  If the attribute is read protected when a CALL to DBGET is
     made,  the  appropriate  positions  in the Standard Record Format
     array will be filled with blanks or zero.

     The value of the index returned in  location  20  of  the  DBINFO
     array  applies only under the settings of SYSHLMODE and SYSHLDISP
     which exist at the time that DBINFO is  called.   Thus,  changing
     modes  from  DISPLAY-7  to  DISPLAY-6  or  from binary to display
     numeric will change  the  indices  returned  by  DBINFO.   It  is
     recommeded  that  DBINFO  be called immediately after the call to
     DBSYSV (see section 2.33) which sets SYSHLMODE  or  SYSHLDISP  in
     order to avoid possible error.












                              CHAPTER 14

                           COBOL INTERFACE



     14.1  DATA TYPES

     In the stand-alone (interactive) System, four internal data types
     are  recognized:   these are INTEGER, REAL, DATE, and TEXT.  TEXT
     may exist as DISPLAY-7 or DISPLAY-6.  The  Host  Languages  COBOL
     interface supports all the stand-alone data types.

       1. INTEGER values may be  represented  either  by  integer
          constants, Computational variables, or text literals or
          variables.

       2. REAL  values  may  be  represented   either   by   real
          constants,   COMP-1  variables,  or  text  literals  or
          variables.  Double precision variables may not be used.

       3. DATE values may be represented  by  integers  or  text.
          The  integers  must  be  computed as the number of days
          since January 1, 1800.  User-supplied  values  in  text
          form  may be parsed by the user's program into separate
          values for month, day  and  year.   They  may  then  be
          converted  to  integers  by  using  the DBDATN routine.
          Dates passed as text must be in the form:

               mm/dd/yy

          where mm is the month, dd the day  and  yy,  the  year.
          For example, 05/12/72 represents May 12, 1972.

       4. TEXT  values  are  of  four  kinds:   file-descriptors,
          keywords,   attribute   identifiers   and  alphanumeric
          values.  Each of these kinds may be passed to the  Host
          Language  routines  as  quoted  literals  or  stored in
          DISPLAY-7 variables.

COBOL INTERFACE                                              Page 14-2


     14.2  DBVAL SUBROUTINE

     DBVAL has been enhanced to perform data type conversions.  Values
     returned  by  DBVAL  will  have  the  same  type  declared in the
     WORKING-STORAGE SECTION of the program by the USAGE clause.  

     If the attribute type is text, this data item may  have  a  usage
     declaration  as  either  DISPLAY-7 or DISPLAY-6.  If the internal
     attribute type is numeric,  this  data  item  may  have  a  usage
     declaration  as  either COMP or DISPLAY.  An attempt to convert a
     text attribute to a numeric data item will generate an error.



     14.3  STANDARD RECORD FORMAT

     The 1022 record is returned by DBGET into a data record  in  what
     we  refer  to  as  'Standard Record Format.' In this format, each
     attribute value begins on a new word boundary.   The  COBOL  data
     description  must  conform  in  structure and usage to the System
     1022 Standard Record Format.  This is achieved by  declaring  one
     elementary  item  to correspond to each 1022 attribute, using the
     following rules for usage:

     1.  For BUNDLED datasets

     ATTRIBUTE TYPE            COBOL USAGE CLAUSE     _________ ____            _____ _____ ______
          INTEGER              COMP
          REAL                 COMP-1
          DATE                 COMP
          TEXT                 DISPLAY-7 SYNC LEFT
                                     or
                               DISPLAY-6 SYNC LEFT


     2.  For UNBUNDLED datasets

     ATTRIBUTE TYPE            COBOL USAGE CLAUSE     _________ ____            _____ _____ ______
          INTEGER              DISPLAY-7 SYNC LEFT PIC X(15)
          REAL                 DISPLAY-7 SYNC LEFT PIC X(15)
          DATE                 DISPLAY-7 SYNC LEFT PIC X(10)
          TEXT                 DISPLAY-7 SYNC LEFT

                                      or

          INTEGER              DISPLAY-6 SYNC LEFT PIC X(12)
          REAL                 DISPLAY-6 SYNC LEFT PIC X(18)
          DATE                 DISPLAY-6 SYNC LEFT PIC X(12)
          TEXT                 DISPLAY-6 SYNC LEFT
COBOL INTERFACE                                              Page 14-3


     Example:

     Assume that the dataset consists of three attributes:

          (#1)  ATTRIBUTE I INTEGER
          (#2)  ATTRIBUTE T TEXT LENGTH 6
          (#3)  ATTRIBUTE D DATE

     Then the correct COBOL record description  for  a  BUNDLED  ASCII
     dataset would be:

          01 X22RECORD DISPLAY-7.
          02 I, COMP, PIC S9(9).
          02 T, DISPLAY-7 SYNC LEFT, PIC X(6).
          02 D, COMP, PIC S9(9).



     14.4  RUNTIME TYPE CONVERSIONS

     The COBOL interface allows the user to convert values returned to
     or  passed  from the Standard Record Format between DISPLAY-6 and
     DISPLAY-7 and between binary and display  numerics.   Two  System
     Variables,  SYSHLDISP  and  SYSHLMODE,  govern these conversions.
     These variables may be set with DBSYSV (see section 2.33.)

     If SYSHLDISP has a value of 0 all display items will be passed as
     or  returned as DISPLAY-7.  A value of +1 means all displays will
     be DISPLAY-6.  Zero is the default setting.

     If SYSHLMODE has a value of +1 then all numerics will be accepted
     or  returned  in  the  prevailing display mode (see SYSHLDISP.) A
     value of -1 means that all numerics will be accepted or  returned
     in  their  binary  forms.   Zero is the default setting and means
     that no conversion will occur.

     SYSHLMODE and SYSHLDISP affect the Standard  Record  Format  (see
     section   14.3.)   Users   should   take  care  that  their  data
     descriptions are correct.












                              CHAPTER 15

                    MACRO INTERFACING CONVENTIONS



     15.1  INTRODUCTION

     To promote the widest use of System 1022, the ability  to  access
     1022  from  MACRO is provided.  The experienced assembly language
     programmer can easily write programs which utilize 1022.   To  do
     so,  he  must  understand  the  1022  calling conventions and not
     interfere with the system's channel  or  core  allocations.   The
     1022  calling  conventions  are  described  in  section 2 of this
     chapter.  The powerful internal  1022  I/O  and  core  management
     facilities have been made available to prevent conflicts in these
     areas.  They are explained below.
MACRO INTERFACING CONVENTIONS                                Page 15-2


     15.2  SUBROUTINE LINKAGE

     The basic subroutine linkage used by 1022 is  the  same  as  that
     used by FORTRAN.  The general form is:

                 .
                 .
                 .
                 MOVEI   16,ARGS
                 PUSHJ   17,DBFOO
                 (return here, AC's 0-16 are destroyed)
                 .
                 .
                 .
                 -n,,0
         ARGS:   0,,ARG1
                 0,,ARG2
                 .
                 .
                 .
                 0,,ARGn
                 .
                 .
                 .
         ARG1:   BLOCK 1
         ARG2:   BLOCK 1
                 .
                 .
                 .
         ARGn:   BLOCK 1


                                 NOTE

          Arguments must not reside in the accumulators.

          Under TOPS-20, System 1022 runs with the  compatibility
          package   at   its   default  location.   Modifying  or
          disabling   the   compatibility   package   may   cause
          unpredictable behavior by System 1022.



     15.3  INITIALIZATION

     Before calling any  other  routines,  DBMAC  must  be  called  to
     perform  System  1022  initialization.  DBMAC takes no arguments,
     and AC 16 must be set  up  properly  to  indicate  this.   As  an
     example  of a 1022 routine called with no arguments, DBMAC may be
     invoked as follows:
MACRO INTERFACING CONVENTIONS                                Page 15-3


                 .
                 .
                 .
         MOVEI   16,[0]+1
         PUSHJ   17,DBMAC
                 .
                 .
                 .

     During its execution, DBMAC will allocate a storage  area  to  be
     used  by System 1022.  The storage area is allocated at .JBFF and
     the value of .JBFF is appropriately changed.

     After System 1022 has been initialized in this fashion, the  user
     may  call  any  1022  routines  available  in  FORTRAN,  with the
     exception, of course, of DBFOR, DBSTRT, DBCBL or any  other  Host
     Language.   The  calling  sequences  are the same as for FORTRAN.
     (See the section  on  interfacing  with  FORTRAN  in  the  User's
     Reference manual.)



     15.4  CORE MANAGEMENT

     Under both TOPS-10 and TOPS-20, the user is required to make  all                        ___
     requests  for  dynamic  core  allocations through the System 1022
     DBCORE routine.

     To  allocate  space  contiguously  after  the  end  of  the  user
     programs,  though  not necessarily contiguous with the end of the
     user programs, DBCORE is called with two arguments.

          The first argument is  the  number  of  words  of  core
          desired.

          The second argument will receive  the  address  of  the
          first  word  of  core  allocated  by  DBCORE.   If  the
          requested amount is not available, the second  argument
          will be zero.

     All core is zeroed when allocated, and is always contiguous  with
     any that may have been allocated by a previous call to DBCORE.

     To de-allocate core, the first argument in  the  call  holds  the
     negative  number  of  words  to  release.  The second argument is
     required, and will  be  zero  if  the  request  failed,  non-zero
     otherwise.  Failure of de-allocation is unlikely.  (Under TOPS-10
     it may indicate that the user's runtime core limit has changed.)

     If three arguments are supplied to DBCORE, they  are  interpreted
     as follows:

          The first argument is the number of words to  allocate,
          as before.
MACRO INTERFACING CONVENTIONS                                Page 15-4


          The second argument is returned as  an  offset  to  the
          first  word  of allocated space, or zero if the request
          failed.

          The third argument is supplied as the base address from
          which to calculate the offset.

     If the third argument is zero, the second argument  will  receive
     the  address  of the allocated space.  The three argument call to
     DBCORE is most often used in FORTRAN programs to  allocate  space
     for dynamic arrays.



     15.5  I/O MANAGEMENT

     Under TOPS-20, in native mode, the user may assign JFNs virtually
     at  will.   Care  must  be  exercised  to  insure that the user's
     program does not lock up files  that  System  1022  may  need  to
     access.

     Under TOPS-10, or TOPS-20 in compatibility mode,  the  user  must
     not  alter  the  status of any I/O channels that may be in use by
     System 1022.

     To communicate with the System about  I/O  channels,  the  DBCHAN
     routine is used.  This routine takes one argument as follows:

          If the argument is zero, the next available channel  is
          assigned  to  the  user,  and  the  channel  number  is
          returned.  If zero  is  returned,  there  are  no  free
          channels.

          If the argument is positive, it is interpreted  as  the
          number  of  the  channel the user wishes to assign.  If
          the argument is returned as zero, the  channel  is  not
          available.    Use   of  DBCHAN  in  this  mode  is  not
          recommended.

          If the argument is negative, it contains  the  negative
          channel  number  that  the user wishes to return to the
          pool of available channels.  User programs that release
          channels  that  they  had  not  previously assigned are
          likely to cause errors.



     15.6  LOADING MACRO PROGRAMS

     MACRO  programs  may  be   loaded   using   either   the   HL1022
     (non-reentrant) or HR1022 (re-entrant) libraries.  When using the
     HL1022 library, the HL1022.REL file is searched and may be loaded
     into either the low or high segments as desired.

     When using the HR1022 library, the HR1022.REL file  is  searched.
MACRO INTERFACING CONVENTIONS                                Page 15-5


     A  super  high  segment  must have been previously made using the
     1022SA program.  Information on making super high segments can be
     found in the System 1022 Data Base Administrator's manual.



     15.7  SUMMARY

     When using 1022 from MACRO, the user must be  carful  to  rigidly
     observe  two  restrictions:   the  user  must  not interfere with
     System 1022 I/O or core management operations.

     Initialization     ______________

                 MOVEI   16,[0]+1
                 PUSHJ   17,DBMAC##

     ALLOCATE n Words of CORE     ________ _ _____ __ ____

                 MOVEI   16,[EXP <-2,,0>,[N],ADR]+1
                 PUSHJ   17,DBCORE##
                 SKIPN   ADR
                 JRST    NOCORE
                                 ;ADDRESS OF CORE IN ADR

     DE-ALLOCATE n Words of CORE     ___________ _ _____ __ ____

                 MOVEI   16,[EXP <-2,,0>,[-N],ADR]+1
                 PUSHJ   17,DBCORE##
                 SKIPN   ADR
                 JRST    NOCORE          ;SHOULD NOT HAPPEN

     RESERVE CHANNEL n     _______ _______ _

                 MOVEI   16,[EXP <-1,,0>,CHAN]+1
                 MOVEI   AC,N
                 MOVEM   AC,CHAN
                 PUSHJ   17,DBCHAN##
                 SKIPN   CHAN
                 JRST    NOCHAN
MACRO INTERFACING CONVENTIONS                                Page 15-6


     RESERVE NEXT FREE CHANNEL     _______ ____ ____ _______

                 MOVEI   16,[EXP <-1,,0>,CHAN]+1
                 SETZM   CHAN
                 PUSHJ   17,DBCHAN##
                 SKIPN   CHAN
                 JRST    NOCHAN

     RETURN CHANNEL n TO FREE CHANNEL POOL     ______ _______ _ __ ____ _______ ____

                 MOVNI   AC,N
                 MOVEM   AC,CHAN
                 MOVEI   16,[EXP <-1,,0>,CHAN]+1
                 PUSHJ   17,DBCHAN##



     15.8  EXAMPLE

     The following is a sample 1022 MACRO application program.

     ;this program assumes chart.dms is a dataset whose attributes are:
     ;        name --         text, length 25, person's name
     ;        empno --        integer, person's employee number
     ;        bossno --       integer, employee number of person
     ;                        that this person reports to.  bossno is zero
     ;                        if the person is the boss of everybody.
     ;this program prints an organization chart from the dataset in
     ;   the form:
     ;        boss's name
     ;            level 2 name
     ;                level 3 name
     ;                level 3 name
     ;            level 2 name
     ;                level 3 name
     ;        etc.....
     ;the only limit on the number of levels is the amount of user core.
     ;the dataset is opened as many times as there are levels in the
     ;chart, but 1022's channel pooling ensures that each incarnation
     ;of the dataset happens on the same channel.
     ;the main routine recursively calls itself to print the names on
     ;the next level.
              title chart -- print organization chart
     
              t1=1            ;scratch ac
              ag=16           ;arg list pointer
              p=17            ;stack pointer
     
              stklen==500     ;stack length

MACRO INTERFACING CONVENTIONS                                Page 15-7


     ;it starts here
     
     chart:   reset                   ;clear the world
              move    p,[iowd stklen,stack] ;set up stack ptr
     
              movei   ag,1+[0]        ;init the macro interface
              pushj   p,dbmac##
     
              movei   ag,arg1         ;* open chart
              pushj   p,dbopen##
     
              movei   ag,arg2         ;* find bossno eq 0
              pushj   p,dbfind##      ;finds the boss
     
              movei   t1,1
              movem   t1,dsnum        ;current dataset number
              movem   t1,dshigh       ;highest dataset that is open
     
              pushj   p,subr          ;call routine to do the work
     
     ;here when everything has been printed
     
              movei   ag,1+[0]
              pushj   p,dbend##       ;let 1022 clean things up
              exit                    ;exit
     
     ;subroutine that does all the work
     
     subr:    movei   ag,arg3         ;* dbset dsnum
              pushj   p,dbset##       ;point to dataset
     
              movei   ag,arg4         ;* getrec done
              pushj   p,dbgrec##      ;get next rec, goto done when done
     
              movei   ag,arg5         ;* let pname eq name
              pushj   p,dbval##       ;put name into pname
     
              move    t1,dsnum        ;fetch dataset number
              soje    t1,subr1        ;jump if no indenting needed
              ash     t1,2            ;compute 4*(level#-1)
              outchr  [" "]           ;output that many spaces
              sojg    t1,.-1
     
     subr1:   outstr  pname           ;output the name
              outstr  [byte (7) 15,12,0] ;and a crlf
     
              move    t1,dshigh       ;fetch highest dataset number
              sub     t1,dsnum        ;subtract current dataset number
              jumpg   t1,subr2        ;jump if next level already open
     
              movei   ag,arg6         ;* open noclose chart
              pushj   p,dbopen##      ;open dataset for next level

MACRO INTERFACING CONVENTIONS                                Page 15-8


     subr2:   movei   ag,arg3         ;* dbset dsnum
              pushj   p,dbset##       ;point back to this level
     
              aos     t1,dsnum        ;increment dataset number
              camle   t1,dshigh       ;is this highest level so far?
               aos    dshigh          ;no--make it so
     
              movei   ag,arg7         ;* map to dsnum via empno to bossno
              pushj   p,dbmap##       ;find employees at next level
     
              pushj   p,subr          ;recurse to print next level
              jrst    subr            ;continue printing this level
     
     ;here when getrec above fails
     done:    sos     dsnum           ;decrement dataset number
              popj    p,              ;return from this subroutine
     
     ;data storage and argument lists
     
     stack:   block   stklen          ;pushdown stack
     dsnum:   block   1               ;current dataset number
     dshigh:  block   1               ;highest dataset opened
     pname:   block   6               ;holds the name attribute
     
              -1,,0
     arg1:    0,,[asciz/chart     /]  ;* open chart
     
              -3,,0
     arg2:    0,,[asciz/bossno    /]  ;* find bossno eq 0
              0,,[asciz/eq   /]
              0,,[0]
     
              -1,,0
     arg3:    0,,dsnum                ;* dbset dsnum
     
              -1,,0
     arg4:    0,,done                 ;* getrec done
     
              -2,,0
     arg5:    0,,[asciz/name /]       ;* let pname eq name
              0,,pname
     
              -2,,0
     arg6:    0,,[asciz/noclose   /]  ;* open noclose chart
              0,,[asciz/chart     /]
     
              -3,,0
     arg7:    0,,dsnum                ;* map to dsnum via empno to bossno
              0,,[asciz/empno     /]
              0,,[asciz/bossno    /]
     
              end     chart












                              CHAPTER 16

                             SPSS COMMAND



     16.1  SPSS*

     The System 1022 user is already familiar with  various  forms  in
     which data may be displayed or output from a dataset.  The Report
     Generator may be used to  produce  reports,  the  Host  Languages
     Interface  may  be used to operate on data from a FORTRAN, COBOL,
     or MACRO-10/20 program, and the DUMP comand may be used to output
     data  in  various  machine  readable  forms.   System  1022  also
     provides  a  facility  for  producing  SPSS  system   files   for
     statistical  analysis  with  SPSS  (Statistical  Packages for the
     Social Sciences).  The SPSS Interface is particularly  useful  in
     any  case  in  which the user wishes to produce statistics and/or
     tables and figures from his data.  The System 1022 SPSS Interface
     is described in detail within this chapter.



     16.1.1  SPSS Input

     The SPSS user generally uses the program to build an SPSS  system
     file  and  then  to  perform  statistical analyses on it.  In the
     translation from social science jargon to  database  jargon,  the
     SPSS  system  file corresponds most closely to a 1022 bundled DMS
     file.

     The SPSS system file contains information detailing the  name  of
     each variable (variable translates to attribute);  a label for it
     (these labels are like the 1022 unabbreviated  attribute  names);
     information as to which values are to be considered missing;  and
     the details of the  SPSS  subfile  structure  (described  below).
     This information is stored in binary format which SPSS reads with
     a  special  operating  system  which  also  drives  the   FORTRAN
     routines.

     Following the information about the variables in the system  file
     is  the  actual  data,  stored  case  by case (case translates to
     record).  An SPSS system file, then, contains  a  sort  of  "home
     block"  describing  the format of the data in the cases, followed

     *SPSS is a trademark of SPSS, Inc., Chicago
SPSS COMMAND                                                 Page 16-2


     by the cases themselves.



     16.1.2  Subfiles

     SPSS allows creation of subfiles of  a  given  set  of  data.   A
     subfile  is  simply  a particular subset of the set of all cases.
     For example, if data were collected on the subject  "Alcohol  Use
     Among  Computer  Programmers,"  then  the  dataset  would contain
     information on all programmers in the study.   A  useful  subfile
     might  be  "Male Programmers," or "Programmers Older than 40." In
     each case, the subfile is a subset of the complete  set  of  data
     collected.

     The subfile structure is also detailed in the "home block" of the
     SPSS system file, and each subfile has a unique name, much like a
     dataset name.  Since the number of cases in a  given  subfile  is
     always  known,  data for a subfile is simply appended to the data
     for the subfile which preceded it.



     16.2  FUNCTION OF THE SPSS INTERFACE

     The 1022 SPSS Interface is  designed  to  produce  skeleton  SPSS
     system  files  with  the  minimum  information  needed to perform
     analyses.   Extra  information  such  as  value  labels,  missing
     values,  etc.   are  easily  inserted  by  the user into the SPSS
     control file, and need not be  a  functional  part  of  the  SPSS
     Interface.

     The system file produced by the Interface contains the  following
     information for each variable (attribute):

     1.  File Name - The file name for the SPSS system file is set  to
         the  name  specified  in  the  FILE  clause  (see below).  No
         extension is used.  The text description of the file  is  set
         to:  "From SYSTEM 1022 dataset:<dataset descriptor>."

     2.  Variable Name - The variable name is  set  to  the  attribute
         abbreviation,  if one exists, or to the first five characters
         of the attribute name if no abbreviation has been provided in
         the DMD file.

     3.  Variable Label - The variable label is set to  the  attribute
         name specified in the DMD file.

     4.  Number of Cases - The number of cases  for  a  given  subfile
         produced  by the Interface is set to the number of records in
         the current selection group.  The SPSS command is illegal  in
         GETREC mode.  If no records are selected, an error is issued.
SPSS COMMAND                                                 Page 16-3


     5.  Missing Values - Missing value information is  provided  only
         in  the  case  of  a  protected  attribute, in which case the
         Interface choses an appropriate value (blanks for  text  data
         and  0.0  for  numeric  data)  and  sets  all values for that
         variable to the missing data value.   These  conventions  are
         the same as used by DBVAL in Host Languages.

     Additionally, options in the Interface allow for the selection of
     all  attributes,  or  only  some attributes;  for the creation of
     subfiles;  and for the creation of variable  names  of  the  form
     "VAR00,  VAR01,  ...," etc.  which are often used with SPSS.  The
     Interface  operates  without  external  command  files  (such  as
     descriptions, etc.) making it fast and simple to use.



     16.2.1  Command Format

     The format for commands to the interface is:

        SPSS FILE <filename> [SUBFILE <filename>] [<options>]

     The options available are:

              ATTRIBUTES attr1 attr2 attr3 ... attrn
              NOTEXT
              INFORM
              VARNUM
              CASWGT <attribute expression>
              GO [USING <command string>]

     The function of the command is as follows:  

     1.  If no SUBFILE clause is given, create a new (or supersede  an
         old) SPSS system file with the name given in the FILE clause.
         The subfile name will be the same as the file name.

     2.  If a SUBFILE clause is present, create a subfile of the given
         name in a pre-existing SPSS system file.  If the pre-existing
         system file does not exist, create a new system file with one
         subfile of the name given in the SUBFILE clause.

     3.  If an ATTRIBUTES clause is given, create an SPSS system  file
         with  only  those  attributes  as  variables  in  that order,
         otherwise create the file or subfile with all  attributes  in
         the order in which they occured in the DMD file.

     4.  If  the  NOTEXT  keyword  is  given,  process  only   numeric
         attributes  (including  display  numerics),  and  ignore TEXT
         attributes.  NOTEXT is ignored  if  an  ATTRIBUTE  clause  is
         specified.

     5.  If the INFORM keyword is  given,  print  information  on  the
         terminal  detailing  the  variables created, their names, and
         labels.  Otherwise no output is printed on the terminal.
SPSS COMMAND                                                 Page 16-4


     6.  If the VARNUM keyword is used, create variable names  of  the
         form  VARnn  where  nn corresponds to the sequential order of
         the variable as placed into the system file.  Variable labels
         are  not affected by VARNUM.  If VARNUM is not specified, use
         the scheme mentioned above for determining variable names.

     7.  If CASWGT is specified, set the value  of  the  special  SPSS
         internal  variable  Caswgt  to  the  value  of  the attribute
         expression  specified  in  the  CASWGT  clause.   The  Caswgt
         variable acts as a weighting factor in certain analyses.

     8.  If the GO option is specified with  no  USING  option,  then,
         when  the  SPSS command has created the system file, SYS:SPSS
         is       run       with        the        command        line
         "<name>.OUT=<name>.SPS,<NAME>/get"  supplied.   The  value of
         <name> is derived from the file name specified  in  the  FILE
         clause.

     9.  If the USING option is supplied, perform the function of  the
         GO option, except use the command string provided, eg.:

              SPSS FILE RUN1 GO USING "R1.OUT=RUN1.SPS"














                              CHAPTER 17

            THE CHANGE COMMAND DURING SIMULTANEOUS UPDATE



     A new feature warns a user if the record on which he is  doing  a
CHANGE  has  been  altered since he GETRECed the record.  This warning
protects the user against another user who is simultaneously  updating
the dataset.  The CHANGE is ignored, and the warning message


          CHANGE ignored. Record altered after GETREC.
          SYSID=n Dataset <dsname> IN <file>
          %Continuing


is printed.



17.1  CHANGES IN GETREC MODE

We explain how this can come about.  A  user  may  have  selected  and
printed the values from a record, while at the same time, another user
selects the same record and changes its values.  We still see the  old
values, since we read the record when it had those values.

     System  1022  could  take  the  philosophy  of   re-reading   all
information  before  each PRINT or LET command, but this would produce
high overhead to protect against a rare occurrance.

     The System variable SYSRESET is provided so  that  the  user  can
re-read  all  data  for  each  FIND  command,  and  write out all data
immediately after a CHANGE.  When SYSRESET  is  2,  the  System  takes
these actions.

     However, after any GETREC of data, another user may  change  that
data  without  the  first  user  knowing this.  When the time comes to
change the record, the System compares the record image used to decide
on  the  CHANGE, with the record read fresh from the disk.  The System
is sure that the new copy is correct because it sets UPDATE ON, if  it
has  to,  before  starting the change procedure, so no other users can
alter the dataset during the CHANGE.
THE CHANGE COMMAND DURING SIMULTANEOUS UPDATE                Page 17-2


     The change is all right if the dataset record did not  change  at
all  while  the  the  user  was  "thinking"  about the change.  If the
dataset record has changed without our knowledge, the  change  may  be
undesired  and incorrect.  So, the System ignores the change and warns
the user.

     To protect completely against any surprises, use UPDATE  ON  from
the  time  that  the records are found until the time that all changes
have been  made.   This  is  impractical  in  any  interactive  update
situations;   in  these  the  warning  is enough to keep mistakes from
being made.



17.2  CHANGES IN GLOBAL MODE

Changes in Global mode are a different case.  The  warning  may  print
for  the first record of the selection group.  Records 2 through n are
GETRECed internally within the CHANGE command, when more than 1 record
is  in  the  group.   Their  values  can't change between the internal
GETREC and the update.  However, they may not have the value the  user
printed  before  giving  the  CHANGE (they may have been updated).  We
suggest that UPDATE ON and UPDATE OFF be used  around  the  FINDs  and
global CHANGEs to insure you CHANGE only what you have last seen.



17.3  CHANGES IN THE HOST LANGUAGE INTERFACE

In the Host Language Interface,  you  can  use  an  optional  pair  of
arguments  at  the  beginning of a call to either DBCHNG or DBDEL that
switches control to a labeled statement if the record has been altered
after  the  DBGREC  call.   The  warning message does not print if the
arguments are used, and prints otherwise.

     In COBOL, the arguments are

                        "UPDE.",procedure-name

where procedure-name is the label to which control  returns  when  the
warning is encountered.

     In FORTRAN, the arguments are

                            'UPDE.',$label

where label is the line to which control moves  when  the  warning  is
encountered.

     On transfer, the new (altered) record has been read, so there  is
no  need  to DBGREC again.  For example, a user wants to decrement the
count of all the tools by 1 and print a warning if any of  the  counts
equal zero.  The FORTRAN program is:
THE CHANGE COMMAND DURING SIMULTANEOUS UPDATE                Page 17-3


                            .
                            .
                            .
                  CALL DBFIND ('TYPE','EQ','TOOL')
          100     CALL DBGREC ($400)
          110     CALL DBVAL ('COUNT',ICOUNT)
                  IF (ICOUNT .EQ. 0) GO TO 300
                  LET ICOUNT = ICOUNT-1
          150     CALL DBCHNG ('UPDE.',$110,'COUNT',ICOUNT)
                  GO TO 100
          300     PRINT 310
          310     FORMAT (' WARNING--OUT OF STOCK')
                  GO TO 100
          400               .
                            .
                            .
Line 150 institutes the CHANGE, and  checks  whether  the  record  was
altered  since the DBGREC.  If it was, it sends the record through the
zero checking procedure  again,  to  make  sure  that  COUNT  was  not
decremented to zero by someone else.

     If a previously written  update  procedure  gives  these  warning
messages,  it means that the procedure does not properly interlock the
examination and updating of the dataset.  The  warnings  are  catching
situations  where  incorrect  updating  may occur.  Review the records
where changes are ignored, and change the  procedure  to  include  the
UPDE.  clause to eliminate any conflicts.












                             APPENDIX A

                         1022 TIME DESCRIPTOR



     The following is 1022's time specification:

          [HHMM    ][  ]
          [HH:MM   ][  ]
          [HH:MM:SS][AM]
          [H:M:S   ][PM]
          [H:MM:S  ][  ]
          [HH:M:S  ][  ]
          [H:M:SS  ][  ]
              .
              .
              .

     where

     HH  -  is 0 - 24 except if AM or PM is  specified  in  which
            case it is 0 - 12.

     MM  -  is 0 - 60.

     SS  -  is 0 - 60.

     Examples:

          1100
          2200
          11:3:5
          10:50:03PM
          5:2:50AM












                             APPENDIX B

                         DATE REPRESENTATIONS



     RADIX DATE FORM     _____ ____ ____

     DATE=((YEAR-1964)*12+(MONTH-1))*31+DAY-1

     where:

     YEAR   is the year (e.g.  1977)

     MONTH  =1 for January
            =2 for February
             .
             .
             .
            =12 for December

     DAY    =day of the month


     1022 DATE     ____ ____

     1022 dates are represented as the number of days since 1/1/1800.


     UNIVERSAL DATE-TIME FORMAT     _________ _________ ______

     This is a single word value that contains both a date and a time.

     The left halfword of the universal date-time word is  the  number
     of days since 11/17/1858.

     The right halfword contains  the  time,  expressed  as  a  binary
     fraction of one day.  Under TOPS-10 the time is usually the local
     time.  Under TOPS-20 the time is Greenwich Mean Time.

     The entire universal date-time word then may be  described  as  a
     real  number  of  days since the base date, with a "binary point"
     between bits 17 and 18.
   m )