/hyphenate plotting, plot-ting/
/notrail/
/blank 12/
/center/Plot optimization:
/blank 1/
/center/An application of Dr. John Holland's Theory of
/center/Adaptive Systems to an artificial system
/blank 15/
/center/David J. Wilson
/blank 1/
/center/CCS 524
/center/December 3, 1979
/blank 1/
  
  
  
  
/trail 0/
/newpage/
/blank 1/
/un//center/The Problem/nu/
  
/a/
A problem I have long had an interest in is optimizing %"plotting%".
Plotting is the process of producing drawings with computer-driven
graphic output devices called pen-plotters.
These devices draw on a sheet of paper by moving a pen to the beginning
position of a line segment to be drawn, putting the pen down into contact
with the paper, moving the pen (in this %"down%" position) along the paper
in the desired direction, and then picking the pen up again (unless the next
line segment starts where the current line ended).
/a/
The length of time taken to produce a drawing is proportional to the total
distance the pen travels divided by the rate at which the plotter moves the
pen.
The distance the pen travels in the %"down%" position is completely determined
by the drawing to be produced.
The distance the pen travels in the %"up%" position, moving from the end
of one line segment to the start of the next, depends upon the order
in which the line segments are drawn, and the direction in which each
segment is to be traversed.
This is clearly subject to optimization, and optimizing (minimizing) the
%"pen-up%" distance will result in producing the drawing in the shortest
  
possible time.
  
/blank 4/
/un//center/Motivation for an adaptive approach/nu/
  
/a/
It is frequently obvious how to best plot a desired figure.
The human mind excels at pattern recognition, perceiving localized groupings
of line segments, etc.  
It is tempting, therefore, to try to invent heuristics to do what
the human mind finds so obvious. 
I cannot prove that this approach cannot work, but every heuristic that I
can think of that seems remotely implementable I can also demonstrate to
be defeated by quite reasonable counterexamples.
/a/
An exhaustive search through the n%! permutations of n line segments
is another approach. 
However, it
 is quite decisively condemned by the standard argument:
assume you can examine one of the n%! permutations  in
one microsecond.
Upon carrying out the multiplications, it seems that the universe will be
growing rather old before I have determined the optimum for even a relatively
simple plot, and its not the simple plots that are of real interest.
Also, even that is optimistic - I have ignored the fact that for each permutation
there are 2**n ways to choose the directions in which to traverse each
of the n line segments%!
  
/newpage/
/a/
Consider a function:
/blank 2/
/col 1,l,65/
         f(x)!
/blank 8/
              0                  m !
                                         x
/endtable/
/blank 1/
/a/
Represent a choice of x as a binary number: a string of l bits.
Then consider this string as a representative of 2**l different schemata.
For example, (letting %"#%" signify %"don't care%") x equaling 10101
represents 1####, #0###, and so on.  The schema 1#### is a name for the upper
half of the domain of the function.  #0### is a name for the union of
the first and third quarters of the domain.  
Evaluating f(x)  gives one of the values for f in the domain
1####, one of the values for f in the domain #0###, and so on.
Evaluating f(x) implicitly gives an evaluation of f in each of the
2**l subsets of the domain that x represents.
  
/a/
Suppose that I sort the n%! permutations into some order, and assign
a number to each one.  Then let m in the figure above be n%!, and let
f(x) be the pen-up distance for the permutation I have assigned the number
x.
If the implicit parellism of the schemata approach can handle very badly
behaved functions (which this certainly is), finding and exploiting any
regularities, and locating the real optimum, could it even cope with this
%"pen-up distance%" function?
  
  
/a/
Critical to the success of the schemata approach is the meaning of
each schema.
In the example above, each schema corresponded to a region of the function's
domain in an attractive binary fashion.
This should allow the adaptive system to search out those regions where 
the function has high values.
The success of the application of this approach to the pen-up distance function
will depend on the meaning of the schemata as they correspond to regularities
in the function's values across the domain of permutations.
Whether such a correspondence exists will in turn depend on whether the
ordering of the permutations reveals or conceals any nice behaviour the 
function might have, and the fashion in which schemata name regions of the
domain.
/newpage/
/un//center/The Class of Environments/nu/
   
  
/a/
The class of environments that the system may face will be the class of all
possible plots.
A particular environment, E, will be a particular plot.
To be precise, a "plot" will be defined as a list of line segments in
a plane.
The list will have a length, n, and each line segment in the list will be
specified by the coordinates of its end points in the plane relative to some
fixed origin and set of axes.
  
/a/
Each of the n elements in the list is thus simply a 4-tuple of numbers.
The first two numbers in a 4-tuple will define the first endpoint of
the corresponding line segment, and the second two numbers will define
the second endpoint.
Traversing a line segment from the first endpoint to the second will be
arbitrarily called %"forwards%", and traversing in the opposite direction
wil be called %"backwards%".
For simplicity, we will assume that the system may choose to traverse a 
line segment in either the forward or backward direction, as it thinks best.
  
  
/a/
The adaptive system will not deal with the list (environment) directly,
but rather will perceive the environment through a payoff function.
No other information from the environment will exist, other than the
value of n, which the system will require when creating and operating on
its population.
The payoff function will be simply the pen-up distance function.  Note
that in this case the task of the adaptive system is to minimize the
 payoff function.
  
  
/blank 4/
/un//center/The criterion for comparing plans/nu/
/a/
I do not have a precise formulation of X.  The object of this project has
been, first of all, to implement an adaptive plan on a computer and see if
it will work at all against the pen-up function.  If the plan should work,
then increasing degrees of sophistication were to be tried in the hope
of improving how well the system works.
  
As best I can state it, a plan %"works%" if it appears to consistently
drive the population to better structures than are in the initial randomly
selected population.  Given the immense size of the problem space,
(n%!)(2**n), any plan that can do this I consider to %"work%".
  
/a/
What then constitutes %"better%"?  Given two plans that work, the important
criteria are:
/bn/
How fast does each work?
How rapidly are the payoffs of the best structures in the population driven
downwards?  
Also of interest is how fast the average payoffs are driven down.
  
/bn/
How far will each plan utimately go?
 Will either plan discover the real optimimum?
If not, how much improvement over the best in the initial population will
be acheived?
Of the most practical interest is the question: how much improvement
over the %"original%" plot (defined by the actual ordering of the list
constituting the environment) will be acheived?
If the initial population contains a structure corresponding to this
%"original%" plot, these last two questions become identical.
  
/a/
I began with an a priori notion of the plan I wished to implement, and
proceeded to approach that plan in steps of increasing complication.
At each step the criteria above were applied to judge whether each step
had the relevance and degree of success I expected.  
As far as I had time to carry the experiment, the results were sufficiently
obvious that statistical tests of the above criteria to precisely evaluate
alternative plans were not necessary.
  
  
  
/blank 3/
/un//center/The set of adaptive plans/nu/
/blank 2/
/un//left/The population/nu/
/a/
At each instant in time, t, there will be a population A(t), a subset of the
possible structures A.
In the function example on page 2 the structures were binary strings, and
so A = An x ... x A1 where each Ai equals [0,1].
It turns out, however, that taking a number, 1000 for example, and deriving
the 1000th permutation is not simple.  If a number is expressed in a mixed
radix system where the digits are coefficients of factorials:
  
/col 1,l,65/
!
       Cn (n-1)%! + Cn-1 (n-2)%! + ... + C3 (2)%! + C2!
/endtable/
/a/
then it is easy to derive the corresponding permutation.
Due to the factorial nature of permutations, there are correspondences between
the factorial coefficients Cn, ..., C2 and the elements in a list of all possible
permutations of n things.  The correspondence I have chosen produces a
lexicographic ordering of the permutations, and is due to D. N. Lehmer.
(See Sedgewick, R, /un/Permutation Generation Methods/nu/, ACM Comp. Surveys
9:2.)
  
/a/
Converting the number 1000 to this mixed radix form yields the coefficients
121220, and is easy to do.  As n gets large, however, this conversion would
by itself be a formidable task.  
Also, its not obvious that the binary schema correspond naturally to any
meaningful patterns in the list of n%! permutations anyway.
The obvious solution is to use the coefficients Cn, ..., C2 themselves as
the components of a structure.  So A = An x ... x A2 where Ai = [0, ..., i-1].
  
/a/
Since the structures are built of factorial coefficients, and the permutations
progress via a factorial process, the reqions named by schemata should
correspond to meaningful patterns.  The following figure shows the correspondence
between permutations and structures, and illustrates one simple schema:
  
/blank 1/
/col 1,l,65/
          for schema ###                    for schema #00!
  !
     permutations  structures          permutations   structures!
     ------------  ----------          ------------   ----------!
         ABCD        0 0 0                 ABCD         0 0 0!
         ABDC        0 0 1                 ABDC         0 0 1!
         ACBD        0 1 0                 ACBD         0 1 0!
         ACDB        0 1 1                 ACDB         0 1 1!
         ADBC        0 2 0                 ADBC         0 2 0!
         ADCB        0 2 1                 ADCB         0 2 1!
         BACD        1 0 0!
         BADC        1 0 1!
         BCAD        1 1 0!
         BCDA        1 1 1!
         BDAC        1 2 0!
         BDCA        1 2 1!
         CABD        2 0 0!
         CADB        2 0 1!
         CBAD        2 1 0!
         CBDA        2 1 1!
         CDAB        2 2 0!
         CDBA        2 2 1!
         DABC        3 0 0!
          DACB        3 0 1!
         DBAC        3 1 0!
         DBCA        3 1 1!
         DCAB        3 2 0!
         DCBA        3 2 1!
         BADC        1 0 1!
         BCDA        1 1 1!
         BDCA        1 2 1!
/endtable/
  
  
/a/
See Appendix A for a Pascal program that examines schemata, and a more
extended set of examples.
/blank 2/
/a/
There still remains the problem of choosing, for a given permutation, from
among the 2**n possible choices of directions to traverse each line segment.
This could be addressed as a subproblem and solved within the payoff function.
Simple schemes come to mind such as always moving (with pen up) from the
endpoint of the current line segment to the nearer of the endpoints of the
next.
I could imagine situations, however, that would be analogous to a Chess gambit -
a sacrifice now could reap a reward later.  For example, consider the following
plot fragment:
/newpage/
/a/
The optimal directions are indicated by arrow heads.  It should be possible to
build up a long sequence by composing many such cases together, defeating any  
scheme with a finite lookahead.
Therefore, I elected to let the adaptive system solve the direction subproblem
right along with the permutation problem.  (I'll return to this issue later.)
So finally: 
/blank 1/
/col 1,l,65/
          A = An x ... x A2  x Bn x ... x B1!
!
                                   where Ai = [0, ..., i-1]!
                                         Bi = [0,1]!
/endtable/
/blank 1/
/a/
Now that the ordering of the permutations, and thus the domain, of the function
to be optimized is defined.  What does its behaviour look like?  
I believe I have selected as "natural" an ordering as possible, so the graph
of the function should appear as nice as is possible.  In order to reasonably
graph all of the points for the pen-up distance function, its necessary to pick
a simple enough plot to limit the number of points, while still revealing
something of the nature of the function.  The following simple figure has only
six line segments, and is the simplest example of a commonly plotted figure:
a grid.
/blank 12/
/a/As simple as this figure is however, it still has 720 permutations multiplied
by 64 direction choices.  What I have done is to write a program to examine
all 720 permutations, and select the best of the 64 choices for each.  The
resulting graph follows, and the program is in Appendix B.  Note that each
graphed point represents 64 points, 63 of which are equal or worse.
/trail 8/
/un//left/Reproduction/nu/
/a/
The adaptive plans I have implemented are of the reproduction and crossover
type.
The population at time t, A(t), is first subjected to a reproduction phase
to produce A'(t), and then A'(t) is subjected to a crossover phase to
produce the next population (generation) A(t+1).  These phases represent
exploitation, and exploration, respectively.
 
/a/
The first stage of implementation involved the mechanics of obtaining the
coordinate list defining the environment, E, randomly selecting an initial
population for generation 0, and the rudiments of the cyclic process of
generating generation i+1 from generation i.
This rudimentary first implementation used only a reproduction phase, to
isolate the exploitation aspect.
 
/a/
The payoff for every structure in the population was calculated, and
an average arrived at.  Then an expected number of offspring was calculated
for each structure.  A random number generator was sampled to resolve fractional
offspring numbers.  This seemed more in keeping with the spirit of the Theory
then deterministic  methods for making the decisions.  The normal calculation would be:
/col 1,l,65/
!
       OFFSPRING := PAYOFF %/ AVERAGE!
/endtable/
/a/
Since I must minimize, not maximize, payoff, visualize the payoff function
inverted about the line y = average (i.e. payoff = average):
/col 1,l,65/
!
       OFFSPRING := [AVERAGE + (AVERAGE - PAYOFF)] %/ AVERAGE!
!
                 := 2 - PAYOFF %/ AVERAGE!
/endtable/
/a/
As a first environment I chose a 6 x 6 grid, involving 14 line segments.
Ignoring the direction problem, at one microsecond per permutation an exhaustive
search would take on the order of a day.  So, multiplying by the 2**14 direction
possibilities, its clear that the problem space is large enough to be interesting.
The plot is illustrated on the following page.  The line segments are numbered
according to the order of the list submitted to the adaptive system, and
arrow heads indicate the forward directions.
/a/
If the plot were to be drawn in the given order, and with the directions shown,
the pen-up distance would be 899.64, which is nearly as bad as the worst
structures chosen at random.  The true optimum is 114.2.  What is interesting,
is that keeping this given ordering but making the best choice of directions
yields a pen-up distance of 120.0.  Nearly optimum%!
This illustrates the critical nature of the direction subproblem, and yet
the graph for the 2 x 2 grid indicated that the function isn't very nice even
with the subproblem screened out.
  
  
/newpage/
/blank 20/
-------    6 x 6 grid --------------
/newpage/
  
/a/
On the next page is a graph of the performance of the system with reproduction
alone.
The solid lines show the results of the first run. 
The initial population was 100 structures chosen at random.
The dotted lines represent a similar run with one change made to the offspring
function.
/a/
The first implementation of crossover (described and graphed later) showed
very erratic behaviour.  The best values showed oscillations with no net
improvement, and the average failed to drive downwards.  I interpreted this
to mean that the exploration aspect of crossover was overpowering the
ability of the offspring function to preserve and exploit present knowledge.
The solution I chose was to magnify the differences from 1.0 of the expected
number of offspring for each structure, emphasizing the distinction between
good and bad structures.
Given the offpring number calculated as before, I applied the %"emphasizing%"
function:
/col 1,l,65/
!
       OFFSPRING := 1.0 + 2*(OFFSPRING - 1.0)!
/endtable/
/a/
The dotted lines illustrate the resulting behaviour.
I did nothing further with tuning this function, as I saw no evidence that
the systems later shortcomings were related to a general failure to exploit.
/a/
Only one other change was made to the offspring function.
Since fractional offspring numbers are settled probabilistically, the population
size drifts from generation to generation.
It is evidence of the uniform distribution of my random number generator that
the drift would always even out eventually.
However, to minimize the drift and keep the population size more constant I
added a %"centering force%" to the final offpring values:
/col 1,l,65/
!
       OFFSPRING := OFFSPRING +!
                     0.5 * (ORIG_SIZE RENT_SIZE) %/ ORIG_SIZE!
/endtable/
/a/
The factor of 0.5 serves to mute the centering effect, and prevent any
tendency to overcompensate and cause oscillations.
/hyphenate occurring, oc-cur-ring/
/trail 12/
/un//left/Crossover/nu/
/a/
The second phase in deriving generation i+1 from generation i is the crossover
phase.
Structures from A'(t) are chosen at random (without replacement), a pair at
a time.
A crossover point is chosen for each pair, and the segments of the structures
to the right of the crossover points exchanged.
The modified structures then become population A(t+1).
Three successive versions of the crossover operator were implemented.
/a/
Recall that each structure is an element of
/col 1,l,65/
!
       An x ... x A2 x Bn x ... x B1!
/endtable/
/a/
Each Bi contains two values, forward and backward, and the corresponding
component of a structure specifies the direction of traversal of line
segment i (the ith element in the list defining E).
This part of the structure is nicely represented as a vector of n bits, and
will be referred to as the "direction bit string" part of the structure.
Each Ai, on the other hand, contains a different number of values: i.
For simplicity of implementation, a fixed number of bits is used for each
of these components of the structure.
My implementation initially uses seven bits for each of these "cells", 
accomodating a maximum value of 128 for n. 
Therefore a structure can be diagrammed:
/col 1,l,65/
!
            Cn    Cn-1    ...     C2    Bn  ...  B1!
/endtable/
/a/
The number of bits actually used in each cell varies according to the number
of values permissible at that position.
Cell i may contain any of the values 0, ..., i-1.
This creates a problem if the crossover point is allowed to occur between any
two bits.
If a cell has a maximum value of 5 (101 binary), crossing 011 and 100 could
produce 7 (111 binary).
The first version of the crossover operator skirted problems by making two
simplifying assumptions:
/bn/
The probabilities of the crossover point occurring within the direction bit
string (including to the left of bit n), and within the cell string, are equal.
/bn/
The cells are regarded as atomic elements - indivisible.  Crossing only occurs
between cells.
/a/
The solid lines on the graph on the following page indicate the performance of
this version with a population size of 100. 
The environment of this and later examples is still the 6 x 6 grid to allow
direct comparisons.
The performance is clearly bad, and prompted the change to the offspring
function discussed and graphed earlier.
The results of the change are illustrated by the dotted lines on the graph:
/newpage/
/blank 12/
First graph with crossover ==================
  
  
  
  
  
/newpage/
/a/
Before complicating the issues by proceeding to the second version of the
crossover operator, I tried two changes.  First, the last run was repeated
with the population size doubled to 200.  A graph of the performance is
on the next page, shown with the solid lines.  The effect was not great,
although the impression I received watching the generation by generation
numbers was one of considerably improved stability.
/a/
The second change was an outgrowth of two observations.  
First, as noted previously, the ordering of the line segments presented to
the system for the 6 x 6 grid would result in a near optimum structure by
%"just%" making the correct choice of direction bit values.  
Second, in practical applications, the plot presented for optimization
may be far from optimum, but is not likely to be at all random.
What would be the effect of giving the system a %"hint%" to start off with?
To answer this question, the system was modified to %"preload%" 5%% of its
initial population with copies of a structure corresponding to performing
the plot exactly as given.  The dotted lines on the following graph
illustrate the resulting performance.  
See Appendix C for detailed output of the run.
/a/
Both of these changes, the population size of 200 and the 5%% preloading,
were kept through all of the later runs to avoid confusing the causes
of performance changes.
/newpage/
/blank 12/
Second crossover graph ====================
/newpage/
/a/
The second version of the crossover operator still treated cells as
indivisible, but "skewed" the density of the probability towards the left
end of the structure in proportion to the number of bits actually used in 
each cell.
For example, cell 2 uses one bit, cells 3 and 4 use two bits each, and so
forth.
The solid lines on the next graph show the results, and Appendix D contains
detailed output.
/a/
The third and final version of the crossover operator incorporated two
changes to complete the progression.
First, crossover was allowed to occur within cells.  If a cell would be
given a value outside its range, its value was left unchanged, as if the
crossover point had actually occurred before the cell rather than within
it.
Second, the probability of the crossover point occurring in the direction
bit string was reduced to better reflect the number of bits involved.
For example, with n = 14 as in the 6 x 6 grid, there are 14 direction bits,
but 41 bits being actually used within the cells.  On that basis
the probability of crossing within the direction bit string
should be 14 %/ (14 + 41).
/a/
The dotted lines on the following graph show the permformance of this
final version, and the detailed output is in Appendix E.  The final version
of the Pascal program implementing the adaptive system is in Appendix F.
  
  
/newpage/
/a/
/blank 12/
Third crossover graph ============
/newpage/
As a different test of the system, consider the plot on the next page.
Note the scrambled numbering of the line segments - any patterns discovered
by the system are certain to be purely of its own devising.  The detailed output
of a run with a population of 250 is in Appendix G, a run which consumed
13 minutes of cpu time on a DEC KL10.
/a/
I don't know the real optimum, but 145.84 is one candidate.  (Note that
the pen is required to start off at and be returned to (0,0)).
The best structure in the initial population is 513.91, and the system finally
achieves a best of 230.22.
By the criterion established at the outset, the system clearly works.
Further, each successive version seemed to work somewhat, although not dramatically, better than its
predecessor.
/hyphenate successfully, suc-cess-ful-ly/
/trail 21/
/un//center/Observations/nu/
/blank 2/
/un//left/Schemata/nu/
/a/
The binary scheme in the function example on page 2 had the property that there
were 3**l different schemata to name subsets of the 2**l problem space.
Any single structure was a representative of 2**l schemata.
The mixed radix scheme pays a considerable penalty in that regard.
Using n = 14, again, 14%! equals approximately 2**36.
A binary scheme would have 2**36 schemata represented by each structure in the
population.
The mixed radix scheme, having only 14 positions in the structure, only has
2**14 schemata represented by a structure.
/a/
The situation looks better if the 41 bits used in the 14 cells are considered, but
not all the bits are permitted to take either of the values 0 or 1, and its
not clear what the additional names really correspond to.
A binary scheme simply appears to %"go against the grain%" of this factorial
process.
The only apparent advantage to considering individual bits is that there is
less likelihood of permanently losing possible values at a given position.
/blank 2/
/un//left/Loss of best structures, and loss of possible values/nu/
/a/
Many examples in the trial runs of the system exist where the current
population's best structure is much worse than the best structure seen up
to that point.
My motive in keeping track of the five best seen at any time was to make it
possible to reintroduce lost good structures.
Doing so, however, might possibly reinforce the already evident tendency to
zero in on a structure that is good, but not optimum.
/a/
Despite crossing within cells, there still appears to be a loss of possible
values for specific cells.
Crossover has no way to resurrect a value for a bit that is gone from the
population.
An approach would be to periodically determine the missing values, and concoct
structures to reintroduce them.
Doing so, however, would have the drawback that such concocted structures would
be unlikely to compete successfully.
They would, in fact, probably be worse than random structures, as they would
be selectively built from values eliminated by the adaptive process%!
/a/
A composite solution would be to introduce missing values by inserting them 
into some of the five best structures seen, and placing these new structures
into the population.  This would have the twin benefit of getting the best
structures back into the population if they've been lost, and also giving
the missing values a fighting chance by trying them out in proven good
contexts.
If the population was already concentrating on those best structures to
the exclusion of all else, then the inserted missing values would spur
exploration into new areas.
The more concentrated the population (and thus the more in need of fresh
avenues of exploration) the more values would be missing.
The perturbing effect of insertion of the missing values would accelerate
precisely when the population was stagnating.
This feedback effect would seem superior to the dead load of random
mutation.
 
 
/blank 2/
/un//left/The direction subproblem/nu/
/a/
If the detailed output in Appendix G is examined, it will be seen that the last
60 generations contributed little to the best five structures other than
fine tuning of the direction bits.
In light of this extreme processing burden caused by what I regard as merely
a subproblem, it seems wise to reevaluate the decision to dump the subproblem
directly onto the adaptive system.
The counter example proposed earlier is valid, but composite cases are likely
to be highly contrived, and no justification for the overall burden of this
approach.
A simple scheme looking ahead a fixed distance (e.g. 3 or 4 steps)
would produce optimum results in almost all cases, and probably close to 
optimum in the rest.
/a/
Incorporating such a solution into the payoff function would cause the adaptive
system to %"see%" the real values of permutations, unobscured by the violent
behaviour of the direction subproblem.  
Looked at another way, the problem space would simply be reduced by a factor
of 2**n.
/blank 5/
/un//center/Conclusion/nu/
/a/
It has been demonstrated that the adaptive approach can successfully attack
an otherwise intractable problem (certainly as complex as the NP-hard
 traveling salesman problem, trivially recast as a plot optimization problem).
It further appears that the performance of the system can be improved greatly
both as far as how good a solution is obtained, and the speed with which it is
reached.
   )