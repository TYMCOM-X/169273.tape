


                               NOTES FROM
                             Ernie Socci's
                        MONITOR INTERNALS CLASS
                              May 6, l98l
                             TYMSHARE, INC.


                        HISTORY OF THE TYMCOM-X

        PDP-10 HISTORY:

        PDP-10 history really began with the UNIVAV 1100 series, and the
7090 which were 36 bit machines.  Tom Hastings, who later became  one of
the chief designers  for the PDP-10  monitor, devised the  scheduler for
the CTSS.  Work was done on development of 36 bit machines at  this time
at DEC by people from MIT; there was also interest and  some development
of 36 bit machines at Stanford and CMU.  First of the PDPs was  the PDP-
6, a 36 bit swapping  machine.  DEC then developed the KA-10,  the first
PDP-10; followed by the KI-10,  KL-10 and the KL-10 and  2020's (KS-10).
Xerox developed the MAX (?);  Dave Poole and Phil Petit, of  Foonly Inc.
developed the F1 through F3.  Of these only the KI, KL, Ks, and F1  - F3
did paging.

        SWAPPING:

        CTSS, the first swapping machines, would just allow one  user in
at a time.  All of that user's memory was brought in as one block. Then,
in order to bring in another, all the user's memory was written on disk,
and all the  code and data of  the new user was  brought in as  a block.
Size was limited to the total available memory space less  the operating
system's memory space.

        The next development was to allow multiple users.  This required
the hardware to have a register  which defined the start and end  of the
current user's memory space.  Then when one user left, another could use
vacant  memory  space.   The problem  of  non-contiguous  spaces  led to
"shuffling" of users  to move user's memory  to adjacent spaces  to free
the largest  possible memory block  for new users.   Shuffling exchanges
CPU power for more efficient memory utilization.

        WHAT IS AN OPERATING SYSTEM?

        An  operating  system  provides  both  sharing  and  protection.
Sharing provides efficiency and communication; protection  provides data
and process structure, integrity, and security.  These two  functions of
an operating system  are basically incompatible  so there is  a constant
trade-off between sharing and protection.

        It was noticed that at  times more than one user would  be using
the  same program  (such as  PIP) and  thereby wasting  memory  space by
duplicating the same program, so a better solution was sought.  A second
memory  bound  S  register  was added  to  the  PDP-10  to  improve this
situation.



                                   1



        These swapping machines were in reality simple  paging machines,
using two large pages.  They divided user address space in two halves: 0
-  377777  (low segment)  of  impure  code, and  400000  -  777777 (high
segment) of  pure, or  non-changing, code.   Each user  got his  own low
segment and shared the high segment.

        TYMCOM-X HISTORY:

        TOPS10 began  with version 1.00.   (Aside:  TOPS10 was  named by
Bob Clements, who was a  "rock freak".  TOPS10 stands for  Ten Operating
Processing  System,  the name  reflects  Bob's interest  in  the  top 10
records.  PDP  stands for Programmed  Data Processor.) Version  2.00 had
GETTAB.   These were  swapping machines,  using DECtape.   The  4 series
monitors  were the  first  successful disk  based  timesharing operating
systems for  the PDP-10.   The 5 series  of TOPS10  monitors had  a file
systems rewrite, and a SCNSER rewrite.

        TYMCOM-X monitor is derived from the 5.02 TOPS10  monitor.  Bill
Weiher from Stanford began with this swapping monitor.  First he rewrote
SCNSER to interface the PDP-10 to TYMNET, then (2) disk I/O routines and
SA-10 channels  for IBM peripherals.   Next (3) a  new FS  (file system)
from scratch with the same  basic structure and ideas and  the scheduler
was modified; this was still  a swapping monitor.  (4) SEGCON  (for high
segment  management)  was  rewritten  (by  Allen  Ginzburg  also), KI-10
support was added because of the new paging hardware; at this point user
memory did  not need  to be  physically contiguous.   (5) and  (6), core
allocation routine rewrites 1 and 2;  now not all user memory had  to be
brought in, and  pages that were not  changed were not  rewritten.  Step
(7)  file  system  rewrite  removed  real  time  support  and  mountable
structure support, cutting "bells and whistles" in favor  of reliability
for basic timesharing.  At this  point only the scheduler was  about the
same as TOPS10 5.02.

        Meanwhile TOPS10 began paging  with the 5.07 version.   5.05 was
the first to run on the  KI.  5.07 and 6 series had paging,  but without
shared pages.

        At this point, in  l976, Ernie Socci joined  TYMSHARE.  Features
then added were (8) paging, (9) clubs and (10) framing.  Basic operating
systems philosophy has been, and  is, to keep the monitor small  and not
to  put  in features  that  can  be efficiently  implemented  by  a user
program. "When it does not cost  a lot, move functionality out of  OS to
user."

        (In TOPS10  ENQ/DEQ features of  schedulers derived from  IBM OS
give functionality similar to clubs.)

        TOPS10 RIB (Retrievable Information Block) Structure:

        In the  UFD (User  File Directory)  there was  basic information
about the file and pointer to  the RIB.  Each word in the  RIB contained
count/address  for blocks,  with  a pointer  word  to the  next  RIB (if
additional space is needed).  Therefore, to find a block near the end of



                                   2



the  file many  RIBs had  to  be read.   R&R (refresh  and  restore) was
developed to collapse RIBs due to deletion of blocks.

        DEVELOPMENT OF TYMCOM-X PAGING:

        Weiher  felt  that tree  structure  should be  used,  not linear
lists, for more efficient retrieval.  Also he felt that the  file system
allocation unit should be  pages, and not blocks.  Since  tree structure
is used R&R is not needed as often.

        Paging  was  designed by  Ernie  Socci and  Allen  Ginzburg, and
implemented by Art  Atkinson, Karen Kolling  and Ernie Socci.   Then (9)
clubs and general process interlocking and (10) framing - which is still
not quite finished but only needs code to be added.

        BASIC ELEMENTS OF TYMCOM-X OPERATING SYSTEM:

     File System
     Network interface/Terminals
     Scheduler
     Context Switching
     Clubs
     Paging & Core Allocation (memory scheduling)
     Generalized I/O (SIMIO)
     Initialization  (DSKCLN)
     Accounting
     Commands - OS
     Interframe Control
     Security (General) & Access Controls

        SIMIO simulates  way disk  used to  look before  paging.  DSKCLN
checks for consistency of files systems.

        Old style operating system would  swap from memory to a  drum or
dedicated moveable head disk, and  also move from memory back  and forth
to file I/O; now all is paging, involving just memory and drum.

        INTERRUPTS:

        There are  7 priority interrupts;  1 is the  highest, and  7 the
lowest.  Channel 7 for is scheduling control; channel 1 is  dedicated to
60 cycle clock on processor. The scheduler is pre-emptive.

        There is  a block of  pages in the  physical memory,  the user's
address space (from page 0 to page 777), and the page map, or  User Page
Table (UPT) consisting  of map slots  containing the APWSC  bits (Access
Public Writeable Software Cache)  plus physical page address.   All user
virtual accesses are through this  UPT. (A "page fault" means the  A bit
is not set.)

        If  a fault  occurs  for an  instruction (say  move  1,1000) the
instruction is  restarted after the  page arrives in  memory.  Switching
users (or  if a user  changes his map)  causes the associative  page map
memory to be cleared.


                                   3



                LEVELS OF OPERATION OF OPERATING SYSTEM

    USER LEVEL
      UUO level ..............
                               ....    clock
                                    > (context switch) level
                               ....    commands
      Interrupt level  .......

    UUO (monitor Unimplemeted User Operation) level:
      1) UPT, context pages, user address space data, resident storage
           all available (resident storage accessible at any level).
      2) can do other UUO's - reentrant
      3) page fault, go into wait, etc. really an extension of user
           code
      4) won't let scheduler interrupt UUO's - saves code in OS
           by not having to interlock as much
      5) can get and release interlocks
      6) all diddling of user address space here.

     Interrupt level:

      Simple:                    Clock, rescheduling, core scheduling:

      only resident storage      can't reach user address space, but can
      minimal code execution       access all context pages & UPTs via
      no rescheduling              polling at clock ticks


        Monitor job: when a command needs to reference a  user's address
space, this is setup at command interrupt level and the code  to execute
the  command  is scheduled  as  a job.   Monitor  jobs  affect differing
portions of user address space, but PC is modified so user job  can't be
restarted.

        Some commands require context pages to be resident.   These poll
every tick (60th of a second) to check if the pages have  arrived before
proceeding.
                          FILE SYSTEM & PAGING

        COMPARISON:

         VM370               TOP20               TYMCOM-X
                             TENEX

  no sharing of pages     share pages          share pages
  separate I/O for        separate I/O for     same I/O system for
    general I/O and         general I/O and      general I/O and
    paging                  paging               paging


        TENEX can eliminate drum and then runs like TYMCOM-X.




                                   4



        A  big concern  is lost  time,  that time  when no  one  can run
because everyone is  paged out.  Disk seek  takes 10 to  40 milliseconds
for head to move  and to this must be  added the time for  latency wait,
that is for the drum to  go around to beginning of file.  There  are 4.5
pages per revolution, for a transfer  rate of 60 * 4.5 or 270  pages per
second maximum at 3600 rpm.

        Latency  optimization  is difficult  for  3330  because hardware
doesn't provide rps  (although it could be  done by polling  for current
position).  Seek  optimization consists of  organizing page-in  queue to
minimuze seeks.  Overlays are rather slow since potentially there can be
many seeks.

        FILE SYSTEM:

     Open device
     Lookup/Enter/Rename file
     Create/Destroy file page
     Create/Destroy private page
     Map/Remove file page
     Truncate
     Close
     Release


        If a file page  is deleted or a  file is superceeded a  user who
had the original entity mapped is not affected.  File page is known only
by disk page address, after it is ascertained.

        DISK DATA PAGE STRUCTURE:

        Entry  in  Master  File  Directory  (MFD)  points  to  User File
Directory (UFD), which contains file name, extension, size, license, and
pointer to the PRIME RIB.  The PRIME RIB contains some information about
the file,  and, for small  files, pointers to  disk pages.  A  PRIME RIB
contains 512 words.

        For larger files  the pointers in the  PRIME RIB point  to SPARE
RIBs.   SPARE pointers  are always  at  the top  of the  RIB,  disk page
pointers beyond.  If PRIME RIB contains all SPARE RIB pointers, and more
are needed, then another level of RIBs can be created.

        Everything in  TYMCOM-X OS  is based on  the disk  page address.
When LOOKUP is  done for a  page, actual disk  page address is  put into
user map and OS doesn't change map entries when entries in RIB changes.

        Holes are place takers for  pages not allocated yet, not  a page
of zeros.  Old style I/O  returns zeros when reading holes,  new mapping
gives "NON EXISTENT  PAGE" error returns.  If  you map past end  of file
get  error return  "PAST END  OF FILE".   Deleting file  pages  does not
compress RIB  structure; for  that a  truncate is  necessary.  Therefore
deleting file pages does not move EOF (unless truncate).

        SAT (Storage Allocation Table):


                                   5



        An SAT (Storage Allocation Table) consists of two tables, a 36 x
256 bit table of F (file allocation) bits, and a 36 x 256 bit table of M
("page is mapped") bits.  File allocation bits are set when the  page is
allocated to a file (RIBs or  data pages).  The address of each  SAT and
the number of  pages free in  each SAT is kept  in an in-core  data base
called the STT(SAT table).

        PCB (Physical Core Block):

        PCB  (Physical Core  Block) is  a tiny  paging system  of shared
pages.   It consists  of 15  pages of  SAT's in  physical memory,  and 7
RIB's.  There are 8 SAT's per dual density 3330 disk unit.   To allocate
page, minimize  I/O, get  page from most  empty SAT.   Empirically, most
files tend to be nearly contiguous, since if several pages are allocated
together they will be contiguous  if possible.  However, when a  page is
appended to  a file  the location  of the  last page  is not  taken into
account.  Allocating  a page is  really just setting  a bit in  the SAT.
SATs  are written  out when  dirty, every  3 seconds  if not  changed (3
second counter is reset if any SAT is changed).

        LOCK LEVELS:

   completely locked -- no access
   write locked
   read locked
   write unlocked
   read unlocked
   "write locked new" -- allows a new PCB to be created without being
                           read-in

SECONDARY PCB:

        If a PCB is wanted and all are in use secondary PCB  is created.
The  secondary  PCB  is  copied into  primary  PCB  when  ready  to run.
Secondary PCB is therefore really sort of a one level queue  for waiting
on PCB's.

        RI (RIB PCB  I/O) and SI (SAT  PCB I/O) are states  entered into
when PCB is acquired but still "dirty".  SAT PCBs are written  out every
3 seconds if no activity, RIB PCB's are written out whenever released if
"dirty". CLOSE has to wait for all RIB PCB's to be written out  at least
once.   In RIB  PCB,  write-again bit  is  used to  expedite  this CLOSE
operation.   This bit  is set  when a  dirty PCB  page is  dirtied again
before being written out.

        DRB  (Directory Block)  points to  FNB (File  Name  Block) which
points to the RIB for the version file which the UFD entry is  for.  FNB
has "does this file have a UFD entry?" bit.  For each version of  a file
in use a ATB (Access Table Block) exists.  Each ATB contains protection,
license, size, etc.   plus a pointer to  the RIB.  An ATB  also contains
the UMC (Unshared Mapped Count) and also contains pointer to SPT (Shared
Page Table).  An ATB exists as long  as a channel for file is open  or a
page is  mapped from file.   Private pages have  dummy ATBs.   These are
needed so that SPTs can exist for private pages.


                                   6



        DDB (Device Data Block) contains contiguous pointers  taken from
RIBs so RIB doesn't always have to be in core.  All DDBs  accessing same
file are linked together.  DDB has one to one association  with channel.
All DDBs for a particular file are searched for a pointer before RIB for
file is read (if necessary).

        Only  non-active blocks  are garbage  collected.  UFD  RIBs have
seven  hash buckets.   File name  without sign  bit divided  by  7 gives
bucket.

        MAPPING:

        LMAP (Logical map) - Software Page Mapping:

        The LMAP contains  addresses for disk pages.   For a page  to be
free both the F and M bits in the SAT have to be free.

        To map a page:  look up page and put  in LMAP, also set  (M) SAT
bit, increment UMC (Unshared Map Count) in ATB.  UMC will have the total
pages unshared  plus 1  if SPT  (Shared Paged  Table) exists,  hence ATB
represents the entire  file.  It is possible  for a page to  be "shared"
with a use count of one.  This can happen if it was really shared at one
time and then all the sharers but one remove the page.  All  SPT entries
point back to ATB.

Page Protections:

   Read only
   Copy-On-Write
   Read/Write


        SWR -  Shareable WRiteable  - allows  one to  write into  a high
segment.  SHR and HGH are the same on TYMCOM-X.

        SPT (Shared Page Table):

        Each SPT has  two sections consisting of  the count in  bits and
disk page addresses to a total of 16 entries.  All SPT's for a  file are
connected and point back to the ATB.

        To map:  map in  SAT, check if M bit  set, if not set it,  if so
search for SPT  to see if shared;  increment count if found,  create SPT
entry  otherwise.   To  remove,  map  in  SAT,  search  SPTs  for entry,
decrement if found, if  zero or not found,  clear M bit.  If  no entries
left in SPT then clear SPT entry in the ATB.

        ATOMIC FILE LOCK:

        The atomic file lock was not in the original file system design,
and had to be added to correct a problem than could occur when a RIB was
being changed.  When a RIB is  flushed or changed, all DDB's have  to be
scanned and pointers  (DEVRIBs) changed.  It used  to be possible  for a



                                   7



user to use  the old pointers while  the RIB was being  changed.  Atomic
file lock now locks out all DDB reading in file during the change.

        Atomic file lock has Read (many readers allowed) and  Write (one
writer, no readers or  other writers allowed).  Whenever  operation with
DDB pointers is performed the atomic file lock must be acquired.  Atomic
file lock is the highest level of the hierarcy of locks.   This hierarcy
of locks avoids deadlock.

        ML STATE (General moniaiting state):

   PCB lock
   Aux circuit
   Block I/O  port allocation
   Atomic file lock
   "monitor buffer" devices (like paper tape readers)








































                                   8



                               NOTES FROM
                             Ernie Socci's
                    MONITOR INTERNALS CLASS PART II
                              June 3, l981
                             TYMSHARE, INC.


                      CPU AND INTERLOCK SCHEDULING


        CPU SCHEDULER:

        The  scheduler  allocates  the resources.   It  is  table driven
utilizing queues and wait states, and is optimized for interactive small
jobs.  All jobs are put into one of the cpu queues, Q0 to  Q3, depending
on the number of  pages in the job (the  more pages a job has  the lower
priority run queue it enters).  Q zero is the highest priority queue, Q3
the lowest.  Q zero is reserved for jobs which have acquired  a critical
system resource, such as PCB lock or atomic file lock.

        One consideration for a scheduler is how much time to allow each
job to run.  A job could be allowed to run to completion, or all jobs in
queue  could in  sequence run  for an  amount of  time dependent  on the
number of  jobs in  the queue.  The  second type,  which is  a processor
sharing model,  could result in  the actual amount  of time  to approach
zero.  In the first case throughput would be optimized, response  in the
second,   illustrating  the   tradeoff  necessary   between   these  two
considerations for a scheduler.

        In our scheduler each job is allocated an amount of time when it
acquires the  cpu which is  called the "quantum"  (Q).  Quantum  size is
dependent on many factors including the relation between old and new job
state.  Job will run  for quantum time assigned  to it each turn  in the
queue  unless  interrupted.  The  scheduler  is preemptive,  that  is it
interrups  a user  in mid-quantum  if there  is a  higher  priority user
entering.

        There are two additional types of queues besides the  cpu queue:
wait states,  and resource queues.   A wait state  is a condition  a job
enters when it's waiting for an event to happen.  Wait states include TI
(tty IO wait), SL (sleep), IO, and SW (page IO wait).  Job is  placed in
a satisfied state when event job is waiting for has occurred.  Scheduler
requeues job when when it is in satisfied state.

        There are  schedulers for  memory and  disk as  well as  the cpu
scheduler.  When you come out of a queue, there are different priorities
for rescheduling.

        DISK SCHEDULER:

        There are two  words per resource (REQ  & AVAL).  REQ  gives the
number of  physical devices left,  if AVAL is  zero the resource  is now
available, and can be given to job.  The disk scheduling algorithm is an



                                   9



"elevator"  algorithm which  moves  all the  way in  from  the outermost
cylinder and then out all the way out picking up sectors on the way.

        CORE SCHEDULER:

                     ISCAN                    OSCAN

                                              STOP
                       Q0                       SL
                       Q1                       TI
                       Q2                       SW
                       Q3                       Q3
                       SW                       Q2
                       TI                       Q1
                       SL                       Q0


        The core scheduler (which is still called the swapper) puts into
memory job that cpu wants to run, bringing in the entire working set for
the  job.  This  scheduler  is not  preemptive.   In and  Out  lists are
scanned taking jobs in and out  of core.  When a point is  reached where
the same job is being brought  in as is being taken out  scheduler stops
taking jobs in and out.  A  list is maintained, called the FIT  list, of
jobs waiting to be swapped in.  In-core protect time will guarantee that
a job stays in core for a particular amount of "real" time (ICPT).  If a
job is completed, it is swapped out immediately.


                                 PAGING


        PAGE SHARING:

        Everything is based  on a disk  page (512 words).   Page sharing
was  selected as  the optimum  solution for  sharing of  data.  Extremes
would be sharing words, which would take lots of pointers but would keep
working sets limited to what was needed, and sharing one big  page which
would have low overhead but lots  of wasted space.  The aim is  to share
data instananeously and to have working sets limited to what is needed.

        Data  must be  in core  page to  be shared.   Core page  has use
count, Swap In  Progress and Swap Out  Progress and Dirty bits  and Disk
Page address.  When page is written  on, dirty bit is turned on  so when
page is  swapped out it  is known that  it is necessary  to write  it to
disk.  LMAP  points to the  core page.  ATB  has pointer to  Shared Page
Table.  Every shared file has its own SPT which contains count  and disk
page  address.  The  Core Hash  Table contains  disk page  addresses for
pages that are in core.

        PRIVATE PAGES:

        System allows  private pages  which are like  file pages  from a
file you can't address.  Page is created, mapped in and deleted and only



                                   10



exists  in core.   Since all  is  based on  disk page  addresses,  it is
necessary to make sure private pages  are not swapped out.  The M  and F
bits in the SAT insure that  system knows if someone has a  page mapped.
The M bit is set if someone has  the page mapped, the F bit if it  is in
some file.

        LMAP:

                               LMAP SLOT
                               =========
                            Shared    Active
                           Unshared  Inactive

        LMAP slot states are shared, unshared, active, inactive.  Active
slot means there is a core page address in LMAP, inactive does  not know
it it is a core page or a  disk page.  the MXW bit is on if page  can be
turned into a read/write page,  and doesn't change when protection  on a
file  changes.  All  active  slots for  page  are chained  so  when page
becomes clean all W bits can be reset.  This is so when page  is written
on again  it can  be marked dirty.   A validate  searches the  core hash
table, and regardless of  the state of the  page writes out the  page if
dirty and clears dirty bit.

        UWS, MWS:

        User Working Set is what  the user says size will be.   This can
be specified  by exact pages  or maximum size.   User is billed  on this
size and for adding pages  to working set.  Monitor Working Set  is what
the monitor believes  is in your working  set.  This is the  working set
brought in by the core scheduler.

        SWAPPER STAGES:

        Swapper stages (core  allocation routines) are exactly  the same
for  Context  Page  and  LMAP;  i.e.,  Naildown,  Reserve  and  Swap In.
Naildown increments use count for pages already in memory and then tries
to reserve any remaining pages.   Pages can be stolen that  are promised
to someone else, if that occurs it tries to reserve replacements for the
stolen pages.  Reserve returns either  Yes or No (can or can't  swap him
in now); Yes may mean that a wait for dirty pages to go out is needed.

        Core pages  are 1) Clean  Free; either Clean  Available(CAV), or
Clean Reserved(CRS), 2) Dirty Free (DFR), 3) Reserved In  Progress (RIP)
or 4) in use (USE).   An RIP page is a  dirty page to start out  when IO
finished.

        The  reserver's job  is  to get  pages for  swapping.   It scans
through OSCAN  and starts  deactivating pages.   When use-count  on page
goes to zero that  page is moved into CAV  or DFR.  As pages  are needed
the scheduler moves pages from DFR  to RIP and starts them out  to disk.
When the  IO finished RIP  page is now  a CRS.  If  there still  are not
enough pages, scheduler starts through the queues and  deactivates pages
(known as "eatting").



                                   11
  Q v³