$margin 10
$width 75
$spacing 2
$number off
$center
$indent left +15
$indent right +15
Optimization of Programs
with Structured Variables
$title left 'R. Neil Faiman, Jr.                                        Page \' left 'Alan A. Kortesoja'
$skip 2
R. Neil Faiman, Jr.  and  Alan A. Kortesoja
United States of America
$skip 2
Manufacturing Data Systems, Inc.
4251 Plymouth Road
Post Office Box 986
Ann Arbor, Michigan 48106
USA
$skip 2
$indent left 0
$indent right 0
$just
Neither this paper nor any version close to it has been or is being
offered elsewhere for publication and, if accepted, the paper will be
personally presented in at least one of the 8th World Computer Congress
locations by one of the co-authors.
$skip 6
May be presented at Tokyo, Melbourne or both.
$page
$center
$skip 6
Optimization of Programs
with Structured Variables
$skip 4
ABSTRACT
$skip $just $para 5
The standard algorithms for common subexpression elimination rarely
consider the special problems presented by structured variables.
We have modified the value number algorithm of Cocke and Schwartz [3] to allow
considerable flexibility in the treatment of data references,
and have developed heuristics which allow efficient optimization
of expressions involving structured variables within basic blocks.
Our approach can be extended naturally to handle global common subexpression
elimination.
In this paper, we present our new algorithm and discuss its implementation in
the context of an optimizing Pascal compiler [5].
$page
$verb
1.   INTRODUCTION
$skip $just $para 5
Common subexpression elimination within a basic block is well understood.
A number of algorithms have been published
(for example, [1,2,6,7]),
most of them based to some extent on the value number method of Cocke and Schwartz [3].
While these algorithms will produce optimal results in programs containing only
simple variables, their treatment of structured variables is limited.
In general, they consider only array variables, and treat an assignment to any
component of an array as a redefinition of the entire array.
$skip $need 3 $para 5
Structured variables are entities such as arrays, Pascal records,
and character strings, which are made up of multiple sub-variables.
These sub-variables may be referenced and modified independently, or a
structured variable may be referenced or modified in its entirety.
$skip $need 3 $para 5
In modern programming languages such as Pascal, structured variables
are used extensively.
Thus, the optimization of programs written in these languages would be more
effective if optimization algorithms showed more sophistication in their
processing of structured variables.
$skip $need 3 $para 5
On the other hand, optimal algorithms for programs with structured variables
can be very expensive.
For example, it is shown in [4] that the equivalence problem for
straight line programs with array assignments is NP-Hard.
The algorithm in this paper was developed for use in an optimizing Pascal
compiler [5],
where the objective was to provide effective optimization
at a reasonable cost for
programs which make full use of Pascal's data structuring capabilities.
$skip 4 $verb $need 6
2.   SUMMARY OF THE ALGORITHM
$skip $just $para 5
The algorithm of Cocke and Schwartz [3] maintains a "current value" for each
variable symbol,
and a hash table of current expressions, each with a unique value number.
An expression is tested for redundancy by looking it up in the hash table,
using the value numbers of its subexpressions to compute the hash key.
Assignment to a simple variable simply sets its current value.
Assignment to an array element gives the array variable a new value
number, so that no previously known element of the array can subsequently be
recognized as a common subexpression.
$skip $need 3 $para 5
Our new algorithm also keeps a value for each symbolic variable and a hash table
of expressions.
However, we update the value number of a structured variable (i.e., an
array or record) only when an assignment is made to the entire variable.
We also keep an auxiliary list of statements which modify variables;
when we find a common subexpression which is a component of a
structured variable, we
check the list to see whether any statement has been processed which could
invalidate this expression.
$skip 4 $verb $need 6
3.   THE INVALIDATION TEST
$skip $just $para 5
Our new algorithm is more expensive than the Cocke and Schwartz algorithm,
since it requires a search of the modifying statements list whenever
a common component reference is found.
Our return comes in the latitude which we have in
deciding whether a statement invalidates a reference.
This test may be as simple or as complex as the compiler writer desires;
it may check for special cases where that seems appropriate;
and it may be modified to allow for different data types.
In our implementation, we chose a simple recursive test function (presented
in Appendix II).
$skip $need 3 $para 5
There is one important refinement that can be made, with a suitable invalidation
test function.
If an assignment to a component variable &a& would normally invalidate the
value of some other component variable &b&, then after an assignment
"&a&\:=\&b&", it is frequently possible to assume that &b& is unchanged.
For example, if A is an array, and I and J are arbitrary index variables,
then after the assignment "A[I]\:=\A[J]", the value of A[J] must be unchanged.
If I=J, then the statement has no effect, and if I=J, the assignment does
not affect A[J], so in neither case is the value of A[J] changed.
$skip $need 3 $para 5
Following are some examples of common subexpressions which can be
recognized by our algorithm, in conjunction with our test function:
$indent left +5
$skip $need 3 $para -3
o\\After an assignment to A[I], the value of A[J] is unknown (unless it is
known that I=J).
However, after an assignment to A[I], the value of A[I+1] must be unchanged.
$skip $need 3 $para -3
o\\After the assignment "A[I]:=A[J]", both A[I] and A[J] are available as
common subexpressions.
$skip $need 3 $para -3
o\\Similarly, after the assignment "P^:=Q^", both P^ and Q^ are available.
$skip $need 3 $para -3
o\\If R is a record with fields F1 and F2,
and F1 and F2 are not in different variants,
then an assignment to R.F1 does
not invalidate R.F2.
$skip $need 3 $para -3
o\\Given the declaration:
$verb
     &var& P, Q: ^ &record&
                   &case& F1: BOOLEAN of
                     TRUE: (F2: INTEGER);
                     FALSE: (F3: CHAR)
                 &end&;
$just
An assignment to P^.F2 does not invalidate Q^.F3, since
P and Q must not point to the same record.
If they did, then either the assignment to field F2 or the reference to
field F3 would be illegal (in Pascal, it is illegal to
refer to a field in a variant record which is not selected by the current value
of the tag field).
$skip $need 3 $para -3
o\\If the variant record in the previous example had been an undiscriminated
union (i.e., if the tag field F1 were omitted),
then the assignment to P^.F2 would have invalidated Q^.F3, since now
assignments to overlapping fields of the same record would be legal.
$indent left -5
$skip 4 $verb $need 6
4.   GLOBAL COMMON SUBEXPRESSIONS
$skip $just $para 5
References to an expression X can be replaced by references to an expression
Y only if expression Y must be evaluated before expression X on every control
flow path through the program.
But this simply means that either Y precedes X in the same basic block,
or the basic block containing Y dominates the basic block containing X in the
program flow graph.
Thus, global common subexpression elimination may be performed with the same
algorithm as local common subexpression elimination, by applying the
algorithm along paths in
the flow graph dominator tree instead of within basic blocks.
$skip $need 3 $para 5
The dominator tree can be computed with an algorithm by Lengauer and Tarjan [8].
The only additional information we need is the sets of variables which can
be modified along some control flow path from a dominating block to a
dominated block.
In our compiler, we compute these sets with an algorithm by Reif [9].
However, since Reif's algorithm manipulates sets (represented as bit vectors),
we have to select some set of variables for the algorithm to work with.
Rather than using the actual variables of the program,
we introduce a set of "Formal Reference Expressions", or FREs.
The FREs are defined recursively:
$skip $need 3 $indent +5 $para -3
o\\If X is a symbolic variable, then there is an FRE ^1oX representing X.
$skip $need 3 $para -3
o\\If F is an FRE representing an array, then there is an FRE F[~]
representing all of the elements of F.
$skip $need 3 $para -3
o\\If P is a pointer type, then there is an FRE ^1oP^^ representing all
dynamically allocated variables to which a variable of type P might point.
$skip $need 3 $para -3
o\\If F is an FRE representing a record with a field fi, then there is an
FRE F.fi representing that field of F.
$skip $need 3 $indent -5 $para 5
It is a straight-forward problem to determine the sets of input and output FREs
for each basic block, and given these, Reif's algorithm can be used to
determine the information needed for global common subexpression elimination.
$skip 4 $need 6 $verb
     APPENDIX I
$skip $just $para 5
Our common subexpression elimination algorithm is presented in full below.
The intermediate form used in the compilation is made up of tuples.
Each tuple has a 'result' field, which may point to another tuple.
If no additional information is known about the value of an expression
tuple, then its result field points to itself.
If the value of an expression is known to be the same as the value of some
previous expression tuple, then its result field points to the previous
tuple.
A basic block is reduced in a linear scan, starting at the beginning of
the block.
The following rules are applied to each tuple T in the basic block.
$skip $need 3 $indent +5 $para -5
(1)\\The operands of T will be references to previous tuples T1, T2, ...\Tn.
Replace these operand references with references to result(T1), result(T2),
...\result(Tn), unless tuple T represents an assignment statement.
If T represents an assignment, then replace its source operand reference,
but not its target operand reference.
$skip $need 3 $para -5
(2)\\If T is an expression tuple, check the hash table to see whether there
is a previous tuple T', which has the same opcode and operands as T.
If there is, then check the "modifying statements" list to see whether there
is an assignment tuple T'' subsequent to T', which invalidates T'.
(See the invalidation test in Appendix II.)
$skip $need 3
$title left 'R. Neil Faiman, Jr.                                       Page \' left 'Alan A. Kortesoja'
Case (a): There is a matching tuple T', and no invalidating assignment T''.
In this case, T' is a common subexpression, so set the result field of T to T'.
$skip $need 3
Case (b):  There are a matching tuple T' and an invalidating assignment T''.
In this case, three subcases are possible.
(b1) If the target operand T'T of the assignment T'' has the same opcode and
operands as T, then T'T is a common subexpression, so set the result field
of T to T'T.
(b2) If the source operand T'S of the assignment T'' has the same opcode and
operands as T, then the special case mentioned in section 3 has been
detected and T'S is a common subexpression, so set the result field of
T to T'S.
(b3) Otherwise, any previously known value of T has been invalidated, so set
the result field of T to T.
$skip $need 3
Case (c): There is no matching tuple T'. Set the result field of T to T.
$skip $need 3 $para -5
(3)\\If T is an assignment tuple with target operand TL and source operand
TR, and if TL is not a structured variable, then set the result field of
TL to TR.
If TL is a structured variable, set the result field of TL to TL.
$indent 0
$skip 4 $need 6 $verb
     APPENDIX II
$skip $just $para 5
The invalidation test determines whether the value of an expression X2 may
be assumed to be unchanged after an assignment to a variable expression X1.
If not, we say that the assignment to X1 invalidates X2.
For optimizing Pascal programs,
the following recursively defined invalidation test function gives good
results.
$skip $need 3 $para 5
Given two expressions X1 and X2, an assignment to X1 invalidates X2
(written "Invalidates(X1,X2)") if any of the following hold:
$skip $indent +5 $need 3 $para -3
o\\X1 and X2 are references to the same variable symbol.
$skip $need 3 $para -3
o\\X1 and X2 are pointer references P1^^ and P2^^, where P1 and P2 have the
same pointer type.
$skip $need 3 $para -3
o\\X1 and X2 are array references A1[i1] and A2[i2], and Invalidates(A1,A2)
is true, and DistinctIndices(i1,i2) is false.
$skip $need 3 $para -3
o\\X1 and X2 are field references R1.f1 and R2.f2, and Invalidates(R1,R2)
and InvFields(f1,f2) are true.
$skip $need 3 $para -3
DistinctIndices(i1,i2) is true if i1 and i2 have the forms c1 and c2 or
x+c1 and x+c2, where c1 and c2 are unequal constants, and x is some
common expression.
$skip $need 3 $para -3
InvFields(f1,f2) is true if f1 and f2 are field names in the same record type,
and either (1) f1 and f2 are in different variants of an undiscriminated union,
or (2) f2 is in a variant of a discriminated union, and f1 is the tag field of
the discriminated union.
$indent 0
$skip 4 $need 6 $verb
     REFERENCES
$skip $just left
1.\\\A.\V.\Aho and J.\D.\Ullman, Optimization of Straight Line Programs,
&SIAM J.&\&Comput.&, vol.\1, no.\1, March 1972, 1-19.
$skip $need 3
2.\\\Aho and Ullman, &Principles of Compiler Design&,
Addison-Wesley, Reading, Mass., 1977, 418-428.
$skip $need 3
3.\\\Cocke and Schwartz, &Programming Languages and their Compilers:
Preliminary Notes&, New York University, 1970, 320-334.
$skip $need 3
4.\\\P.\J.\Downey and R.\Sethi, Assignment Commands with Array References,
&Journal of the ACM&, vol.\25, no.\4, October 1978, 652-666.
$skip $need 3
5.\\\R.\N.\Faiman and A.\A.\Kortesoja, An Optimizing Pascal Compiler,
&Proceedings COMPSAC 79&, IEEE, 624-628.
$skip $need 3
6.\\\Gries, &Compiler Construction for Digital Computers&, Wiley, New York,
1971, 377-382.
$skip $need 3
7.\\\Hecht, &Flow Analysis of Computer Programs&, North-Holland, New York,
1977, 208-210.
$skip $need 3
8.\\\T.\Lengauer and R.\E.\Tarjan, A Fast Algorithm for Finding Dominators
in a Flow Graph, &ACM Trans.&\&on Prog.&\&Lang.&\&and Systems&, vol.\1, no.\1, July 1979,
121-141.
$skip $need 3
9.\\\J.\H.\Reif, Combinatorial Aspects of Symbolic Program Analysis,
Ph.D. Th., Harvard U., 1977.
   